{"codeList":["$ pip install pdf2image\n$ pip install pymilvus\n$ pip install colpali_engine\n$ pip install tqdm\n$ pip install pillow\n","from pdf2image import convert_from_path\n\npdf_path = \"pdfs/2004.12832v2.pdf\"\nimages = convert_from_path(pdf_path)\n\nfor i, image in enumerate(images):\n    image.save(f\"pages/page_{i + 1}.png\", \"PNG\")\n","from pymilvus import MilvusClient, DataType\nimport numpy as np\nimport concurrent.futures\n\nclient = MilvusClient(uri=\"milvus.db\")\n","class MilvusColbertRetriever:\n    def __init__(self, milvus_client, collection_name, dim=128):\n        # Initialize the retriever with a Milvus client, collection name, and dimensionality of the vector embeddings.\n        # If the collection exists, load it.\n        self.collection_name = collection_name\n        self.client = milvus_client\n        if self.client.has_collection(collection_name=self.collection_name):\n            self.client.load_collection(collection_name)\n        self.dim = dim\n\n    def create_collection(self):\n        # Create a new collection in Milvus for storing embeddings.\n        # Drop the existing collection if it already exists and define the schema for the collection.\n        if self.client.has_collection(collection_name=self.collection_name):\n            self.client.drop_collection(collection_name=self.collection_name)\n        schema = self.client.create_schema(\n            auto_id=True,\n            enable_dynamic_fields=True,\n        )\n        schema.add_field(field_name=\"pk\", datatype=DataType.INT64, is_primary=True)\n        schema.add_field(\n            field_name=\"vector\", datatype=DataType.FLOAT_VECTOR, dim=self.dim\n        )\n        schema.add_field(field_name=\"seq_id\", datatype=DataType.INT16)\n        schema.add_field(field_name=\"doc_id\", datatype=DataType.INT64)\n        schema.add_field(field_name=\"doc\", datatype=DataType.VARCHAR, max_length=65535)\n\n        self.client.create_collection(\n            collection_name=self.collection_name, schema=schema\n        )\n\n    def create_index(self):\n        # Create an index on the vector field to enable fast similarity search.\n        # Releases and drops any existing index before creating a new one with specified parameters.\n        self.client.release_collection(collection_name=self.collection_name)\n        self.client.drop_index(\n            collection_name=self.collection_name, index_name=\"vector\"\n        )\n        index_params = self.client.prepare_index_params()\n        index_params.add_index(\n            field_name=\"vector\",\n            index_name=\"vector_index\",\n            index_type=\"HNSW\",  # or any other index type you want\n            metric_type=\"IP\",  # or the appropriate metric type\n            params={\n                \"M\": 16,\n                \"efConstruction\": 500,\n            },  # adjust these parameters as needed\n        )\n\n        self.client.create_index(\n            collection_name=self.collection_name, index_params=index_params, sync=True\n        )\n\n    def create_scalar_index(self):\n        # Create a scalar index for the \"doc_id\" field to enable fast lookups by document ID.\n        self.client.release_collection(collection_name=self.collection_name)\n\n        index_params = self.client.prepare_index_params()\n        index_params.add_index(\n            field_name=\"doc_id\",\n            index_name=\"int32_index\",\n            index_type=\"INVERTED\",  # or any other index type you want\n        )\n\n        self.client.create_index(\n            collection_name=self.collection_name, index_params=index_params, sync=True\n        )\n\n    def search(self, data, topk):\n        # Perform a vector search on the collection to find the top-k most similar documents.\n        search_params = {\"metric_type\": \"IP\", \"params\": {}}\n        results = self.client.search(\n            self.collection_name,\n            data,\n            limit=int(50),\n            output_fields=[\"vector\", \"seq_id\", \"doc_id\"],\n            search_params=search_params,\n        )\n        doc_ids = set()\n        for r_id in range(len(results)):\n            for r in range(len(results[r_id])):\n                doc_ids.add(results[r_id][r][\"entity\"][\"doc_id\"])\n\n        scores = []\n\n        def rerank_single_doc(doc_id, data, client, collection_name):\n            # Rerank a single document by retrieving its embeddings and calculating the similarity with the query.\n            doc_colbert_vecs = client.query(\n                collection_name=collection_name,\n                filter=f\"doc_id in [{doc_id}]\",\n                output_fields=[\"seq_id\", \"vector\", \"doc\"],\n                limit=1000,\n            )\n            doc_vecs = np.vstack(\n                [doc_colbert_vecs[i][\"vector\"] for i in range(len(doc_colbert_vecs))]\n            )\n            score = np.dot(data, doc_vecs.T).max(1).sum()\n            return (score, doc_id)\n\n        with concurrent.futures.ThreadPoolExecutor(max_workers=300) as executor:\n            futures = {\n                executor.submit(\n                    rerank_single_doc, doc_id, data, client, self.collection_name\n                ): doc_id\n                for doc_id in doc_ids\n            }\n            for future in concurrent.futures.as_completed(futures):\n                score, doc_id = future.result()\n                scores.append((score, doc_id))\n\n        scores.sort(key=lambda x: x[0], reverse=True)\n        if len(scores) >= topk:\n            return scores[:topk]\n        else:\n            return scores\n\n    def insert(self, data):\n        # Insert ColBERT embeddings and metadata for a document into the collection.\n        colbert_vecs = [vec for vec in data[\"colbert_vecs\"]]\n        seq_length = len(colbert_vecs)\n        doc_ids = [data[\"doc_id\"] for i in range(seq_length)]\n        seq_ids = list(range(seq_length))\n        docs = [\"\"] * seq_length\n        docs[0] = data[\"filepath\"]\n\n        # Insert the data as multiple vectors (one for each sequence) along with the corresponding metadata.\n        self.client.insert(\n            self.collection_name,\n            [\n                {\n                    \"vector\": colbert_vecs[i],\n                    \"seq_id\": seq_ids[i],\n                    \"doc_id\": doc_ids[i],\n                    \"doc\": docs[i],\n                }\n                for i in range(seq_length)\n            ],\n        )\n","from colpali_engine.models import ColPali\nfrom colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor\nfrom colpali_engine.utils.processing_utils import BaseVisualRetrieverProcessor\nfrom colpali_engine.utils.torch_utils import ListDataset, get_torch_device\nfrom torch.utils.data import DataLoader\nimport torch\nfrom typing import List, cast\n\ndevice = get_torch_device(\"cpu\")\nmodel_name = \"vidore/colpali-v1.2\"\n\nmodel = ColPali.from_pretrained(\n    model_name,\n    torch_dtype=torch.bfloat16,\n    device_map=device,\n).eval()\n\nqueries = [\n    \"How to end-to-end retrieval with ColBert?\",\n    \"Where is ColBERT performance table?\",\n]\n\nprocessor = cast(ColPaliProcessor, ColPaliProcessor.from_pretrained(model_name))\n\ndataloader = DataLoader(\n    dataset=ListDataset[str](queries),\n    batch_size=1,\n    shuffle=False,\n    collate_fn=lambda x: processor.process_queries(x),\n)\n\nqs: List[torch.Tensor] = []\nfor batch_query in dataloader:\n    with torch.no_grad():\n        batch_query = {k: v.to(model.device) for k, v in batch_query.items()}\n        embeddings_query = model(**batch_query)\n    qs.extend(list(torch.unbind(embeddings_query.to(\"cpu\"))))\n","from tqdm import tqdm\nfrom PIL import Image\nimport os\n\nimages = [Image.open(\"./pages/\" + name) for name in os.listdir(\"./pages\")]\n\ndataloader = DataLoader(\n    dataset=ListDataset[str](images),\n    batch_size=1,\n    shuffle=False,\n    collate_fn=lambda x: processor.process_images(x),\n)\n\nds: List[torch.Tensor] = []\nfor batch_doc in tqdm(dataloader):\n    with torch.no_grad():\n        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n        embeddings_doc = model(**batch_doc)\n    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n\nprint(ds[0].shape)\n","retriever = MilvusColbertRetriever(collection_name=\"colpali\", milvus_client=client)\nretriever.create_collection()\nretriever.create_index()\n","filepaths = [\"./pages/\" + name for name in os.listdir(\"./pages\")]\nfor i in range(len(filepaths)):\n    data = {\n        \"colbert_vecs\": ds[i].float().numpy(),\n        \"doc_id\": i,\n        \"filepath\": filepaths[i],\n    }\n    retriever.insert(data)\n","for query in qs:\n    query = query.float().numpy()\n    result = retriever.search(query, topk=1)\n    print(filepaths[result[0][1]])\n"],"headingContent":"Use ColPali for Multi-Modal Retrieval with Milvus","anchorList":[{"label":"ColPali f√ºr multimodales Retrieval mit Milvus verwenden","href":"Use-ColPali-for-Multi-Modal-Retrieval-with-Milvus","type":1,"isActive":false},{"label":"Vorbereitung","href":"Preparation","type":2,"isActive":false},{"label":"Vorbereiten der Daten","href":"Prepare-the-data","type":2,"isActive":false}]}