{"codeList":["$ pip install pymilvus -U\n","import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-***********\"\n","from typing import List\nfrom openai import OpenAI\n\nfrom pymilvus import (\n    MilvusClient,\n    DataType,\n    Function,\n    FunctionType,\n    AnnSearchRequest,\n    RRFRanker,\n)\n","# Connect to Milvus\nuri = \"http://localhost:19530\"\ncollection_name = \"full_text_demo\"\nclient = MilvusClient(uri=uri)\n","# Define tokenizer parameters for text analysis\nanalyzer_params = {\"tokenizer\": \"standard\", \"filter\": [\"lowercase\"]}\n","# Create schema\nschema = MilvusClient.create_schema()\nschema.add_field(\n    field_name=\"id\",\n    datatype=DataType.VARCHAR,\n    is_primary=True,\n    auto_id=True,\n    max_length=100,\n)\nschema.add_field(\n    field_name=\"content\",\n    datatype=DataType.VARCHAR,\n    max_length=65535,\n    analyzer_params=analyzer_params,\n    enable_match=True,  # Enable text matching\n    enable_analyzer=True,  # Enable text analysis\n)\nschema.add_field(field_name=\"sparse_vector\", datatype=DataType.SPARSE_FLOAT_VECTOR)\nschema.add_field(\n    field_name=\"dense_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=1536,  # Dimension for text-embedding-3-small\n)\nschema.add_field(field_name=\"metadata\", datatype=DataType.JSON)\n\n# Define BM25 function to generate sparse vectors from text\nbm25_function = Function(\n    name=\"bm25\",\n    function_type=FunctionType.BM25,\n    input_field_names=[\"content\"],\n    output_field_names=\"sparse_vector\",\n)\n\n# Add the function to schema\nschema.add_function(bm25_function)\n","# Define indexes\nindex_params = MilvusClient.prepare_index_params()\nindex_params.add_index(\n    field_name=\"sparse_vector\",\n    index_type=\"SPARSE_INVERTED_INDEX\",\n    metric_type=\"BM25\",\n)\nindex_params.add_index(field_name=\"dense_vector\", index_type=\"FLAT\", metric_type=\"IP\")\n\n# Drop collection if exist\nif client.has_collection(collection_name):\n    client.drop_collection(collection_name)\n# Create the collection\nclient.create_collection(\n    collection_name=collection_name,\n    schema=schema,\n    index_params=index_params,\n)\nprint(f\"Collection '{collection_name}' created successfully\")\n","# Set up OpenAI for embeddings\nopenai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\nmodel_name = \"text-embedding-3-small\"\n\n\n# Define embedding generation function for reuse\ndef get_embeddings(texts: List[str]) -> List[List[float]]:\n    if not texts:\n        return []\n\n    response = openai_client.embeddings.create(input=texts, model=model_name)\n    return [embedding.embedding for embedding in response.data]\n","# Example documents to insert\ndocuments = [\n    {\n        \"content\": \"Milvus is a vector database built for embedding similarity search and AI applications.\",\n        \"metadata\": {\"source\": \"documentation\", \"topic\": \"introduction\"},\n    },\n    {\n        \"content\": \"Full-text search in Milvus allows you to search using keywords and phrases.\",\n        \"metadata\": {\"source\": \"tutorial\", \"topic\": \"full-text search\"},\n    },\n    {\n        \"content\": \"Hybrid search combines the power of sparse BM25 retrieval with dense vector search.\",\n        \"metadata\": {\"source\": \"blog\", \"topic\": \"hybrid search\"},\n    },\n]\n\n# Prepare entities for insertion\nentities = []\ntexts = [doc[\"content\"] for doc in documents]\nembeddings = get_embeddings(texts)\n\nfor i, doc in enumerate(documents):\n    entities.append(\n        {\n            \"content\": doc[\"content\"],\n            \"dense_vector\": embeddings[i],\n            \"metadata\": doc.get(\"metadata\", {}),\n        }\n    )\n\n# Insert data\nclient.insert(collection_name, entities)\nprint(f\"Inserted {len(entities)} documents\")\n","# Example query for keyword search\nquery = \"full-text search keywords\"\n\n# BM25 sparse vectors\nresults = client.search(\n    collection_name=collection_name,\n    data=[query],\n    anns_field=\"sparse_vector\",\n    limit=5,\n    output_fields=[\"content\", \"metadata\"],\n)\nsparse_results = results[0]\n\n# Print results\nprint(\"\\nSparse Search (Full-text search):\")\nfor i, result in enumerate(sparse_results):\n    print(\n        f\"{i+1}. Score: {result['distance']:.4f}, Content: {result['entity']['content']}\"\n    )\n","# Example query for semantic search\nquery = \"How does Milvus help with similarity search?\"\n\n# Generate embedding for query\nquery_embedding = get_embeddings([query])[0]\n\n# Semantic search using dense vectors\nresults = client.search(\n    collection_name=collection_name,\n    data=[query_embedding],\n    anns_field=\"dense_vector\",\n    limit=5,\n    output_fields=[\"content\", \"metadata\"],\n)\ndense_results = results[0]\n\n# Print results\nprint(\"\\nDense Search (Semantic):\")\nfor i, result in enumerate(dense_results):\n    print(\n        f\"{i+1}. Score: {result['distance']:.4f}, Content: {result['entity']['content']}\"\n    )\n","# Example query for hybrid search\nquery = \"what is hybrid search\"\n\n# Get query embedding\nquery_embedding = get_embeddings([query])[0]\n\n# Set up BM25 search request\nsparse_search_params = {\"metric_type\": \"BM25\"}\nsparse_request = AnnSearchRequest(\n    [query], \"sparse_vector\", sparse_search_params, limit=5\n)\n\n# Set up dense vector search request\ndense_search_params = {\"metric_type\": \"IP\"}\ndense_request = AnnSearchRequest(\n    [query_embedding], \"dense_vector\", dense_search_params, limit=5\n)\n\n# Perform hybrid search with reciprocal rank fusion\nresults = client.hybrid_search(\n    collection_name,\n    [sparse_request, dense_request],\n    ranker=RRFRanker(),  # Reciprocal Rank Fusion for combining results\n    limit=5,\n    output_fields=[\"content\", \"metadata\"],\n)\nhybrid_results = results[0]\n\n# Print results\nprint(\"\\nHybrid Search (Combined):\")\nfor i, result in enumerate(hybrid_results):\n    print(\n        f\"{i+1}. Score: {result['distance']:.4f}, Content: {result['entity']['content']}\"\n    )\n","# Format retrieved documents into context\ncontext = \"\\n\\n\".join([doc[\"entity\"][\"content\"] for doc in hybrid_results])\n\n# Create prompt\nprompt = f\"\"\"Answer the following question based on the provided context. \nIf the context doesn't contain relevant information, just say \"I don't have enough information to answer this question.\"\n\nContext:\n{context}\n\nQuestion: {query}\n\nAnswer:\"\"\"\n\n# Call OpenAI API\nresponse = openai_client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant that answers questions based on the provided context.\",\n        },\n        {\"role\": \"user\", \"content\": prompt},\n    ],\n)\n\nprint(response.choices[0].message.content)\n"],"headingContent":"Full Text Search with Milvus","anchorList":[{"label":"使用 Milvus 進行全文檢索","href":"Full-Text-Search-with-Milvus","type":1,"isActive":false},{"label":"準備工作","href":"Preparation","type":2,"isActive":false},{"label":"設定與組態","href":"Setup-and-Configuration","type":2,"isActive":false},{"label":"全文檢索的合集設定","href":"Collection-Setup-for-Full-Text-Search","type":2,"isActive":false},{"label":"插入資料","href":"Insert-Data","type":2,"isActive":false},{"label":"執行擷取","href":"Perform-Retrieval","type":2,"isActive":false},{"label":"答案產生","href":"Answer-Generation","type":2,"isActive":false}]}