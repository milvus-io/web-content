---
id: evaluation_with_deepeval.md
summary: æœ¬æŒ‡å—èªªæ˜å¦‚ä½•ä½¿ç”¨ DeepEval è©•ä¼°ä»¥ Milvus ç‚ºåŸºç¤çš„ Retrieval-Augmented Generation (RAG) ç®¡é“ã€‚
title: ä½¿ç”¨ DeepEval é€²è¡Œè©•ä¼°
---
<h1 id="Evaluation-with-DeepEval" class="common-anchor-header">ä½¿ç”¨ DeepEval é€²è¡Œè©•ä¼°<button data-href="#Evaluation-with-DeepEval" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h1><p><a href="https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/integration/evaluation_with_deepeval.ipynb" target="_parent"><img translate="no" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<a href="https://github.com/milvus-io/bootcamp/blob/master/integration/evaluation_with_deepeval.ipynb" target="_blank"><img translate="no" src="https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white" alt="GitHub Repository"/></a></p>
<p>æœ¬æŒ‡å—æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨<a href="https://docs.confident-ai.com/">DeepEval</a>ä¾†è©•ä¼°å»ºç«‹åœ¨<a href="https://milvus.io/">Milvus</a> ä¸Šçš„æª¢ç´¢-å¢å¼·ç”Ÿæˆ (RAG) ç®¡é“ã€‚</p>
<p>RAG ç³»çµ±çµåˆäº†æª¢ç´¢ç³»çµ±èˆ‡ç”Ÿæˆæ¨¡å‹ï¼Œå¯æ ¹æ“šçµ¦å®šçš„æç¤ºç”Ÿæˆæ–°æ–‡å­—ã€‚è©²ç³»çµ±é¦–å…ˆä½¿ç”¨ Milvus å¾èªæ–™åº«ä¸­æª¢ç´¢ç›¸é—œæ–‡ä»¶ï¼Œç„¶å¾Œæ ¹æ“šæª¢ç´¢åˆ°çš„æ–‡ä»¶ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ç”Ÿæˆæ–°æ–‡æœ¬ã€‚</p>
<p>DeepEval æ˜¯ä¸€å€‹å¯å”åŠ©æ‚¨è©•ä¼° RAG ç®¡é“çš„æ¡†æ¶ã€‚ç¾æœ‰çš„å·¥å…·å’Œæ¡†æ¶å¯ä»¥å¹«åŠ©æ‚¨å»ºç«‹é€™äº›ç®¡é“ï¼Œä½†æ˜¯è©•ä¼°å®ƒå’Œé‡åŒ–æ‚¨çš„ç®¡é“æ•ˆèƒ½å¯èƒ½å¾ˆå›°é›£ã€‚é€™å°±æ˜¯ DeepEval çš„ç”¨æ­¦ä¹‹åœ°ã€‚</p>
<h2 id="Prerequisites" class="common-anchor-header">å…ˆæ±ºæ¢ä»¶<button data-href="#Prerequisites" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>åœ¨åŸ·è¡Œæœ¬ç­†è¨˜æœ¬ä¹‹å‰ï¼Œè«‹ç¢ºå®šæ‚¨å·²å®‰è£ä¸‹åˆ—ä¾è³´é …ç›®ï¼š</p>
<pre><code translate="no" class="language-python">$ pip install --upgrade pymilvus openai requests tqdm pandas deepeval
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ Google Colabï¼Œç‚ºäº†å•Ÿç”¨å‰›å®‰è£çš„ç›¸ä¾æ€§ï¼Œæ‚¨å¯èƒ½éœ€è¦<strong>é‡æ–°å•Ÿå‹•é‹è¡Œæ™‚</strong>ï¼ˆé»æ“Šè¢å¹•ä¸Šæ–¹çš„ã€ŒRuntimeã€åŠŸèƒ½è¡¨ï¼Œä¸¦å¾ä¸‹æ‹‰å¼åŠŸèƒ½è¡¨ä¸­é¸æ“‡ã€ŒRestart sessionã€ï¼‰ã€‚</p>
</div>
<p>åœ¨æœ¬ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ OpenAI ä½œç‚º LLMã€‚æ‚¨æ‡‰è©²æº–å‚™<a href="https://platform.openai.com/docs/quickstart">api key</a> <code translate="no">OPENAI_API_KEY</code> ä½œç‚ºç’°å¢ƒè®Šæ•¸ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> os

os.environ[<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="hljs-string">&quot;sk-*****************&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<h2 id="Define-the-RAG-pipeline" class="common-anchor-header">å®šç¾© RAG ç®¡é“<button data-href="#Define-the-RAG-pipeline" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>æˆ‘å€‘å°‡å®šç¾©ä»¥ Milvus ä½œç‚ºå‘é‡å„²å­˜ã€OpenAI ä½œç‚º LLM çš„ RAG é¡ã€‚è©²é¡åŒ…å«<code translate="no">load</code> æ–¹æ³• (å°‡æ–‡å­—è³‡æ–™è¼‰å…¥ Milvus)ã€<code translate="no">retrieve</code> æ–¹æ³• (æ“·å–èˆ‡çµ¦å®šå•é¡Œæœ€ç›¸ä¼¼çš„æ–‡å­—è³‡æ–™)ï¼Œä»¥åŠ<code translate="no">answer</code> æ–¹æ³• (ä½¿ç”¨æ“·å–çš„çŸ¥è­˜å›ç­”çµ¦å®šå•é¡Œ)ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient


<span class="hljs-keyword">class</span> <span class="hljs-title class_">RAG</span>:
    <span class="hljs-string">&quot;&quot;&quot;
    RAG(Retrieval-Augmented Generation) class built upon OpenAI and Milvus.
    &quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, openai_client: OpenAI, milvus_client: MilvusClient</span>):
        <span class="hljs-variable language_">self</span>._prepare_openai(openai_client)
        <span class="hljs-variable language_">self</span>._prepare_milvus(milvus_client)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_emb_text</span>(<span class="hljs-params">self, text: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">float</span>]:
        <span class="hljs-keyword">return</span> (
            <span class="hljs-variable language_">self</span>.openai_client.embeddings.create(<span class="hljs-built_in">input</span>=text, model=<span class="hljs-variable language_">self</span>.embedding_model)
            .data[<span class="hljs-number">0</span>]
            .embedding
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_prepare_openai</span>(<span class="hljs-params">
        self,
        openai_client: OpenAI,
        embedding_model: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;text-embedding-3-small&quot;</span>,
        llm_model: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;gpt-4o-mini&quot;</span>,
    </span>):
        <span class="hljs-variable language_">self</span>.openai_client = openai_client
        <span class="hljs-variable language_">self</span>.embedding_model = embedding_model
        <span class="hljs-variable language_">self</span>.llm_model = llm_model
        <span class="hljs-variable language_">self</span>.SYSTEM_PROMPT = <span class="hljs-string">&quot;&quot;&quot;
            Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.
        &quot;&quot;&quot;</span>
        <span class="hljs-variable language_">self</span>.USER_PROMPT = <span class="hljs-string">&quot;&quot;&quot;
            Use the following pieces of information enclosed in &lt;context&gt; tags to provide an answer to the question enclosed in &lt;question&gt; tags.
            &lt;context&gt;
            {context}
            &lt;/context&gt;
            &lt;question&gt;
            {question}
            &lt;/question&gt;
        &quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_prepare_milvus</span>(<span class="hljs-params">
        self, milvus_client: MilvusClient, collection_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;rag_collection&quot;</span>
    </span>):
        <span class="hljs-variable language_">self</span>.milvus_client = milvus_client
        <span class="hljs-variable language_">self</span>.collection_name = collection_name
        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.milvus_client.has_collection(<span class="hljs-variable language_">self</span>.collection_name):
            <span class="hljs-variable language_">self</span>.milvus_client.drop_collection(<span class="hljs-variable language_">self</span>.collection_name)
        embedding_dim = <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>._emb_text(<span class="hljs-string">&quot;demo&quot;</span>))
        <span class="hljs-variable language_">self</span>.milvus_client.create_collection(
            collection_name=<span class="hljs-variable language_">self</span>.collection_name,
            dimension=embedding_dim,
            metric_type=<span class="hljs-string">&quot;IP&quot;</span>,
            consistency_level=<span class="hljs-string">&quot;Bounded&quot;</span>,  <span class="hljs-comment"># Supported values are (`&quot;Strong&quot;`, `&quot;Session&quot;`, `&quot;Bounded&quot;`, `&quot;Eventually&quot;`). See https://milvus.io/docs/consistency.md#Consistency-Level for more details.</span>
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load</span>(<span class="hljs-params">self, texts: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):
        <span class="hljs-string">&quot;&quot;&quot;
        Load the text data into Milvus.
        &quot;&quot;&quot;</span>
        data = []
        <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(texts, desc=<span class="hljs-string">&quot;Creating embeddings&quot;</span>)):
            data.append({<span class="hljs-string">&quot;id&quot;</span>: i, <span class="hljs-string">&quot;vector&quot;</span>: <span class="hljs-variable language_">self</span>._emb_text(line), <span class="hljs-string">&quot;text&quot;</span>: line})
        <span class="hljs-variable language_">self</span>.milvus_client.insert(collection_name=<span class="hljs-variable language_">self</span>.collection_name, data=data)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">retrieve</span>(<span class="hljs-params">self, question: <span class="hljs-built_in">str</span>, top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:
        <span class="hljs-string">&quot;&quot;&quot;
        Retrieve the most similar text data to the given question.
        &quot;&quot;&quot;</span>
        search_res = <span class="hljs-variable language_">self</span>.milvus_client.search(
            collection_name=<span class="hljs-variable language_">self</span>.collection_name,
            data=[<span class="hljs-variable language_">self</span>._emb_text(question)],
            limit=top_k,
            search_params={<span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;IP&quot;</span>, <span class="hljs-string">&quot;params&quot;</span>: {}},  <span class="hljs-comment"># inner product distance</span>
            output_fields=[<span class="hljs-string">&quot;text&quot;</span>],  <span class="hljs-comment"># Return the text field</span>
        )
        retrieved_texts = [res[<span class="hljs-string">&quot;entity&quot;</span>][<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> res <span class="hljs-keyword">in</span> search_res[<span class="hljs-number">0</span>]]
        <span class="hljs-keyword">return</span> retrieved_texts[:top_k]

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">answer</span>(<span class="hljs-params">
        self,
        question: <span class="hljs-built_in">str</span>,
        retrieval_top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span>,
        return_retrieved_text: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,
    </span>):
        <span class="hljs-string">&quot;&quot;&quot;
        Answer the given question with the retrieved knowledge.
        &quot;&quot;&quot;</span>
        retrieved_texts = <span class="hljs-variable language_">self</span>.retrieve(question, top_k=retrieval_top_k)
        user_prompt = <span class="hljs-variable language_">self</span>.USER_PROMPT.<span class="hljs-built_in">format</span>(
            context=<span class="hljs-string">&quot;\n&quot;</span>.join(retrieved_texts), question=question
        )
        response = <span class="hljs-variable language_">self</span>.openai_client.chat.completions.create(
            model=<span class="hljs-variable language_">self</span>.llm_model,
            messages=[
                {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-variable language_">self</span>.SYSTEM_PROMPT},
                {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: user_prompt},
            ],
        )
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> return_retrieved_text:
            <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> response.choices[<span class="hljs-number">0</span>].message.content, retrieved_texts
<button class="copy-code-btn"></button></code></pre>
<p>è®“æˆ‘å€‘ç”¨ OpenAI å’Œ Milvus å®¢æˆ¶ç«¯åˆå§‹åŒ– RAG é¡åˆ¥ã€‚</p>
<pre><code translate="no" class="language-python">openai_client = OpenAI()
milvus_client = MilvusClient(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>)

my_rag = RAG(openai_client=openai_client, milvus_client=milvus_client)
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>è‡³æ–¼<code translate="no">MilvusClient</code> çš„åƒæ•¸ ï¼š</p>
<ul>
<li>å°‡<code translate="no">uri</code> è¨­å®šç‚ºæœ¬æ©Ÿæª”æ¡ˆï¼Œä¾‹å¦‚<code translate="no">./milvus.db</code> ï¼Œæ˜¯æœ€æ–¹ä¾¿çš„æ–¹æ³•ï¼Œå› ç‚ºå®ƒæœƒè‡ªå‹•åˆ©ç”¨<a href="https://milvus.io/docs/milvus_lite.md">Milvus Lite</a>å°‡æ‰€æœ‰è³‡æ–™å„²å­˜åœ¨é€™å€‹æª”æ¡ˆä¸­ã€‚</li>
<li>å¦‚æœæ‚¨æœ‰å¤§è¦æ¨¡çš„è³‡æ–™ï¼Œæ‚¨å¯ä»¥åœ¨<a href="https://milvus.io/docs/quickstart.md">docker æˆ– kubernetes</a> ä¸Šæ¶è¨­æ•ˆèƒ½æ›´é«˜çš„ Milvus ä¼ºæœå™¨ã€‚åœ¨æ­¤è¨­å®šä¸­ï¼Œè«‹ä½¿ç”¨ä¼ºæœå™¨çš„ uriï¼Œä¾‹å¦‚<code translate="no">http://localhost:19530</code> ï¼Œä½œç‚ºæ‚¨çš„<code translate="no">uri</code> ã€‚</li>
<li>å¦‚æœæ‚¨æƒ³ä½¿ç”¨<a href="https://zilliz.com/cloud">Zilliz Cloud</a>ï¼ˆMilvus çš„å®Œå…¨ç®¡ç†<a href="https://docs.zilliz.com/docs/on-zilliz-cloud-console#free-cluster-details">é›²ç«¯</a>æœå‹™ï¼‰ï¼Œè«‹èª¿æ•´<code translate="no">uri</code> å’Œ<code translate="no">token</code> ï¼Œèˆ‡ Zilliz Cloud ä¸­çš„<a href="https://docs.zilliz.com/docs/on-zilliz-cloud-console#free-cluster-details">Public Endpoint å’Œ Api key</a>å°æ‡‰ã€‚</li>
</ul>
</div>
<h2 id="Run-the-RAG-pipeline-and-get-results" class="common-anchor-header">åŸ·è¡Œ RAG ç®¡é“ä¸¦ç²å¾—çµæœ<button data-href="#Run-the-RAG-pipeline-and-get-results" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>æˆ‘å€‘ä½¿ç”¨<a href="https://github.com/milvus-io/milvus/blob/master/DEVELOPMENT.md">Milvus é–‹ç™¼æŒ‡å—</a>ä½œç‚º RAG ä¸­çš„ç§æœ‰çŸ¥è­˜ï¼Œé€™æ˜¯ç°¡å–® RAG ç®¡é“çš„è‰¯å¥½è³‡æ–™ä¾†æºã€‚</p>
<p>ä¸‹è¼‰ä¸¦è¼‰å…¥ RAG ç®¡é“ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> urllib.request
<span class="hljs-keyword">import</span> os

url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/milvus-io/milvus/master/DEVELOPMENT.md&quot;</span>
file_path = <span class="hljs-string">&quot;./Milvus_DEVELOPMENT.md&quot;</span>

<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(file_path):
    urllib.request.urlretrieve(url, file_path)
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> file:
    file_text = file.read()

text_lines = file_text.split(<span class="hljs-string">&quot;# &quot;</span>)
my_rag.load(text_lines)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">Creating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:20&lt;00:00,  2.26it/s]
</code></pre>
<p>è®“æˆ‘å€‘å®šç¾©ä¸€å€‹é—œæ–¼é–‹ç™¼æŒ‡å—æ–‡ä»¶å…§å®¹çš„æŸ¥è©¢å•é¡Œã€‚ç„¶å¾Œä½¿ç”¨<code translate="no">answer</code> æ–¹æ³•å–å¾—ç­”æ¡ˆå’Œæ“·å–çš„ä¸Šä¸‹æ–‡æ–‡å­—ã€‚</p>
<pre><code translate="no" class="language-python">question = <span class="hljs-string">&quot;what is the hardware requirements specification if I want to build Milvus and run from source code?&quot;</span>
my_rag.answer(question, return_retrieved_text=<span class="hljs-literal">True</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">('The hardware requirements specification to build and run Milvus from source code is as follows:\n\n- 8GB of RAM\n- 50GB of free disk space',
 ['Hardware Requirements\n\nThe following specification (either physical or virtual machine resources) is recommended for Milvus to build and run from source code.\n\n```\n- 8GB of RAM\n- 50GB of free disk space\n```\n\n##',
  'Building Milvus on a local OS/shell environment\n\nThe details below outline the hardware and software requirements for building on Linux and MacOS.\n\n##',
  &quot;Software Requirements\n\nAll Linux distributions are available for Milvus development. However a majority of our contributor worked with Ubuntu or CentOS systems, with a small portion of Mac (both x86_64 and Apple Silicon) contributors. If you would like Milvus to build and run on other distributions, you are more than welcome to file an issue and contribute!\n\nHere's a list of verified OS types where Milvus can successfully build and run:\n\n- Debian/Ubuntu\n- Amazon Linux\n- MacOS (x86_64)\n- MacOS (Apple Silicon)\n\n##&quot;])
</code></pre>
<p>ç¾åœ¨è®“æˆ‘å€‘æº–å‚™ä¸€äº›å•é¡Œèˆ‡å…¶ç›¸å°æ‡‰çš„åœ°é¢çœŸå¯¦ç­”æ¡ˆã€‚æˆ‘å€‘å¾ RAG ç®¡é“å–å¾—ç­”æ¡ˆå’Œä¸Šä¸‹æ–‡ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

question_list = [
    <span class="hljs-string">&quot;what is the hardware requirements specification if I want to build Milvus and run from source code?&quot;</span>,
    <span class="hljs-string">&quot;What is the programming language used to write Knowhere?&quot;</span>,
    <span class="hljs-string">&quot;What should be ensured before running code coverage?&quot;</span>,
]
ground_truth_list = [
    <span class="hljs-string">&quot;If you want to build Milvus and run from source code, the recommended hardware requirements specification is:\n\n- 8GB of RAM\n- 50GB of free disk space.&quot;</span>,
    <span class="hljs-string">&quot;The programming language used to write Knowhere is C++.&quot;</span>,
    <span class="hljs-string">&quot;Before running code coverage, you should make sure that your code changes are covered by unit tests.&quot;</span>,
]
contexts_list = []
answer_list = []
<span class="hljs-keyword">for</span> question <span class="hljs-keyword">in</span> tqdm(question_list, desc=<span class="hljs-string">&quot;Answering questions&quot;</span>):
    answer, contexts = my_rag.answer(question, return_retrieved_text=<span class="hljs-literal">True</span>)
    contexts_list.append(contexts)
    answer_list.append(answer)

df = pd.DataFrame(
    {
        <span class="hljs-string">&quot;question&quot;</span>: question_list,
        <span class="hljs-string">&quot;contexts&quot;</span>: contexts_list,
        <span class="hljs-string">&quot;answer&quot;</span>: answer_list,
        <span class="hljs-string">&quot;ground_truth&quot;</span>: ground_truth_list,
    }
)
rag_results = Dataset.from_pandas(df)
df
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">/Users/eureka/miniconda3/envs/zilliz/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
Answering questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03&lt;00:00,  1.06s/it]
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type { vertical-align: middle; }<pre><code translate="no">.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>å•é¡Œ</th>
      <th>ä¸Šä¸‹æ–‡</th>
      <th>ç­”æ¡ˆ</th>
      <th>åœ°é¢çœŸç›¸</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ä»€éº¼æ˜¯ç¡¬é«”éœ€æ±‚è¦æ ¼ï¼Ÿ</td>
      <td>[Hardware Requirements/ç¡¬é«”éœ€æ±‚è¦æ ¼]ä»¥ä¸‹ç‚ºç¡¬é«”éœ€æ±‚è¦æ ¼...</td>
      <td>ç¡¬é«”éœ€æ±‚è¦æ ¼æ˜¯ä»€éº¼ï¼Ÿ</td>
      <td>å¦‚æœæ‚¨æƒ³å»ºç«‹ Milvus ä¸¦å¾ä¾†æºåŸ·è¡Œ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ç”¨ä»€éº¼ç·¨ç¨‹èªè¨€ä¾†å¯«...</td>
      <td>[CMake &amp; Conan\n\nMilvus çš„æ¼”ç®—æ³•å‡½å¼åº«...</td>
      <td>ç·¨å¯« Knowherus çš„ç¨‹å¼èªè¨€æ˜¯...</td>
      <td>ç”¨ä¾†ç·¨å¯« Knowher...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>åœ¨é‹è¡Œä»£ç¢¼è¦†è“‹ä¹‹å‰æ‡‰ç¢ºä¿å“ªäº›...</td>
      <td>[Code coverage\n/nBefore submitting your pull ...</td>
      <td>åœ¨åŸ·è¡Œç¨‹å¼ç¢¼è¦†è“‹ä¹‹å‰ï¼Œæ‡‰è©²ç¢ºä¿...</td>
      <td>åœ¨åŸ·è¡Œç¨‹å¼ç¢¼è¦†è“‹ä¹‹å‰ï¼Œæ‚¨æ‡‰è©²ç¢ºä¿ ...</td>
    </tr>
  </tbody>
</table>
</div>
<h2 id="Evaluating-Retriever" class="common-anchor-header">è©•ä¼° Retriever<button data-href="#Evaluating-Retriever" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>åœ¨è©•ä¼°å¤§å‹èªè¨€æ¨¡å‹ (LLM) ç³»çµ±ä¸­çš„ Retriever æ™‚ï¼Œè©•ä¼°ä»¥ä¸‹å¹¾é»è‡³é—œé‡è¦ï¼š</p>
<ol>
<li><p><strong>æ’åºç›¸é—œæ€§</strong>ï¼šretrieverå¦‚ä½•æœ‰æ•ˆåœ°å°‡ç›¸é—œè³‡è¨Šå„ªå…ˆæ–¼ä¸ç›¸é—œçš„è³‡æ–™ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡æ“·å–</strong>ï¼šæ ¹æ“šè¼¸å…¥æ“·å–èˆ‡æ“·å–ä¸Šä¸‹æ–‡ç›¸é—œè³‡è¨Šçš„èƒ½åŠ›ã€‚</p></li>
<li><p><strong>å¹³è¡¡æ€§</strong>ï¼šæ“·å–å·¥å…·å¦‚ä½•æœ‰æ•ˆç®¡ç†æ–‡å­—å€å¡Šå¤§å°èˆ‡æ“·å–ç¯„åœï¼Œä»¥æ¸›å°‘ä¸ç›¸é—œæ€§ã€‚</p></li>
</ol>
<p>é€™äº›å› ç´ åˆåœ¨ä¸€èµ·ï¼Œæä¾›äº†å°æª¢ç´¢å™¨å¦‚ä½•æ’å®šå„ªå…ˆé †åºã€æ“·å–å’Œå‘ˆç¾æœ€æœ‰ç”¨è³‡è¨Šçš„å…¨é¢ç­è§£ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> deepeval.metrics <span class="hljs-keyword">import</span> (
    ContextualPrecisionMetric,
    ContextualRecallMetric,
    ContextualRelevancyMetric,
)
<span class="hljs-keyword">from</span> deepeval.test_case <span class="hljs-keyword">import</span> LLMTestCase
<span class="hljs-keyword">from</span> deepeval <span class="hljs-keyword">import</span> evaluate

contextual_precision = ContextualPrecisionMetric()
contextual_recall = ContextualRecallMetric()
contextual_relevancy = ContextualRelevancyMetric()

test_cases = []

<span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> df.iterrows():
    test_case = LLMTestCase(
        <span class="hljs-built_in">input</span>=row[<span class="hljs-string">&quot;question&quot;</span>],
        actual_output=row[<span class="hljs-string">&quot;answer&quot;</span>],
        expected_output=row[<span class="hljs-string">&quot;ground_truth&quot;</span>],
        retrieval_context=row[<span class="hljs-string">&quot;contexts&quot;</span>],
    )
    test_cases.append(test_case)

<span class="hljs-comment"># test_cases</span>
result = evaluate(
    test_cases=test_cases,
    metrics=[contextual_precision, contextual_recall, contextual_relevancy],
    print_results=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># Change to True to see detailed metric results</span>
)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">/Users/eureka/miniconda3/envs/zilliz/lib/python3.9/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.1.6, however version 1.2.2 is available. You should consider upgrading via the &quot;pip install --upgrade deepeval&quot; command.
  warnings.warn(
</code></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">æ‚¨æ­£åœ¨åŸ·è¡Œ DeepEval æœ€æ–°çš„<span style="color: #6a00ff; text-decoration-color: #6a00ff">Contextual Precision Metric</span>ï¼<span style="color: #374151; text-decoration-color: #374151">(ä½¿ç”¨ gpt-4oã€ </span><span style="color: #374151; text-decoration-color: #374151">strict=</span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">False</span><span style="color: #374151; text-decoration-color: #374151">ã€ </span><span style="color: #374151; text-decoration-color: #374151">async_mode=</span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">True</span><span style="color: #374151; text-decoration-color: #374151; font-weight: bold">ï¼‰</span><span style="color: #374151; text-decoration-color: #374151">..</span><span style="color: #374151; text-decoration-color: #374151">.</span></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">âœ¨ æ‚¨æ­£åœ¨é‹è¡Œ DeepEval æœ€æ–°çš„<span style="color: #6a00ff; text-decoration-color: #6a00ff">Contextual Recall Metric</span>ï¼<span style="color: #374151; text-decoration-color: #374151">(ä½¿ç”¨ gpt-4oï¼Œ </span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">strict</span><span style="color: #374151; text-decoration-color: #374151">=False</span><span style="color: #374151; text-decoration-color: #374151">ï¼Œ </span><span style="color: #374151; text-decoration-color: #374151">async</span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">_</span><span style="color: #374151; text-decoration-color: #374151">mode=True</span><span style="color: #374151; text-decoration-color: #374151; font-weight: bold">ï¼‰</span><span style="color: #374151; text-decoration-color: #374151">..</span><span style="color: #374151; text-decoration-color: #374151">.</span></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">âœ¨ æ‚¨æ­£åœ¨åŸ·è¡Œ DeepEval æœ€æ–°çš„<span style="color: #6a00ff; text-decoration-color: #6a00ff">Contextual Relevancy Metric</span>ï¼<span style="color: #374151; text-decoration-color: #374151; font-weight: bold">(</span><span style="color: #374151; text-decoration-color: #374151">using gpt-4o, </span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">strict=False</span><span style="color: #374151; text-decoration-color: #374151">, </span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">async_mode=True</span><span style="color: #374151; text-decoration-color: #374151; font-weight: bold">)</span><span style="color: #374151; text-decoration-color: #374151">...</span></pre>
<pre><code translate="no">Event loop is already running. Applying nest_asyncio patch to allow async execution...


Evaluating 3 test case(s) in parallel: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|100% (3/3) [Time Taken: 00:11,  3.91s/test case]
</code></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #05f58d; text-decoration-color: #05f58d">âœ“</span>æ¸¬è©¦å®Œæˆ ğŸ‰ï¼åŸ·è¡Œ<span style="color: #008000; text-decoration-color: #008000">ã€Œdeepeval loginã€</span>ä»¥æª¢è¦– Confident AI çš„è©•ä¼°çµæœã€‚ 
â€¼ï¸ æ³¨æ„ï¼šæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ Confident AI ä¸Šå° deepeval çš„æ‰€æœ‰æŒ‡æ¨™åŸ·è¡Œè©•ä¼°ã€‚</pre>
<h2 id="Evaluating-Generation" class="common-anchor-header">è©•ä¼°ç”Ÿæˆ<button data-href="#Evaluating-Generation" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>è¦è©•ä¼°å¤§å‹èªè¨€æ¨¡å‹ (LLM) ä¸­ç”Ÿæˆè¼¸å‡ºçš„å“è³ªï¼Œå¿…é ˆè‘—é‡æ–¼å…©å€‹é—œéµæ–¹é¢ï¼š</p>
<ol>
<li><p><strong>ç›¸é—œæ€§</strong>ï¼šè©•ä¼°æç¤ºæ˜¯å¦æœ‰æ•ˆåœ°å¼•å° LLM ç”¢ç”Ÿæœ‰ç”¨ä¸”ç¬¦åˆä¸Šä¸‹æ–‡çš„å›æ‡‰ã€‚</p></li>
<li><p><strong>å¿ å¯¦æ€§</strong>ï¼šæ¸¬é‡è¼¸å‡ºçš„æº–ç¢ºæ€§ï¼Œç¢ºä¿æ¨¡å‹ç”¢ç”Ÿçš„è³‡è¨Šèˆ‡äº‹å¯¦ç›¸ç¬¦ï¼Œæ²’æœ‰å¹»è¦ºæˆ–çŸ›ç›¾ã€‚ç”¢ç”Ÿçš„å…§å®¹æ‡‰èˆ‡æª¢ç´¢ä¸Šä¸‹æ–‡ä¸­æä¾›çš„äº‹å¯¦è³‡è¨Šä¸€è‡´ã€‚</p></li>
</ol>
<p>é€™äº›å› ç´ å…±åŒç¢ºä¿è¼¸å‡ºå…§å®¹æ—¢ç›¸é—œåˆå¯é ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> deepeval.metrics <span class="hljs-keyword">import</span> AnswerRelevancyMetric, FaithfulnessMetric
<span class="hljs-keyword">from</span> deepeval.test_case <span class="hljs-keyword">import</span> LLMTestCase
<span class="hljs-keyword">from</span> deepeval <span class="hljs-keyword">import</span> evaluate

answer_relevancy = AnswerRelevancyMetric()
faithfulness = FaithfulnessMetric()

test_cases = []

<span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> df.iterrows():
    test_case = LLMTestCase(
        <span class="hljs-built_in">input</span>=row[<span class="hljs-string">&quot;question&quot;</span>],
        actual_output=row[<span class="hljs-string">&quot;answer&quot;</span>],
        expected_output=row[<span class="hljs-string">&quot;ground_truth&quot;</span>],
        retrieval_context=row[<span class="hljs-string">&quot;contexts&quot;</span>],
    )
    test_cases.append(test_case)

<span class="hljs-comment"># test_cases</span>
result = evaluate(
    test_cases=test_cases,
    metrics=[answer_relevancy, faithfulness],
    print_results=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># Change to True to see detailed metric results</span>
)
<button class="copy-code-btn"></button></code></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">âœ¨ æ‚¨æ­£åœ¨é‹è¡Œ DeepEval æœ€æ–°çš„<span style="color: #6a00ff; text-decoration-color: #6a00ff">ç­”æ¡ˆç›¸é—œåº¦æŒ‡æ¨™</span>ï¼<span style="color: #374151; text-decoration-color: #374151">(ä½¿ç”¨ gpt-4oï¼Œ </span><span style="color: #374151; text-decoration-color: #374151">strict=</span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">False</span><span style="color: #374151; text-decoration-color: #374151">ï¼Œ </span><span style="color: #374151; text-decoration-color: #374151">async_mode=</span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">True</span><span style="color: #374151; text-decoration-color: #374151; font-weight: bold">ï¼‰</span><span style="color: #374151; text-decoration-color: #374151">..</span><span style="color: #374151; text-decoration-color: #374151">.</span></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">âœ¨ æ‚¨æ­£åœ¨åŸ·è¡Œ DeepEval æœ€æ–°çš„<span style="color: #6a00ff; text-decoration-color: #6a00ff">å¿ èª åº¦å…¬åˆ¶</span>ï¼<span style="color: #374151; text-decoration-color: #374151; font-weight: bold">(</span><span style="color: #374151; text-decoration-color: #374151">using gpt-4o, </span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">strict=False</span><span style="color: #374151; text-decoration-color: #374151">, </span><span style="color: #374151; text-decoration-color: #374151; font-style: italic">async_mode=True</span><span style="color: #374151; text-decoration-color: #374151; font-weight: bold">)</span><span style="color: #374151; text-decoration-color: #374151">...</span></pre>
<pre><code translate="no">Event loop is already running. Applying nest_asyncio patch to allow async execution...


Evaluating 3 test case(s) in parallel: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|100% (3/3) [Time Taken: 00:11,  3.97s/test case]
</code></pre>
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #05f58d; text-decoration-color: #05f58d">âœ“</span>æ¸¬è©¦å®Œæˆ ğŸ‰ï¼åŸ·è¡Œ<span style="color: #008000; text-decoration-color: #008000">ã€Œdeepeval loginã€</span>ä»¥æª¢è¦– Confident AI çš„è©•ä¼°çµæœã€‚ 
â€¼ï¸ æ³¨æ„ï¼šæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ Confident AI ä¸Šå° deepeval çš„æ‰€æœ‰æŒ‡æ¨™åŸ·è¡Œè©•ä¼°ã€‚</pre>
