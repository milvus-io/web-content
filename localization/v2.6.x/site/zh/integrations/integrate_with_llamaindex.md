---
id: integrate_with_llamaindex.md
summary: 本指南演示了如何使用 LlamaIndex 和 Milvus 建立检索增强生成（RAG）系统。
title: 使用 Milvus 和 LlamaIndex 的检索增强生成（RAG）
---
<h1 id="Retrieval-Augmented-Generation-RAG-with-Milvus-and-LlamaIndex" class="common-anchor-header">使用 Milvus 和 LlamaIndex 的检索增强生成（RAG）<button data-href="#Retrieval-Augmented-Generation-RAG-with-Milvus-and-LlamaIndex" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h1><p><a href="https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/integration/rag_with_milvus_and_llamaindex.ipynb" target="_parent"><img translate="no" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<a href="https://github.com/milvus-io/bootcamp/blob/master/integration/rag_with_milvus_and_llamaindex.ipynb" target="_blank"><img translate="no" src="https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white" alt="GitHub Repository"/></a></p>
<p>本指南演示了如何使用 LlamaIndex 和 Milvus 构建检索-增强生成（RAG）系统。</p>
<p>RAG 系统结合了检索系统和生成模型，可根据给定提示生成新文本。该系统首先使用 Milvus 从语料库中检索相关文档，然后使用生成模型根据检索到的文档生成新文本。</p>
<p><a href="https://www.llamaindex.ai/">LlamaIndex</a>是一个简单、灵活的数据框架，用于将自定义数据源连接到大型语言模型（LLMs）。<a href="https://milvus.io/">Milvus</a>是世界上最先进的开源向量数据库，专为支持嵌入式相似性搜索和人工智能应用而构建。</p>
<p>在本笔记本中，我们将快速演示如何使用 MilvusVectorStore。</p>
<h2 id="Before-you-begin" class="common-anchor-header">开始之前<button data-href="#Before-you-begin" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Install-dependencies" class="common-anchor-header">安装依赖项</h3><p>本页面上的代码片段需要 pymilvus 和 llamaindex 依赖项。您可以使用以下命令安装它们：</p>
<pre><code translate="no" class="language-python">$ pip install pymilvus&gt;=<span class="hljs-number">2.4</span><span class="hljs-number">.2</span>
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-python">$ pip install llama-index-vector-stores-milvus
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-python">$ pip install llama-index
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>如果使用的是 Google Colab，要启用刚刚安装的依赖项，可能需要<strong>重新启动运行时</strong>。(点击屏幕上方的 "Runtime（运行时）"菜单，从下拉菜单中选择 "Restart session（重新启动会话）"）。</p>
</div>
<h3 id="Setup-OpenAI" class="common-anchor-header">设置 OpenAI</h3><p>首先让我们添加 openai api 密钥。这将允许我们访问 chatgpt。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> openai

openai.api_key = <span class="hljs-string">&quot;sk-***********&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<h3 id="Prepare-data" class="common-anchor-header">准备数据</h3><p>您可以使用以下命令下载样本数据：</p>
<pre><code translate="no" class="language-python">! mkdir -p <span class="hljs-string">&#x27;data/&#x27;</span>
! wget <span class="hljs-string">&#x27;https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt&#x27;</span> -O <span class="hljs-string">&#x27;data/paul_graham_essay.txt&#x27;</span>
! wget <span class="hljs-string">&#x27;https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf&#x27;</span> -O <span class="hljs-string">&#x27;data/uber_2021.pdf&#x27;</span>
<button class="copy-code-btn"></button></code></pre>
<h2 id="Getting-Started" class="common-anchor-header">开始<button data-href="#Getting-Started" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Generate-our-data" class="common-anchor-header">生成数据</h3><p>作为第一个例子，让我们从文件<code translate="no">paul_graham_essay.txt</code> 中生成一个文档。这是保罗-格雷厄姆（Paul Graham）的一篇题为<code translate="no">What I Worked On</code> 的文章。我们将使用 SimpleDirectoryReader 生成文档。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> SimpleDirectoryReader

<span class="hljs-comment"># load documents</span>
documents = SimpleDirectoryReader(
    input_files=[<span class="hljs-string">&quot;./data/paul_graham_essay.txt&quot;</span>]
).load_data()

<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Document ID:&quot;</span>, documents[<span class="hljs-number">0</span>].doc_id)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">Document ID: 95f25e4d-f270-4650-87ce-006d69d82033
</code></pre>
<h3 id="Create-an-index-across-the-data" class="common-anchor-header">创建数据索引</h3><p>现在我们有了文档，可以创建索引并插入文档。对于索引，我们将使用 MilvusVectorStore。MilvusVectorStore 需要几个参数：</p>
<h4 id="basic-args" class="common-anchor-header">基本参数</h4><ul>
<li><code translate="no">uri (str, optional)</code>:要连接的 URI，对于 Milvus 或 Zilliz Cloud 服务，其形式为 "https://address:port"；对于本地的精简版 Milvus，其形式为 "path/to/local/milvus.db"。默认为"./milvus_llamaindex.db"。</li>
<li><code translate="no">token (str, optional)</code>:登录令牌。不使用 rbac 时为空，使用 rbac 时很可能是 "username:password"。</li>
<li><code translate="no">collection_name (str, optional)</code>:用于存储数据的 Collection 的名称。默认为 "llamalection"。</li>
<li><code translate="no">overwrite (bool, optional)</code>:是否覆盖同名的现有 Collection。默认为 "假"。</li>
</ul>
<h4 id="scalar-fields-including-doc-id--text" class="common-anchor-header">标量字段，包括 doc id 和文本</h4><ul>
<li><code translate="no">doc_id_field (str, optional)</code>:Collections 的 doc_id 字段名称。默认为 DEFAULT_DOC_ID_KEY。</li>
<li><code translate="no">text_key (str, optional)</code>:在传递的 Collections 中存储什么键文本。在使用自己的 Collections 时使用。默认为 DEFAULT_TEXT_KEY。</li>
<li><code translate="no">scalar_field_names (list, optional)</code>:要包含在 Collections Schema 中的额外标量字段的名称。</li>
<li><code translate="no">scalar_field_types (list, optional)</code>:额外标量字段的类型。</li>
</ul>
<h4 id="dense-field" class="common-anchor-header">密集字段</h4><ul>
<li><code translate="no">enable_dense (bool)</code>:布尔标志，用于启用或禁用密集嵌入。默认为 True。</li>
<li><code translate="no">dim (int, optional)</code>:Collections 的嵌入向量维度。创建新 Collections 时必须使用，且 enable_sparse 为 False。</li>
<li><code translate="no">embedding_field (str, optional)</code>:Collections 的密集嵌入字段名称，默认为 DEFAULT_EMBEDDING_KEY。</li>
<li><code translate="no">index_config (dict, optional)</code>:用于构建密集嵌入索引的配置。默认为 "无"。</li>
<li><code translate="no">search_config (dict, optional)</code>:用于搜索 Milvus 密集索引的配置。注意必须与<code translate="no">index_config</code> 指定的索引类型兼容。默认为无。</li>
<li><code translate="no">similarity_metric (str, optional)</code>:用于高密度 Embeddings 的相似度量，目前支持 IP、COSINE 和 L2。</li>
</ul>
<h4 id="sparse-field" class="common-anchor-header">稀疏字段</h4><ul>
<li><code translate="no">enable_sparse (bool)</code>:布尔标志，用于启用或禁用稀疏嵌入。默认为假。</li>
<li><code translate="no">sparse_embedding_field (str)</code>:稀疏嵌入字段的名称，默认为 DEFAULT_SPARSE_EMBEDDING_KEY。</li>
<li><code translate="no">sparse_embedding_function (Union[BaseSparseEmbeddingFunction, BaseMilvusBuiltInFunction], optional)</code>:如果 enable_sparse 为 True，则应提供此对象将文本转换为稀疏嵌入。如果为 None，将使用默认的稀疏嵌入函数（BGEM3SparseEmbeddingFunction）。</li>
<li><code translate="no">sparse_index_config (dict, optional)</code>:用于构建稀疏嵌入索引的配置。默认为 "无"。</li>
</ul>
<h4 id="hybrid-ranker" class="common-anchor-header">混合排序器</h4><ul>
<li><p><code translate="no">hybrid_ranker (str)</code>:指定混合搜索查询中使用的排名器类型。目前只支持 ["RRFRanker", "WeightedRanker"]。默认为 "RRFRanker"。</p></li>
<li><p><code translate="no">hybrid_ranker_params (dict, optional)</code>:混合排名器的配置参数。该字典的结构取决于所使用的特定排名器：</p>
<ul>
<li>对于 "RRFRanker"，它应包括<ul>
<li>"k"（int）：互易排序融合（RRF）中使用的参数。该值用于计算 RRF 算法中的排名分数，该算法将多种排名策略合并为一个分数，以提高搜索相关性。</li>
</ul></li>
<li>对于 "WeightedRanker"（加权排名器），它的期望值是<ul>
<li>"权重"（浮点数列表）：一个包含两个权重的列表：<ol>
<li>密集嵌入组件的权重。</li>
<li>稀疏嵌入成分的权重。 这些权重用于调整混合检索过程中嵌入的密集和稀疏成分的重要性。 默认为空字典，这意味着排名器将以其预定义的默认设置进行操作。</li>
</ol></li>
</ul></li>
</ul></li>
</ul>
<h4 id="others" class="common-anchor-header">其他</h4><ul>
<li><code translate="no">collection_properties (dict, optional)</code>:Collections 属性，如 TTL（生存时间）和 MMAP（内存映射）。默认为 "无"。可以包括<ul>
<li>"collection.ttl.seconds"（int）：设置此属性后，当前 Collections 中的数据将在指定时间内过期。Collection 中过期的数据将被清理，不会参与搜索或查询。</li>
<li>"mmap.enabled"（bool）：是否在 Collections 级别启用内存映射存储。</li>
</ul></li>
<li><code translate="no">index_management (IndexManagement)</code>:指定要使用的索引管理策略。默认为 "create_if_not_exists"。</li>
<li><code translate="no">batch_size (int)</code>:配置向 Milvus 插入数据时一个批次中处理的文档数量。默认为 DEFAULT_BATCH_SIZE。</li>
<li><code translate="no">consistency_level (str, optional)</code>:对新创建的 Collections 使用哪种一致性级别。默认为 "Session"。</li>
</ul>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Create an index over the documents</span>
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> VectorStoreIndex, StorageContext
<span class="hljs-keyword">from</span> llama_index.vector_stores.milvus <span class="hljs-keyword">import</span> MilvusVectorStore


vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>对于<code translate="no">MilvusVectorStore</code> 的参数：</p>
<ul>
<li>将<code translate="no">uri</code> 设置为本地文件，如<code translate="no">./milvus.db</code> ，是最方便的方法，因为它会自动利用<a href="https://milvus.io/docs/milvus_lite.md">Milvus Lite</a>将所有数据存储在此文件中。</li>
<li>如果数据规模较大，可以在<a href="https://milvus.io/docs/quickstart.md">docker 或 kubernetes</a> 上设置性能更强的 Milvus 服务器。在此设置中，请使用服务器 uri，例如<code translate="no">http://localhost:19530</code> ，作为您的<code translate="no">uri</code> 。</li>
<li>如果你想使用<a href="https://zilliz.com/cloud">Zilliz Cloud</a>（Milvus 的全托管云服务），请调整<code translate="no">uri</code> 和<code translate="no">token</code> ，它们与 Zilliz Cloud 中的<a href="https://docs.zilliz.com/docs/on-zilliz-cloud-console#free-cluster-details">公共端点和 Api 密钥</a>相对应。</li>
</ul>
</div>
<h3 id="Query-the-data" class="common-anchor-header">查询数据</h3><p>现在我们已经将文档存储到了索引中，可以针对索引提出问题。索引会将自身存储的数据作为 chatgpt 的知识库。</p>
<pre><code translate="no" class="language-python">query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;What did the author learn?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The author learned that philosophy courses in college were boring to him, leading him to switch his focus to studying AI.
</code></pre>
<pre><code translate="no" class="language-python">res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges for the author as it affected his mother's health, leading to a stroke caused by colon cancer. This resulted in her losing her balance and needing to be placed in a nursing home. The author and his sister were determined to help their mother get out of the nursing home and back to her house.
</code></pre>
<p>下一个测试显示覆盖会删除之前的数据。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> Document


vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    [Document(text=<span class="hljs-string">&quot;The number that is being searched for is ten.&quot;</span>)],
    storage_context,
)
query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;Who is the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The author is the individual who created the context information.
</code></pre>
<p>下一个测试显示的是向已有索引添加额外数据。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">del</span> index, vector_store, storage_context, query_engine

vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, overwrite=<span class="hljs-literal">False</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)
query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;What is the number?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The number is ten.
</code></pre>
<pre><code translate="no" class="language-python">res = query_engine.query(<span class="hljs-string">&quot;Who is the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">Paul Graham
</code></pre>
<h2 id="Metadata-filtering" class="common-anchor-header">元数据过滤<button data-href="#Metadata-filtering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>我们可以通过过滤特定来源生成结果。下面的示例说明了从目录中加载所有文档，然后根据元数据对其进行过滤。</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core.vector_stores <span class="hljs-keyword">import</span> ExactMatchFilter, MetadataFilters

<span class="hljs-comment"># Load all the two documents loaded before</span>
documents_all = SimpleDirectoryReader(<span class="hljs-string">&quot;./data/&quot;</span>).load_data()

vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents_all, storage_context)
<button class="copy-code-btn"></button></code></pre>
<p>我们只想检索文件<code translate="no">uber_2021.pdf</code> 中的文档。</p>
<pre><code translate="no" class="language-python">filters = MetadataFilters(
    filters=[ExactMatchFilter(key=<span class="hljs-string">&quot;file_name&quot;</span>, value=<span class="hljs-string">&quot;uber_2021.pdf&quot;</span>)]
)
query_engine = index.as_query_engine(filters=filters)
res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)

<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges related to the adverse impact on the business and operations, including reduced demand for Mobility offerings globally, affecting travel behavior and demand. Additionally, the pandemic led to driver supply constraints, impacted by concerns regarding COVID-19, with uncertainties about when supply levels would return to normal. The rise of the Omicron variant further affected travel, resulting in advisories and restrictions that could adversely impact both driver supply and consumer demand for Mobility offerings.
</code></pre>
<p>当从文件<code translate="no">paul_graham_essay.txt</code> 中检索时，我们会得到不同的结果。</p>
<pre><code translate="no" class="language-python">filters = MetadataFilters(
    filters=[ExactMatchFilter(key=<span class="hljs-string">&quot;file_name&quot;</span>, value=<span class="hljs-string">&quot;paul_graham_essay.txt&quot;</span>)]
)
query_engine = index.as_query_engine(filters=filters)
res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)

<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges for the author as it affected his mother's health, leading to a stroke caused by colon cancer. This resulted in his mother losing her balance and needing to be placed in a nursing home. The author and his sister were determined to help their mother get out of the nursing home and back to her house.
</code></pre>
