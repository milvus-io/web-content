{"codeList":["├── video_1                                       (VIDEO) # video.mp4\n│   ├── video_id                                  (INT)\n│   ├── video_url                                 (STRING)\n│   ├── frames                                    (ARRAY)\n│   │   ├── frame_1                               (STRUCT)\n│   │   │   ├── caption                           (STRUCT) # captions.jsonl\n│   │   │   │   ├── plain_caption                 (STRING)\n│   │   │   │   ├── rich_caption                  (STRING)\n│   │   │   │   ├── risk                          (STRING)\n│   │   │   │   ├── risk_correct                  (BOOL)\n│   │   │   │   ├── risk_yes_rate                 (FLOAT)\n│   │   │   │   ├── weather                       (STRING)\n│   │   │   │   ├── weather_rate                  (FLOAT)\n│   │   │   │   ├── road                          (STRING)\n│   │   │   │   ├── road_rate                     (FLOAT)\n│   │   │   │   ├── is_tunnel                     (BOOL)\n│   │   │   │   ├── is_tunnel_yes_rate            (FLOAT)\n│   │   │   │   ├── is_highway                    (BOOL)\n│   │   │   │   ├── is_highway_yes_rate           (FLOAT)\n│   │   │   │   ├── has_pedestrain                (BOOL)\n│   │   │   │   ├── has_pedestrain_yes_rate       (FLOAT)\n│   │   │   │   ├── has_carrier_car               (BOOL)\n│   │   │   ├── traffic_light                     (STRUCT) # traffic_lights.jsonl\n│   │   │   │   ├── index                         (INT)\n│   │   │   │   ├── class                         (STRING)\n│   │   │   │   ├── bbox                          (LIST<FLOAT>)\n│   │   │   ├── front_car                         (STRUCT) # front_cars.jsonl\n│   │   │   │   ├── has_lead                      (BOOL)\n│   │   │   │   ├── lead_prob                     (FLOAT)\n│   │   │   │   ├── lead_x                        (FLOAT)\n│   │   │   │   ├── lead_y                        (FLOAT)\n│   │   │   │   ├── lead_speed_kmh                (FLOAT)\n│   │   │   │   ├── lead_a                        (FLOAT)\n│   │   ├── frame_2                               (STRUCT)\n│   │   ├── ...                                   (STRUCT)\n│   │   ├── frame_n                               (STRUCT)\n├── video_2\n├── ...\n├── video_n\n","from pymilvus import MilvusClient, DataType\n\nclient = MilvusClient(\"http://localhost:19530\")\n\n# create the schema for the caption struct\nschema_for_caption = client.create_struct_field_schema()\n\nschema_for_caption.add_field(\n    field_name=\"frame_id\",\n    datatype=DataType.INT64,\n    description=\"ID of the frame to which the ego vehicle's behavior belongs\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"plain_caption\",\n    datatype=DataType.VARCHAR,\n    max_length=1024,\n    description=\"plain description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"plain_cap_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the plain description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"rich_caption\",\n    datatype=DataType.VARCHAR,\n    max_length=1024,\n    description=\"rich description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"rich_cap_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the rich description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk\",\n    datatype=DataType.VARCHAR,\n    max_length=1024,\n    description=\"description of the ego vehicle's risks\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the description of the ego vehicle's risks\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk_correct\",\n    datatype=DataType.BOOL,\n    description=\"whether the risk assessment is correct\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk_yes_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of risk being present\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"weather\",\n    datatype=DataType.VARCHAR,\n    max_length=50,\n    description=\"weather condition\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"weather_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of the weather condition\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"road\",\n    datatype=DataType.VARCHAR,\n    max_length=50,\n    description=\"road type\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"road_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of the road type\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"is_tunnel\",\n    datatype=DataType.BOOL,\n    description=\"whether the road is a tunnel\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"is_tunnel_yes_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of the road being a tunnel\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"is_highway\",\n    datatype=DataType.BOOL,\n    description=\"whether the road is a highway\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"is_highway_yes_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of the road being a highway\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"has_pedestrian\",\n    datatype=DataType.BOOL,\n    description=\"whether there is a pedestrian present\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"has_pedestrian_yes_rate\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of pedestrian presence\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"has_carrier_car\",\n    datatype=DataType.BOOL,\n    description=\"whether there is a carrier car present\"\n)\n","schema_for_front_car = client.create_struct_field_schema()\n\nschema_for_front_car.add_field(\n    field_name=\"frame_id\",\n    datatype=DataType.INT64,\n    description=\"ID of the frame to which the ego vehicle's behavior belongs\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"has_lead\",\n    datatype=DataType.BOOL,\n    description=\"whether there is a leading vehicle\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"lead_prob\",\n    datatype=DataType.FLOAT,\n    description=\"probability/confidence of the leading vehicle's presence\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"lead_x\",\n    datatype=DataType.FLOAT,\n    description=\"x position of the leading vehicle relative to the ego vehicle\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"lead_y\",\n    datatype=DataType.FLOAT,\n    description=\"y position of the leading vehicle relative to the ego vehicle\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"lead_speed_kmh\",\n    datatype=DataType.FLOAT,\n    description=\"speed of the leading vehicle in km/h\"\n)\n\nschema_for_front_car.add_field(\n    field_name=\"lead_a\",\n    datatype=DataType.FLOAT,\n    description=\"acceleration of the leading vehicle\"\n)\n","schema = client.create_schema()\n\nschema.add_field(\n    field_name=\"video_id\",\n    datatype=DataType.VARCHAR,\n    description=\"primary key\",\n    max_length=16,\n    is_primary=True,\n    auto_id=False\n)\n\nschema.add_field(\n    field_name=\"video_url\",\n    datatype=DataType.VARCHAR,\n    max_length=512,\n    description=\"URL of the video\"\n)\n\nschema.add_field(\n    field_name=\"captions\",\n    datatype=DataType.ARRAY,\n    element_type=DataType.STRUCT,\n    struct_schema=schema_for_caption,\n    max_capacity=600,\n    description=\"captions for the current video\"\n)\n\nschema.add_field(\n    field_name=\"traffic_lights\",\n    datatype=DataType.JSON,\n    description=\"frame-specific traffic lights identified in the current video\"\n)\n\nschema.add_field(\n    field_name=\"front_cars\",\n    datatype=DataType.ARRAY,\n    element_type=DataType.STRUCT,\n    struct_schema=schema_for_front_car,\n    max_capacity=600,\n    description=\"frame-specific leading cars identified in the current video\"\n)\n","index_params = client.prepare_index_params()\n\nindex_params.add_index(\n    field_name=\"captions[plain_cap_vector]\", \n    index_type=\"HNSW\", \n    metric_type=\"MAX_SIM_COSINE\", \n    index_name=\"captions_plain_cap_vector_idx\", # mandatory for now\n    index_params={\"M\": 16, \"efConstruction\": 200}\n)\n\nindex_params.add_index(\n    field_name=\"captions[rich_cap_vector]\", \n    index_type=\"HNSW\", \n    metric_type=\"MAX_SIM_COSINE\", \n    index_name=\"captions_rich_cap_vector_idx\", # mandatory for now\n    index_params={\"M\": 16, \"efConstruction\": 200}\n)\n\nindex_params.add_index(\n    field_name=\"captions[risk_vector]\", \n    index_type=\"HNSW\", \n    metric_type=\"MAX_SIM_COSINE\", \n    index_name=\"captions_risk_vector_idx\", # mandatory for now\n    index_params={\"M\": 16, \"efConstruction\": 200}\n)\n","client.create_collection(\n    collection_name=\"covla_dataset\",\n    schema=schema,\n    index_params=index_params\n)\n","import json\nfrom openai import OpenAI\n\nopenai_client = OpenAI(\n    api_key='YOUR_OPENAI_API_KEY',\n)\n\nvideo_id = \"0a0fc7a5db365174\" # represent a single video with 600 frames\n\n# get all front car records in the specified video clip\nentries = []\nfront_cars = []\nwith open('data/front_car/{}.jsonl'.format(video_id), 'r') as f:\n    for line in f:\n        entries.append(json.loads(line))\n\nfor entry in entries:\n    for key, value in entry.items():\n        value['frame_id'] = int(key)\n        front_cars.append(value)\n\n# get all traffic lights identified in the specified video clip\nentries = []\ntraffic_lights = []\nframe_id = 0\nwith open('data/traffic_lights/{}.jsonl'.format(video_id), 'r') as f:\n    for line in f:\n        entries.append(json.loads(line))\n\nfor entry in entries:\n    for key, value in entry.items():\n        if not value or (value['index'] == 1 and key != '0'):\n            frame_id+=1\n\n        if value:\n            value['frame_id'] = frame_id\n            traffic_lights.append(value)\n        else:\n            value_dict = {}\n            value_dict['frame_id'] = frame_id\n            traffic_lights.append(value_dict)\n\n# get all captions generated in the video clip and convert them into vector embeddings\nentries = []\ncaptions = []\nwith open('data/captions/{}.jsonl'.format(video_id), 'r') as f:\n    for line in f:\n        entries.append(json.loads(line))\n\ndef get_embedding(text, model=\"embeddinggemma:latest\"):\n    response = openai_client.embeddings.create(input=text, model=model)\n    return response.data[0].embedding\n\n# Add embeddings to each entry\nfor entry in entries:\n    # Each entry is a dict with a single key (e.g., '0', '1', ...)\n    for key, value in entry.items():\n        value['frame_id'] = int(key)  # Convert key to integer and assign to frame_id\n\n        if \"plain_caption\" in value and value[\"plain_caption\"]:\n            value[\"plain_cap_vector\"] = get_embedding(value[\"plain_caption\"])\n        if \"rich_caption\" in value and value[\"rich_caption\"]:\n            value[\"rich_cap_vector\"] = get_embedding(value[\"rich_caption\"])\n        if \"risk\" in value and value[\"risk\"]:\n            value[\"risk_vector\"] = get_embedding(value[\"risk\"])\n\n        captions.append(value)\n\ndata = {\n    \"video_id\": video_id,\n    \"video_url\": \"https://your-storage.com/{}\".format(video_id),\n    \"captions\": captions,\n    \"traffic_lights\": traffic_lights,\n    \"front_cars\": front_cars\n}\n","client.insert(\n    collection_name=\"covla_dataset\",\n    data=[data]\n)\n\n# {'insert_count': 1, 'ids': ['0a0fc7a5db365174'], 'cost': 0}\n"],"headingContent":"Data Model Design with an Array of Structs","anchorList":[{"label":"使用结构数组设计数据模型Compatible with Milvus 2.6.4+","href":"Data-Model-Design-with-an-Array-of-Structs","type":1,"isActive":false},{"label":"为什么要使用结构数组","href":"Why-Array-of-Structs","type":2,"isActive":false},{"label":"Schema 设计指南","href":"Schema-design-guidelines","type":2,"isActive":false},{"label":"定义 Struct 模式 Schema","href":"Define-the-Struct-schema","type":3,"isActive":false},{"label":"深思熟虑地设置最大容量","href":"Set-the-max-capacity-thoughtfully","type":3,"isActive":false},{"label":"在 Struct 中索引向量字段","href":"Index-vector-fields-in-Structs","type":3,"isActive":false},{"label":"实际示例为自动驾驶建立 CoVLA 数据集模型","href":"A-real-world-example-Modeling-the-CoVLA-dataset-for-autonomous-driving","type":2,"isActive":false},{"label":"步骤 1：将数据集映射到 Collections Schema 中","href":"Step-1-Map-the-dataset-into-a-collection-schema","type":3,"isActive":false},{"label":"步骤 2：初始化 Schema","href":"Step-2-Initialize-the-schemas","type":3,"isActive":false},{"label":"第 3 步：设置索引参数","href":"Step-3-Set-index-parameters","type":3,"isActive":false},{"label":"第 4 步：创建 Collections","href":"Step-4-Create-a-collection","type":3,"isActive":false},{"label":"第 5 步：插入数据","href":"Step-5-Insert-the-data","type":3,"isActive":false}]}