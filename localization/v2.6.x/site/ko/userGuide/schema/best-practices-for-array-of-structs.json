{"codeList":["├── video_1                                       (VIDEO) # video.mp4\n│   ├── video_id                                  (INT)\n│   ├── video_url                                 (STRING)\n│   ├── frames                                    (ARRAY)\n│   │   ├── frame_1                               (STRUCT)\n│   │   │   ├── caption                           (STRUCT) # captions.jsonl\n│   │   │   │   ├── plain_caption                 (STRING)\n│   │   │   │   ├── rich_caption                  (STRING)\n│   │   │   │   ├── risk                          (STRING)\n│   │   │   │   ├── risk_correct                  (BOOL)\n│   │   │   │   ├── risk_yes_rate                 (FLOAT)\n│   │   │   │   ├── weather                       (STRING)\n│   │   │   │   ├── weather_rate                  (FLOAT)\n│   │   │   │   ├── road                          (STRING)\n│   │   │   │   ├── road_rate                     (FLOAT)\n│   │   │   │   ├── is_tunnel                     (BOOL)\n│   │   │   │   ├── is_tunnel_yes_rate            (FLOAT)\n│   │   │   │   ├── is_highway                    (BOOL)\n│   │   │   │   ├── is_highway_yes_rate           (FLOAT)\n│   │   │   │   ├── has_pedestrain                (BOOL)\n│   │   │   │   ├── has_pedestrain_yes_rate       (FLOAT)\n│   │   │   │   ├── has_carrier_car               (BOOL)\n│   │   │   ├── traffic_light                     (STRUCT) # traffic_lights.jsonl\n│   │   │   │   ├── index                         (INT)\n│   │   │   │   ├── class                         (STRING)\n│   │   │   │   ├── bbox                          (LIST<FLOAT>)\n│   │   │   ├── front_car                         (STRUCT) # front_cars.jsonl\n│   │   │   │   ├── has_lead                      (BOOL)\n│   │   │   │   ├── lead_prob                     (FLOAT)\n│   │   │   │   ├── lead_x                        (FLOAT)\n│   │   │   │   ├── lead_y                        (FLOAT)\n│   │   │   │   ├── lead_speed_kmh                (FLOAT)\n│   │   │   │   ├── lead_a                        (FLOAT)\n│   │   ├── frame_2                               (STRUCT)\n│   │   ├── ...                                   (STRUCT)\n│   │   ├── frame_n                               (STRUCT)\n├── video_2\n├── ...\n├── video_n\n","from pymilvus import MilvusClient, DataType\n\n# create the schema for the caption struct\nschema_for_caption = MilvusClient.create_struct_field_schema()\n\nschema_for_caption.add_field(\n    field_name=\"frame_id\",\n    datatype=DataType.INT64,\n    description=\"ID of the frame to which the ego vehicle's behavior belongs\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"plain_caption\",\n    datatype=DataType.VARCHAR,\n    description=\"plain description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"plain_cap_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the plain description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"rich_caption\",\n    datatype=DataType.VARCHAR,\n    description=\"rich description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"rich_cap_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the rich description of the ego vehicle's behaviors\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk\",\n    datatype=DataType.VARCHAR,\n    description=\"description of the ego vehicle's risks\"\n)\n\nschema_for_caption.add_field(\n    field_name=\"risk_vector\",\n    datatype=DataType.FLOAT_VECTOR,\n    dim=768,\n    description=\"vectors for the description of the ego vehicle's risks\"\n)\n\n...\n","schema = MilvusClient.create_schema()\n\nschema.add_field(\n    field_name=\"video_id\",\n    datatype=DataType.VARCHAR,\n    description=\"primary key\"\n)\n\nschema.add_field(\n    field_name=\"video_url\",\n    datatype=DataType.VARCHAR,\n    max_length=512,\n    description=\"URL of the video\"\n)\n\nschema.add_field(\n    field_name=\"states\",\n    datatype=DataType.JSON,\n    description=\"frame-specific state of the ego vehicle in the current video\"\n)\n\n# highlight-start\nschema.add_field(\n    field_name=\"captions\",\n    datatype=DataType.ARRAY,\n    element_type=DataType.STRUCT,\n    struct_schema=struct_for_caption,\n    max_capacity=600,\n    description=\"captions for the current video\"\n)\n# highlight-end\n\nschema.add_field(\n    field_name=\"traffic_lights\",\n    datatype=DataType.JSON,\n    description=\"frame-specific traffic lights identified in the current video\"\n)\n\nschema.add_field(\n    field_name=\"front_cars\",\n    datatype=DataType.JSON,\n    description=\"frame-specific leading cars identified in the current video\"\n)\n","index_params = MilvusClient.prepare_index_params()\n\nindex_params.add_index(\n    field_name=\"plain_cap_vector\",\n    index_type=\"HNSW\",\n    metric_type=\"MAX_SIM_COSINE\",\n    params={\n        \"M\": 16,\n        \"efConstruction\": 128\n    }\n)\n\nindex_params.add_index(\n    field_name=\"rich_cap_vector\",\n    index_type=\"HNSW\",\n    metric_type=\"MAX_SIM_COSINE\",\n    params={\n        \"M\": 16,\n        \"efConstruction\": 128\n    }\n)\n\nindex_params.add_index(\n    field_name=\"risk_vector\",\n    index_type=\"HNSW\",\n    metric_type=\"MAX_SIM_COSINE\",\n    params={\n        \"M\": 16,\n        \"efConstruction\": 128\n    }\n)\n","client = MilvusClient(\"http://localhost:19530\")\n\nclient.create_collection(\n    collection_name=\"covla_dataset\",\n    schema=schema,\n    index_params=index_params\n)\n","{\n    \"video_id\": \"0a0fc7a5db365174\",\n    \"video_url\": \"videos/0a0fc7a5db365174.mp4\",\n    \"states\": {\n        \"0\": {\n            \"trajectory\": [[0.0, -0.0, 0.0], ...],\n            \"extrinsic_matrix\": [[-0.016034273081459105, -0.9998714384933313, -8.280132118064406e-05, 0.0], ...],\n            \"intrinsic_matrix\": [[2648.0, 0.0, 964.0], ...]\n        },\n        \"1\": {...}\n        ...\n        \"599\": {...}\n    },\n    \"captions\": [\n        {\n            \"frame_id\": 0,\n            \"plain_caption\": \"The ego vehicle is moving at a moderate speed with deceleration and turning right. There are 2 traffic lights;one which displays a red signal, and one which displays a right arrow, and straight arrow signal. Caution is required because the distance between the ego vehicle and the leading car is narrow.\",\n            \"rich_caption\": \"The ego vehicle is moving at a moderate speed with deceleration and turning right. There are 2 traffic lights;one which displays a red signal, and one which displays a right arrow, and straight arrow signal. Caution is required because the distance between the ego vehicle and the leading car is narrow. It is cloudy. The car is driving on a wide road. No pedestrians appear to be present. What the driver of ego vehicle should be careful is to maintain a safe distance from the leading car and to be prepared to stop if necessary\",\n            \"risk\": \"to maintain a safe distance from the leading car and to be prepared to stop if necessary\",\n            \"risk_correct\": true,\n            \"risk_yes_rate\": 0.6062515935356961,\n            ...\n        },\n        {\n            \"frame_id\": 1\n            ...\n        }\n        ...\n        {\n            \"frame_id\": 599\n            ...\n        }\n    ],\n    \"traffic_lights\": {\n        \"0\": [\n            {\"0\": {\"index\": 1, \"class\": \"red\", \"bbox\": [485.9914855957031, 294.18536376953125, 574.1666259765625, 360.3130798339844]}}\n            {\"1\": {\"index\": 2, \"class\": \"right\", \"bbox\": [487.6523742675781, 294.0285339355469, 574.2948608398438, 359.5504455566406]}}\n            {\"2\": {\"index\": 3, \"class\": \"straight\", \"bbox\": [487.6523742675781, 294.0285339355469, 574.2948608398438, 359.5504455566406]}}\n        ],\n        \"1\": [...],\n        ...\n        \"599\": [...]\n    },\n    \"front_cars\": {\n        \"0\": [\n            {\"0\": {\"has_lead\": true, \"lead_prob\": 0.967777669429779, \"lead_x\": 5.26953125, \"lead_y\": 1.07421875, \"lead_speed_kmh\": 23.6953125, \"lead_a\": 0.546875}}\n        ],\n        \"1\": [...]\n        ...\n        \"599\": [...]\n    }\n}\n","data = [\n    {\"video_id\": \"0a0fc7a5db365174\", ...}\n    ...\n]\n\nclient.insert(\n    collection_name=\"covla_dataset\",\n    data=data\n)\n"],"headingContent":"Data Model Design with an Array of Structs","anchorList":[{"label":"구조 배열을 사용한 데이터 모델 설계Compatible with Milvus 2.6.4+","href":"Data-Model-Design-with-an-Array-of-Structs","type":1,"isActive":false},{"label":"왜 구조체 배열인가?","href":"Why-Array-of-Structs","type":2,"isActive":false},{"label":"스키마 설계 가이드라인","href":"Schema-design-guidelines","type":2,"isActive":false},{"label":"구조체 스키마 정의","href":"Define-the-Struct-schema","type":3,"isActive":false},{"label":"최대 용량을 신중하게 설정하세요.","href":"Set-the-max-capacity-thoughtfully","type":3,"isActive":false},{"label":"구조체에서 벡터 필드 인덱싱","href":"Index-vector-fields-in-Structs","type":3,"isActive":false},{"label":"실제 예제 자율 주행을 위한 CoVLA 데이터 세트 모델링하기","href":"A-real-world-example-Modeling-the-CoVLA-dataset-for-autonomous-driving","type":2,"isActive":false},{"label":"1단계: 데이터 집합을 컬렉션 스키마에 매핑하기","href":"Step-1-Map-the-dataset-into-a-collection-schema","type":3,"isActive":false},{"label":"2단계: 스키마 초기화","href":"Step-2-Initialize-the-schemas","type":3,"isActive":false},{"label":"3단계: 인덱스 매개변수 설정","href":"Step-3-Set-index-parameters","type":3,"isActive":false},{"label":"4단계: 컬렉션 만들기","href":"Step-4-Create-a-collection","type":3,"isActive":false},{"label":"5단계: 데이터 삽입","href":"Step-5-Insert-the-data","type":3,"isActive":false}]}