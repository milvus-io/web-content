{"codeList":["$ pip install -qU pymilvus openai embed_anything\n","import sys\n\n# Clone the EmbedAnything repository if not already cloned\n![ -d \"EmbedAnything\" ] || git clone https://github.com/StarlightSearch/EmbedAnything.git\n\n# Add the `examples/adapters` directory to the Python path\nsys.path.append(\"EmbedAnything/examples/adapters\")\nprint(\"✅ EmbedAnything cloned and adapter path added.\")\n","import os\nfrom openai import OpenAI\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-***********\"\n\nopenai_client = OpenAI()\n","import embed_anything\nfrom embed_anything import (\n    WhichModel,\n    EmbeddingModel,\n)\nfrom milvus_db import MilvusVectorAdapter\nfrom pymilvus import MilvusClient\n\n# Official Milvus client for full operations\nmilvus_client = MilvusClient(uri=\"./milvus.db\", token=\"\")\n\n# EmbedAnything adapter for pushing embeddings into Milvus\nindex_name = \"embed_anything_milvus_collection\"\nmilvus_adapter = MilvusVectorAdapter(\n    uri=\"./milvus.db\", token=\"\", collection_name=index_name\n)\n\n# Delete existing collection if it exists\nif milvus_client.has_collection(index_name):\n    milvus_client.drop_collection(index_name)\n\n# Create a new collection with dimension matching the embedding model later used\nmilvus_adapter.create_index(dimension=384)\n","# Initialize the embedding model\nmodel = EmbeddingModel.from_pretrained_hf(\n    WhichModel.Bert, model_id=\"sentence-transformers/all-MiniLM-L12-v2\"\n)\n","# Embed a PDF file\ndata = embed_anything.embed_file(\n    \"./pdf_files/WhatisMilvus.pdf\",\n    embedder=model,\n    adapter=milvus_adapter,\n)\n","def retrieve_documents(question, top_k=3):\n    query_vector = list(\n        embed_anything.embed_query([question], embedder=model)[0].embedding\n    )\n    search_res = milvus_client.search(\n        collection_name=index_name,\n        data=[query_vector],\n        limit=top_k,\n        output_fields=[\"text\"],\n    )\n    docs = [(res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]]\n    return docs\n","def generate_rag_response(question):\n    retrieved_docs = retrieve_documents(question)\n    context = \"\\n\".join([f\"Text: {doc[0]}\\n\" for doc in retrieved_docs])\n    system_prompt = (\n        \"You are an AI assistant. Provide answers based on the given context.\"\n    )\n    user_prompt = f\"\"\"\n    Use the following pieces of information to answer the question. If the information is not in the context, say you don't know.\n    \n    Context:\n    {context}\n    \n    Question: {question}\n    \"\"\"\n    response = openai_client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n    )\n    return response.choices[0].message.content\n","question = \"How does Milvus search for similar documents?\"\nanswer = generate_rag_response(question)\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")\n"],"headingContent":"Building RAG with Milvus and EmbedAnything","anchorList":[{"label":"Milvus와 EmbedAnything으로 RAG 구축하기","href":"Building-RAG-with-Milvus-and-EmbedAnything","type":1,"isActive":false},{"label":"준비","href":"Preparation","type":2,"isActive":false},{"label":"RAG 빌드","href":"Build-RAG","type":2,"isActive":false}]}