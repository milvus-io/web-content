---
id: milvus_rag_with_vllm.md
summary: >-
  ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” Milvus, vLLM ë° Llama 3.1ë¡œ RAGë¥¼ êµ¬ì¶•í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ,
  Milvusì—ì„œ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì„ë² ë”©í•˜ê³  ì €ì¥í•˜ëŠ” ë°©ë²•ê³¼ ì´ ë²¡í„° ì €ì¥ì†Œë¥¼ ì§€ì‹ì°½ê³ ë¡œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í…ìŠ¤íŠ¸
  ì²­í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
title: 'Milvus, vLLM, Llama 3.1ë¡œ RAG êµ¬ì¶•í•˜ê¸°'
---
<h1 id="Building-RAG-with-Milvus-vLLM-and-Llama-31" class="common-anchor-header">Milvus, vLLM, Llama 3.1ë¡œ RAG êµ¬ì¶•í•˜ê¸°<button data-href="#Building-RAG-with-Milvus-vLLM-and-Llama-31" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h1><p>ìº˜ë¦¬í¬ë‹ˆì•„ ëŒ€í•™êµ ë²„í´ë¦¬ëŠ” 2024ë…„ 7ì›” ì¸íë² ì´ì…˜ ë‹¨ê³„ í”„ë¡œì íŠ¸ë¡œ LLM ì¶”ë¡  ë° ì„œë¹™ì„ ìœ„í•œ ë¹ ë¥´ê³  ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ <a href="https://docs.vllm.ai/en/latest/index.html">vLLMì„</a> <a href="https://lfaidata.foundation/">LF AI &amp; Data Foundationì—</a> ê¸°ë¶€í–ˆìŠµë‹ˆë‹¤. ë™ë£Œ íšŒì› í”„ë¡œì íŠ¸ë¡œì„œ LF AI &amp; Dataì˜ ê°€ì¡±ì´ ëœ vLLMì„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰</p>
<p>ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸<a href="https://zilliz.com/glossary/large-language-models-(llms)">(LLM)</a>ê³¼ <a href="https://zilliz.com/learn/what-is-vector-database">ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ”</a> ì¼ë°˜ì ìœ¼ë¡œ <a href="https://zilliz.com/glossary/ai-hallucination">AI í™˜ê°ì„</a> í•´ê²°í•˜ê¸° ìœ„í•´ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„í‚¤í…ì²˜ì¸ ê²€ìƒ‰ ì¦ê°• ìƒì„±<a href="https://zilliz.com/learn/Retrieval-Augmented-Generation">(RAG)</a>ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì§ì„ ì´ë£¹ë‹ˆë‹¤. ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” Milvus, vLLM ë° Llama 3.1ì„ ì‚¬ìš©í•˜ì—¬ RAGë¥¼ êµ¬ì¶•í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ, Milvusì—ì„œ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ <a href="https://zilliz.com/glossary/vector-embeddings">ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ì„ë² ë”©í•˜ê³ </a> ì €ì¥í•˜ëŠ” ë°©ë²•ê³¼ ì´ ë²¡í„° ì €ì¥ì†Œë¥¼ ì§€ì‹ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë¡œ ì¦ê°•ëœ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” Metaì˜ Llama 3.1-8B ëª¨ë¸ì„ ì œê³µí•˜ê¸° ìœ„í•´ vLLMì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤!</p>
<h2 id="Introduction-to-Milvus-vLLM-and-Metaâ€™s-Llama-31" class="common-anchor-header">Milvus, vLLM ë° Metaì˜ Llama 3.1 ì†Œê°œ<button data-href="#Introduction-to-Milvus-vLLM-and-Metaâ€™s-Llama-31" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Milvus-vector-database" class="common-anchor-header">Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤<button data-href="#Milvus-vector-database" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p><a href="https://zilliz.com/what-is-milvus"><strong>MilvusëŠ”</strong></a> <a href="https://zilliz.com/blog/what-is-a-real-vector-database">íŠ¹ë³„íˆ ì œì‘ëœ</a> ì˜¤í”ˆ ì†ŒìŠ¤ ë¶„ì‚°í˜• ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ, <a href="https://zilliz.com/learn/generative-ai">ìƒì„± AI</a> (GenAI) ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ë²¡í„°ë¥¼ ì €ì¥, ìƒ‰ì¸ ë° ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <a href="https://zilliz.com/blog/a-review-of-hybrid-search-in-milvus">í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰,</a> <a href="https://zilliz.com/blog/what-is-new-with-metadata-filtering-in-milvus">ë©”íƒ€ë°ì´í„° í•„í„°ë§</a>, ì¬ë­í‚¹ì„ ìˆ˜í–‰í•˜ê³  ìˆ˜ì¡° ê°œì˜ ë²¡í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” MilvusëŠ” AI ë° ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ìµœê³ ì˜ ì„ íƒì…ë‹ˆë‹¤. <a href="https://github.com/milvus-io/">MilvusëŠ”</a> ë¡œì»¬, í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ ì™„ì „ ê´€ë¦¬í˜• <a href="https://zilliz.com/cloud">Zilliz Cloudì—ì„œ</a> í˜¸ìŠ¤íŒ…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<h3 id="vLLM" class="common-anchor-header">vLLM<button data-href="#vLLM" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p><a href="https://vllm.readthedocs.io/en/latest/index.html"><strong>vLLMì€</strong></a> UC ë²„í´ë¦¬ ìŠ¤ì¹´ì´ë©ì—ì„œ ì‹œì‘ëœ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¡œ, LLM ì„œë¹„ìŠ¤ ì„±ëŠ¥ ìµœì í™”ì— ì¤‘ì ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤. PagedAttention, ì—°ì† ë°°ì¹­, ìµœì í™”ëœ CUDA ì»¤ë„ì„ í†µí•œ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ì— ë¹„í•´ vLLMì€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ë©´ì„œ ì„œë¹™ ì„±ëŠ¥ì„ ìµœëŒ€ 24ë°°ê¹Œì§€ í–¥ìƒì‹œí‚µë‹ˆë‹¤.</p>
<p><a href="https://arxiv.org/abs/2309.06180">"í˜ì´ì§€ì–´í…ì…˜ìœ¼ë¡œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬</a>" ë°±ì„œì— ë”°ë¥´ë©´ KV ìºì‹œëŠ” GPU ë©”ëª¨ë¦¬ì˜ ì•½ 30%ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì ì¬ì ì¸ ë©”ëª¨ë¦¬ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. KV ìºì‹œëŠ” ì¸ì ‘ ë©”ëª¨ë¦¬ì— ì €ì¥ë˜ì§€ë§Œ í¬ê¸°ê°€ ë³€ê²½ë˜ë©´ ë©”ëª¨ë¦¬ ì¡°ê°í™”ê°€ ë°œìƒí•˜ì—¬ ê³„ì‚°ì— ë¹„íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="/docs/v2.6.x/assets/vllm_1.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ì´ë¯¸ì§€ 1. ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œì˜ KV ìºì‹œ ë©”ëª¨ë¦¬ ê´€ë¦¬(2023ë…„ í˜ì´ì§•ëœ ì£¼ì˜ <a href="https://arxiv.org/pdf/2309.06180">ë¬¸ì„œ</a>)</em></p>
<p>KV ìºì‹œì— ê°€ìƒ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” vLLMì€ í•„ìš”ì— ë”°ë¼ ë¬¼ë¦¬ì  GPU ë©”ëª¨ë¦¬ë§Œ í• ë‹¹í•˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ì¡°ê°í™”ë¥¼ ì œê±°í•˜ê³  ì‚¬ì „ í• ë‹¹ì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ê²°ê³¼, vLLMì€ NVIDIA A10G ë° A100 GPUì—ì„œ <a href="https://huggingface.co/docs/transformers/main_classes/text_generation">í—ˆê¹…í˜ì´ìŠ¤ íŠ¸ëœìŠ¤í¬ë¨¸</a> (HF) ë° <a href="https://github.com/huggingface/text-generation-inference">í…ìŠ¤íŠ¸ ìƒì„± ì¶”ë¡ </a> (TGI)ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì—¬ HFë³´ë‹¤ ìµœëŒ€ 24ë°°, TGIë³´ë‹¤ 3.5ë°° ë” ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="/docs/v2.6.x/assets/vllm_2.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ì´ë¯¸ì§€ 2. ê° ìš”ì²­ì´ 3ê°œì˜ ë³‘ë ¬ ì¶œë ¥ ì™„ë£Œë¥¼ ìš”ì²­í•  ë•Œ ì²˜ë¦¬ëŸ‰ ì œê³µ. vLLMì€ HFë³´ë‹¤ 8.5ë°°~15ë°°, TGIë³´ë‹¤ 3.3ë°°~3.5ë°° ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ ë‹¬ì„±í•©ë‹ˆë‹¤(2023ë…„ <a href="https://blog.vllm.ai/2023/06/20/vllm.html">vLLM ë¸”ë¡œê·¸</a>).</em></p>
<h3 id="Metaâ€™s-Llama-31" class="common-anchor-header">ë©”íƒ€ì˜ ë¼ë§ˆ 3.1<button data-href="#Metaâ€™s-Llama-31" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models"><strong>ë©”íƒ€ì˜ ë¼ë§ˆ 3.1ì€</strong></a> 2024ë…„ 7ì›” 23ì¼ì— ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤. 405B ëª¨ë¸ì€ ì—¬ëŸ¬ ê³µê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ ìƒì—…ì  ì‚¬ìš©ì´ í—ˆìš©ëœ 128,000ê°œì˜ ì…ë ¥ í† í° ì»¨í…ìŠ¤íŠ¸ ì°½ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë©”íƒ€ëŠ” 405ì–µ ê°œì˜ íŒŒë¼ë¯¸í„° ëª¨ë¸ê³¼ í•¨ê»˜ Llama3 70B(700ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°)ì™€ 8B(80ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°)ì˜ ì—…ë°ì´íŠ¸ ë²„ì „ì„ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWbMJv2vnLfjW3Rh6L96gqS5YW7MhRLh5j9tjNN8BHR5W3qgyTW6N1vHY6lZ3l8N8htfRfqP8DzW72mhHB6vwYd2W77hFt886l4_PV22X226RPmZbW67mSH08gVp9MW2jcZvf24w97BW207Jmf8gPH0yW20YPQv261xxjW8nc6VW3jj-nNW6XdRhg5HhZk_W1QS0yL9dJZb0W818zFK1w62kdW8y-_4m1gfjfNW2jswrd3xbv-yW5mrvdk3n-KqyW45sLMF21qDrwW5TR3vr2MYxZ9W2hWhq23q-nQdW4blHqh3JlZWfW937hlZ58-KJCW82Pgv9384MbYW7yp56M6pvzd6f77wnH004">ë©”íƒ€ ì›¹ì‚¬ì´íŠ¸ì—ì„œ</a> ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>í•µì‹¬ ì¸ì‚¬ì´íŠ¸ëŠ” ìƒì„±ëœ ë°ì´í„°ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ë©´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆì§€ë§Œ, í’ˆì§ˆì´ ì¢‹ì§€ ì•Šì€ ì˜ˆì œëŠ” ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. Llama íŒ€ì€ ëª¨ë¸ ìì²´, ë³´ì¡° ëª¨ë¸ ë° ê¸°íƒ€ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ë¶ˆëŸ‰ ì˜ˆì œë¥¼ ì‹ë³„í•˜ê³  ì œê±°í•˜ê¸° ìœ„í•´ ê´‘ë²”ìœ„í•˜ê²Œ ì‘ì—…í–ˆìŠµë‹ˆë‹¤.</p>
<h2 id="Build-and-Perform-the-RAG-Retrieval-with-Milvus" class="common-anchor-header">Milvusë¡œ RAG ê²€ìƒ‰ êµ¬ì¶• ë° ìˆ˜í–‰í•˜ê¸°<button data-href="#Build-and-Perform-the-RAG-Retrieval-with-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Prepare-your-dataset" class="common-anchor-header">ë°ì´í„° ì§‘í•©ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.<button data-href="#Prepare-your-dataset" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ì´ ë°ëª¨ì—ì„œëŠ” ê³µì‹ <a href="https://milvus.io/docs/">Milvus ì„¤ëª…ì„œë¥¼</a> ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì— ì €ì¥í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> DirectoryLoader
<span class="hljs-comment"># Load HTML files already saved in a local directory</span>
path = <span class="hljs-string">&quot;../../RAG/rtdocs_new/&quot;</span>
global_pattern = <span class="hljs-string">&#x27;*.html&#x27;</span>
loader = DirectoryLoader(path=path, glob=global_pattern)
docs = loader.load()


<span class="hljs-comment"># Print num documents and a preview.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loaded <span class="hljs-subst">{<span class="hljs-built_in">len</span>(docs)}</span> documents&quot;</span>)
<span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)
pprint.pprint(docs[<span class="hljs-number">0</span>].metadata)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">loaded 22 documents
Why Milvus Docs Tutorials Tools Blog Community Stars0 Try Managed Milvus FREE Search Home v2.4.x About ...
{&#x27;source&#x27;: &#x27;https://milvus.io/docs/quickstart.md&#x27;}
<button class="copy-code-btn"></button></code></pre>
<h3 id="Download-an-embedding-model" class="common-anchor-header">ì„ë² ë”© ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.<button data-href="#Download-an-embedding-model" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ë‹¤ìŒìœ¼ë¡œ, HuggingFaceì—ì„œ ë¬´ë£Œ ì˜¤í”ˆ ì†ŒìŠ¤ <a href="https://zilliz.com/ai-models">ì„ë² ë”© ëª¨ë¸ì„</a> ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer


<span class="hljs-comment"># Initialize torch settings for device-agnostic code.</span>
N_GPU = torch.cuda.device_count()
DEVICE = torch.device(<span class="hljs-string">&#x27;cuda:N_GPU&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)


<span class="hljs-comment"># Download the model from huggingface model hub.</span>
model_name = <span class="hljs-string">&quot;BAAI/bge-large-en-v1.5&quot;</span>
encoder = SentenceTransformer(model_name, device=DEVICE)


<span class="hljs-comment"># Get the model parameters and save for later.</span>
EMBEDDING_DIM = encoder.get_sentence_embedding_dimension()
MAX_SEQ_LENGTH_IN_TOKENS = encoder.get_max_seq_length()


<span class="hljs-comment"># Inspect model parameters.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;model_name: <span class="hljs-subst">{model_name}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;EMBEDDING_DIM: <span class="hljs-subst">{EMBEDDING_DIM}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;MAX_SEQ_LENGTH: <span class="hljs-subst">{MAX_SEQ_LENGTH}</span>&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">model_name: BAAI/bge-large-en-v1.5
EMBEDDING_DIM: 1024
MAX_SEQ_LENGTH: 512
<button class="copy-code-btn"></button></code></pre>
<h3 id="Chunk-and-encode-your-custom-data-as-vectors" class="common-anchor-header">ì‚¬ìš©ì ì§€ì • ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ì²­í¬í•˜ê³  ì¸ì½”ë”©í•©ë‹ˆë‹¤.<button data-href="#Chunk-and-encode-your-custom-data-as-vectors" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ì €ëŠ” 10% ê²¹ì¹˜ëŠ” 512ìì˜ ê³ ì • ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter


CHUNK_SIZE = <span class="hljs-number">512</span>
chunk_overlap = np.<span class="hljs-built_in">round</span>(CHUNK_SIZE * <span class="hljs-number">0.10</span>, <span class="hljs-number">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;chunk_size: <span class="hljs-subst">{CHUNK_SIZE}</span>, chunk_overlap: <span class="hljs-subst">{chunk_overlap}</span>&quot;</span>)


<span class="hljs-comment"># Define the splitter.</span>
child_splitter = RecursiveCharacterTextSplitter(
   chunk_size=CHUNK_SIZE,
   chunk_overlap=chunk_overlap)


<span class="hljs-comment"># Chunk the docs.</span>
chunks = child_splitter.split_documents(docs)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{<span class="hljs-built_in">len</span>(docs)}</span> docs split into <span class="hljs-subst">{<span class="hljs-built_in">len</span>(chunks)}</span> child documents.&quot;</span>)


<span class="hljs-comment"># Encoder input is doc.page_content as strings.</span>
list_of_strings = [doc.page_content <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> chunks <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(doc, <span class="hljs-string">&#x27;page_content&#x27;</span>)]


<span class="hljs-comment"># Embedding inference using HuggingFace encoder.</span>
embeddings = torch.tensor(encoder.encode(list_of_strings))


<span class="hljs-comment"># Normalize the embeddings.</span>
embeddings = np.array(embeddings / np.linalg.norm(embeddings))


<span class="hljs-comment"># Milvus expects a list of `numpy.ndarray` of `numpy.float32` numbers.</span>
converted_values = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(np.float32, embeddings))


<span class="hljs-comment"># Create dict_list for Milvus insertion.</span>
dict_list = []
<span class="hljs-keyword">for</span> chunk, vector <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(chunks, converted_values):
   <span class="hljs-comment"># Assemble embedding vector, original text chunk, metadata.</span>
   chunk_dict = {
       <span class="hljs-string">&#x27;chunk&#x27;</span>: chunk.page_content,
       <span class="hljs-string">&#x27;source&#x27;</span>: chunk.metadata.get(<span class="hljs-string">&#x27;source&#x27;</span>, <span class="hljs-string">&quot;&quot;</span>),
       <span class="hljs-string">&#x27;vector&#x27;</span>: vector,
   }
   dict_list.append(chunk_dict)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">chunk_size: 512, chunk_overlap: 51.0
22 docs split into 355 child documents.
<button class="copy-code-btn"></button></code></pre>
<h3 id="Save-the-vectors-in-Milvus" class="common-anchor-header">ë°€ë²„ìŠ¤ì— ë²¡í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.<button data-href="#Save-the-vectors-in-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ì¸ì½”ë”©ëœ ë²¡í„° ì„ë² ë”©ì„ Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Connect a client to the Milvus Lite server.</span>
<span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient
mc = MilvusClient(<span class="hljs-string">&quot;milvus_demo.db&quot;</span>)


<span class="hljs-comment"># Create a collection with flexible schema and AUTOINDEX.</span>
COLLECTION_NAME = <span class="hljs-string">&quot;MilvusDocs&quot;</span>
mc.create_collection(COLLECTION_NAME,
       EMBEDDING_DIM,
       consistency_level=<span class="hljs-string">&quot;Eventually&quot;</span>,
       auto_id=<span class="hljs-literal">True</span>, 
       overwrite=<span class="hljs-literal">True</span>)


<span class="hljs-comment"># Insert data into the Milvus collection.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start inserting entities&quot;</span>)
start_time = time.time()
mc.insert(
   COLLECTION_NAME,
   data=dict_list,
   progress_bar=<span class="hljs-literal">True</span>)


end_time = time.time()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Milvus insert time for <span class="hljs-subst">{<span class="hljs-built_in">len</span>(dict_list)}</span> vectors: &quot;</span>, end=<span class="hljs-string">&quot;&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{<span class="hljs-built_in">round</span>(end_time - start_time, <span class="hljs-number">2</span>)}</span> seconds&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">Start inserting entities
Milvus insert time for 355 vectors: 0.2 seconds
<button class="copy-code-btn"></button></code></pre>
<h3 id="Perform-a-vector-search" class="common-anchor-header">ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.<button data-href="#Perform-a-vector-search" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>Milvusì˜ ì§€ì‹ì°½ê³ ì—ì„œ ì§ˆë¬¸ì„ í•˜ê³  ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python">SAMPLE_QUESTION = <span class="hljs-string">&quot;What do the parameters for HNSW mean?&quot;</span>


<span class="hljs-comment"># Embed the question using the same encoder.</span>
query_embeddings = torch.tensor(encoder.encode(SAMPLE_QUESTION))
<span class="hljs-comment"># Normalize embeddings to unit length.</span>
query_embeddings = F.normalize(query_embeddings, p=<span class="hljs-number">2</span>, dim=<span class="hljs-number">1</span>)
<span class="hljs-comment"># Convert the embeddings to list of list of np.float32.</span>
query_embeddings = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(np.float32, query_embeddings))


<span class="hljs-comment"># Define metadata fields you can filter on.</span>
OUTPUT_FIELDS = <span class="hljs-built_in">list</span>(dict_list[<span class="hljs-number">0</span>].keys())
OUTPUT_FIELDS.remove(<span class="hljs-string">&#x27;vector&#x27;</span>)


<span class="hljs-comment"># Define how many top-k results you want to retrieve.</span>
TOP_K = <span class="hljs-number">2</span>


<span class="hljs-comment"># Run semantic vector search using your query and the vector database.</span>
results = mc.search(
    COLLECTION_NAME,
    data=query_embeddings,
    output_fields=OUTPUT_FIELDS,
    limit=TOP_K,
    consistency_level=<span class="hljs-string">&quot;Eventually&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<p>ê²€ìƒ‰ëœ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-text">Retrieved result #1
distance = 0.7001987099647522
(&#x27;Chunk text: layer, finds the node closest to the target in this layer, and&#x27;
...
&#x27;outgoing&#x27;)
source: https://milvus.io/docs/index.md

Retrieved result #2
distance = 0.6953287124633789
(&#x27;Chunk text: this value can improve recall rate at the cost of increased&#x27;
...
&#x27;to the target&#x27;)
source: https://milvus.io/docs/index.md
<button class="copy-code-btn"></button></code></pre>
<h2 id="Build-and-Perform-the-RAG-Generation-with-vLLM-and-Llama-31-8B" class="common-anchor-header">vLLM ë° Llama 3.1-8Bë¡œ RAG ìƒì„± ë¹Œë“œ ë° ìˆ˜í–‰í•˜ê¸°<button data-href="#Build-and-Perform-the-RAG-Generation-with-vLLM-and-Llama-31-8B" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Install-vLLM-and-models-from-HuggingFace" class="common-anchor-header">HuggingFaceì—ì„œ vLLM ë° ëª¨ë¸ ì„¤ì¹˜í•˜ê¸°<button data-href="#Install-vLLM-and-models-from-HuggingFace" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>vLLMì€ ê¸°ë³¸ì ìœ¼ë¡œ HuggingFaceì—ì„œ ëŒ€ìš©ëŸ‰ ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ìƒˆë¡œìš´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ -ì—…ê·¸ë ˆì´ë“œ ë˜ëŠ” -ìœ ë¥¼ í†µí•´ pipë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ vLLMìœ¼ë¡œ Metaì˜ Llama 3.1 ëª¨ë¸ì„ ì¶”ë¡ í•˜ë ¤ë©´ GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.</p>
<p>vLLMì´ ì§€ì›ë˜ëŠ” ëª¨ë“  ëª¨ë¸ì˜ ì „ì²´ ëª©ë¡ì€ ì´ <a href="https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models">ë¬¸ì„œ í˜ì´ì§€ë¥¼</a> ì°¸ì¡°í•˜ì„¸ìš”.</p>
<pre><code translate="no" class="language-shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">(Recommended) Create a new conda environment.</span>
conda create -n myenv python=3.11 -y
conda activate myenv
<span class="hljs-meta prompt_">

# </span><span class="language-bash">Install vLLM with CUDA 12.1.</span>
pip install -U vllm transformers torch


import vllm, torch
from vllm import LLM, SamplingParams
<span class="hljs-meta prompt_">

# </span><span class="language-bash">Clear the GPU memory cache.</span>
torch.cuda.empty_cache()
<span class="hljs-meta prompt_">

# </span><span class="language-bash">Check the GPU.</span>
!nvidia-smi
<button class="copy-code-btn"></button></code></pre>
<p>vLLMì„ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ <a href="https://docs.vllm.ai/en/latest/getting_started/installation.html">ì„¤ì¹˜</a> í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.</p>
<h3 id="Get-a-HuggingFace-token" class="common-anchor-header">í—ˆê¹…í˜ì´ìŠ¤ í† í° ë°›ê¸°.<button data-href="#Get-a-HuggingFace-token" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ë©”íƒ€ ë¼ë§ˆ 3.1ê³¼ ê°™ì€ HuggingFaceì˜ ì¼ë¶€ ëª¨ë¸ì€ ì‚¬ìš©ìê°€ ë¼ì´ì„ ìŠ¤ë¥¼ ìˆ˜ë½í•´ì•¼ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í—ˆê¹…í˜ì´ìŠ¤ ê³„ì •ì„ ìƒì„±í•˜ê³  ëª¨ë¸ì˜ ë¼ì´ì„ ìŠ¤ë¥¼ ìˆ˜ë½í•œ í›„ í† í°ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.</p>
<p>HuggingFaceì—ì„œ ì´ <a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-70B">Llama3.1 í˜ì´ì§€ë¥¼</a> ë°©ë¬¸í•˜ë©´ ì•½ê´€ì— ë™ì˜í• ì§€ ë¬»ëŠ” ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤. ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê¸° ì „ì— "<strong>ë¼ì´ì„ ìŠ¤ ìˆ˜</strong>ë½"ì„ í´ë¦­í•˜ì—¬ ë©”íƒ€ ì•½ê´€ì— ë™ì˜í•©ë‹ˆë‹¤. ìŠ¹ì¸ì€ ë³´í†µ í•˜ë£¨ë„ ì±„ ê±¸ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
<p><strong>ìŠ¹ì¸ì„ ë°›ì€ í›„ì—ëŠ” ìƒˆë¡œìš´ HuggingFace í† í°ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ì „ í† í°ì€ ìƒˆ ê¶Œí•œìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</strong></p>
<p>vLLMì„ ì„¤ì¹˜í•˜ê¸° ì „ì— ìƒˆ í† í°ìœ¼ë¡œ í—ˆê¹…í˜ì´ìŠ¤ì— ë¡œê·¸ì¸í•˜ì„¸ìš”. ì•„ë˜ì—ì„œëŠ” Colab ì‹œí¬ë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í† í°ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Login to HuggingFace using your new token.</span>
from huggingface_hub import login
from google.colab import userdata
hf_token = userdata.get(&#x27;HF_TOKEN&#x27;)
login(token = hf_token, add_to_git_credential=True)
<button class="copy-code-btn"></button></code></pre>
<h3 id="Run-the-RAG-Generation" class="common-anchor-header">RAG-ì„¸ëŒ€ ì‹¤í–‰<button data-href="#Run-the-RAG-Generation" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h3><p>ë°ëª¨ì—ì„œëŠ” ìŠ¤í•€ì—…ì— GPUì™€ ìƒë‹¹í•œ ë©”ëª¨ë¦¬ê°€ í•„ìš”í•œ <code translate="no">Llama-3.1-8B</code> ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ë‹¤ìŒ ì˜ˆì œëŠ” A100 GPUê°€ ìˆëŠ” Google Colab Pro(ì›” $10)ì—ì„œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. vLLMì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ <a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html">ë¹ ë¥¸ ì‹œì‘ ì„¤ëª…ì„œë¥¼</a> ì°¸ì¡°í•˜ì„¸ìš”.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># 1. Choose a model</span>
MODELTORUN = <span class="hljs-string">&quot;meta-llama/Meta-Llama-3.1-8B-Instruct&quot;</span>


<span class="hljs-comment"># 2. Clear the GPU memory cache, you&#x27;re going to need it all!</span>
torch.cuda.empty_cache()


<span class="hljs-comment"># 3. Instantiate a vLLM model instance.</span>
llm = LLM(model=MODELTORUN,
         enforce_eager=<span class="hljs-literal">True</span>,
         dtype=torch.bfloat16,
         gpu_memory_utilization=<span class="hljs-number">0.5</span>,
         max_model_len=<span class="hljs-number">1000</span>,
         seed=<span class="hljs-number">415</span>,
         max_num_batched_tokens=<span class="hljs-number">3000</span>)
<button class="copy-code-btn"></button></code></pre>
<p>Milvusì—ì„œ ê²€ìƒ‰í•œ ì»¨í…ìŠ¤íŠ¸ì™€ ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Separate all the context together by space.</span>
contexts_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(contexts)
<span class="hljs-comment"># Lance Martin, LangChain, says put the best contexts at the end.</span>
contexts_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">reversed</span>(contexts))


<span class="hljs-comment"># Separate all the unique sources together by comma.</span>
source_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">reversed</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">dict</span>.fromkeys(sources))))


SYSTEM_PROMPT = <span class="hljs-string">f&quot;&quot;&quot;First, check if the provided Context is relevant to
the user&#x27;s question.  Second, only if the provided Context is strongly relevant, answer the question using the Context.  Otherwise, if the Context is not strongly relevant, answer the question without using the Context. 
Be clear, concise, relevant.  Answer clearly, in fewer than 2 sentences.
Grounding sources: <span class="hljs-subst">{source_combined}</span>
Context: <span class="hljs-subst">{contexts_combined}</span>
User&#x27;s question: <span class="hljs-subst">{SAMPLE_QUESTION}</span>
&quot;&quot;&quot;</span>


prompts = [SYSTEM_PROMPT]
<button class="copy-code-btn"></button></code></pre>
<p>ì´ì œ ê²€ìƒ‰ëœ ì²­í¬ì™€ í”„ë¡¬í”„íŠ¸ì— ì±„ì›Œì§„ ì›ë˜ ì§ˆë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Sampling parameters</span>
sampling_params = SamplingParams(temperature=<span class="hljs-number">0.2</span>, top_p=<span class="hljs-number">0.95</span>)


<span class="hljs-comment"># Invoke the vLLM model.</span>
outputs = llm.generate(prompts, sampling_params)


<span class="hljs-comment"># Print the outputs.</span>
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
   prompt = output.prompt
   generated_text = output.outputs[<span class="hljs-number">0</span>].text
   <span class="hljs-comment"># !r calls repr(), which prints a string inside quotes.</span>
   <span class="hljs-built_in">print</span>()
   <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{SAMPLE_QUESTION!r}</span>&quot;</span>)
   pprint.pprint(<span class="hljs-string">f&quot;Generated text: <span class="hljs-subst">{generated_text!r}</span>&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">Question: &#x27;What do the parameters for HNSW MEAN!?&#x27;
Generated text: &#x27;Answer: The parameters for HNSW (Hiera(rchical Navigable Small World Graph) are: &#x27;
&#x27;* M: The maximum degree of nodes on each layer oof the graph, which can improve &#x27;
&#x27;recall rate at the cost of increased search time. * efConstruction and ef: &#x27; 
&#x27;These parameters specify a search range when building or searching an index.&#x27;
<button class="copy-code-btn"></button></code></pre>
<p>ìœ„ì˜ ë‹µë³€ì´ ì™„ë²½í•´ ë³´ì…ë‹ˆë‹¤!</p>
<p>ì´ ë°ëª¨ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œë‹¤ë©´ ì§ì ‘ ì‚¬ìš©í•´ ë³´ì‹œê³  ì˜ê²¬ì„ ì•Œë ¤ì£¼ì„¸ìš”. ë˜í•œ <a href="https://discord.com/invite/8uyFbECzPX">Discordì˜ Milvus ì»¤ë®¤ë‹ˆí‹°ì—</a> ê°€ì…í•˜ì—¬ ëª¨ë“  GenAI ê°œë°œìì™€ ì§ì ‘ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</p>
<h2 id="References" class="common-anchor-header">ì°¸ê³  ìë£Œ<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p>vLLM <a href="https://docs.vllm.ai/en/latest/getting_started/installation.html">ê³µì‹ ë¬¸ì„œ</a> ë° <a href="https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models">ëª¨ë¸ í˜ì´ì§€</a>.</p></li>
<li><p><a href="https://arxiv.org/pdf/2309.06180">í˜¸ì¶œ ì£¼ì˜ì— ê´€í•œ 2023 vLLM ë…¼ë¬¸</a></p></li>
<li><p>ë ˆì´ ì„œë°‹ì—ì„œ<a href="https://www.youtube.com/watch?v=80bIUggRJf4">2023ë…„ vLLM í”„ë ˆì  í…Œì´ì…˜</a> </p></li>
<li><p>vLLM ë¸”ë¡œê·¸: <a href="https://blog.vllm.ai/2023/06/20/vllm.html">ì›í˜ì´ì§€ì–´í…ì…˜ìœ¼ë¡œ ì‰½ê³ , ë¹ ë¥´ê³ , ì €ë ´í•œ LLM ì„œë¹„ìŠ¤ ì œê³µ: vLLM</a></p></li>
<li><p>vLLM ì„œë²„ ì‹¤í–‰ì— ëŒ€í•œ ìœ ìš©í•œ ë¸”ë¡œê·¸ì…ë‹ˆë‹¤: <a href="https://ploomber.io/blog/vllm-deploy/">vLLM ë°°í¬: ë‹¨ê³„ë³„ ê°€ì´ë“œ</a></p></li>
<li><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">ë¼ë§ˆ 3 ëª¨ë¸ ë¬´ë¦¬ | ì—°êµ¬ - Metaì˜ AI</a></p></li>
</ul>
