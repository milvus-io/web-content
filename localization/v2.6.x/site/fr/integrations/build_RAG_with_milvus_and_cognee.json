{"codeList":["$ pip install pymilvus git+https://github.com/topoteretes/cognee.git\n","import os\n\nimport cognee\n\ncognee.config.set_llm_api_key(\"YOUR_OPENAI_API_KEY\")\n\n\nos.environ[\"VECTOR_DB_PROVIDER\"] = \"milvus\"\nos.environ[\"VECTOR_DB_URL\"] = \"./milvus.db\"\n","$ wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n$ unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs\n","from glob import glob\n\ntext_lines = []\n\nfor file_path in glob(\"milvus_docs/en/faq/*.md\", recursive=True):\n    with open(file_path, \"r\") as file:\n        file_text = file.read()\n\n    text_lines += file_text.split(\"# \")\n","await cognee.prune.prune_data()\nawait cognee.prune.prune_system(metadata=True)\n","await cognee.add(data=text_lines, dataset_name=\"milvus_faq\")\nawait cognee.cognify()\n\n# [DocumentChunk(id=UUID('6889e7ef-3670-555c-bb16-3eb50d1d30b0'), updated_at=datetime.datetime(2024, 12, 4, 6, 29, 46, 472907, tzinfo=datetime.timezone.utc), text='Does the query perform in memory? What are incremental data and historical data?\\n\\nYes. When ...\n# ...\n","from cognee.api.v1.search import SearchType\n\nquery_text = \"How is data stored in milvus?\"\nsearch_results = await cognee.search(SearchType.SUMMARIES, query_text=query_text)\n\nprint(search_results[0])\n","from cognee.api.v1.search import SearchType\n\nquery_text = \"How is data stored in milvus?\"\nsearch_results = await cognee.search(SearchType.CHUNKS, query_text=query_text)\n","def format_and_print(data):\n    print(\"ID:\", data[\"id\"])\n    print(\"\\nText:\\n\")\n    paragraphs = data[\"text\"].split(\"\\n\\n\")\n    for paragraph in paragraphs:\n        print(paragraph.strip())\n        print()\n\n\nformat_and_print(search_results[0])\n","await cognee.prune.prune_data()\nawait cognee.prune.prune_system(metadata=True)\n","# We only use one line of text as the dataset, which simplifies the output later\ntext = \"\"\"\n    Natural language processing (NLP) is an interdisciplinary\n    subfield of computer science and information retrieval.\n    \"\"\"\n\nawait cognee.add(text)\nawait cognee.cognify()\n","query_text = \"Tell me about NLP\"\nsearch_results = await cognee.search(SearchType.INSIGHTS, query_text=query_text)\n\nfor result_text in search_results:\n    print(result_text)\n\n# Example output:\n# ({'id': UUID('bc338a39-64d6-549a-acec-da60846dd90d'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 1, 211808, tzinfo=datetime.timezone.utc), 'name': 'natural language processing', 'description': 'An interdisciplinary subfield of computer science and information retrieval.'}, {'relationship_name': 'is_a_subfield_of', 'source_node_id': UUID('bc338a39-64d6-549a-acec-da60846dd90d'), 'target_node_id': UUID('6218dbab-eb6a-5759-a864-b3419755ffe0'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 15, 473137, tzinfo=datetime.timezone.utc)}, {'id': UUID('6218dbab-eb6a-5759-a864-b3419755ffe0'), 'updated_at': datetime.datetime(2024, 11, 21, 12, 23, 1, 211808, tzinfo=datetime.timezone.utc), 'name': 'computer science', 'description': 'The study of computation and information processing.'})\n# (...)\n#\n# It represents nodes and relationships in the knowledge graph:\n# - The first element is the source node (e.g., 'natural language processing').\n# - The second element is the relationship between nodes (e.g., 'is_a_subfield_of').\n# - The third element is the target node (e.g., 'computer science').\n"],"headingContent":"","anchorList":[{"label":"Construire RAG","href":"Build-RAG","type":2,"isActive":false}]}