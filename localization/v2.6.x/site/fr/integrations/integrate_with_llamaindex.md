---
id: integrate_with_llamaindex.md
summary: >-
  Ce guide montre comment construire un système de Génération Assistée par
  Récupération (RAG) en utilisant LlamaIndex et Milvus.
title: Génération améliorée par récupération (RAG) avec Milvus et LlamaIndex
---
<h1 id="Retrieval-Augmented-Generation-RAG-with-Milvus-and-LlamaIndex" class="common-anchor-header">Génération améliorée par récupération (RAG) avec Milvus et LlamaIndex<button data-href="#Retrieval-Augmented-Generation-RAG-with-Milvus-and-LlamaIndex" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h1><p><a href="https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/integration/rag_with_milvus_and_llamaindex.ipynb" target="_parent"><img translate="no" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
<a href="https://github.com/milvus-io/bootcamp/blob/master/integration/rag_with_milvus_and_llamaindex.ipynb" target="_blank"><img translate="no" src="https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white" alt="GitHub Repository"/></a></p>
<p>Ce guide montre comment construire un système de génération améliorée par récupération (RAG) en utilisant LlamaIndex et Milvus.</p>
<p>Le système RAG combine un système de recherche avec un modèle génératif pour générer un nouveau texte basé sur une invite donnée. Le système récupère d'abord les documents pertinents d'un corpus à l'aide de Milvus, puis utilise un modèle génératif pour générer un nouveau texte basé sur les documents récupérés.</p>
<p><a href="https://www.llamaindex.ai/">LlamaIndex</a> est un cadre de données simple et flexible permettant de connecter des sources de données personnalisées à de grands modèles de langage (LLM). <a href="https://milvus.io/">Milvus</a> est la base de données vectorielles open-source la plus avancée au monde, conçue pour alimenter les applications de recherche de similarité et d'intelligence artificielle.</p>
<p>Dans ce carnet, nous allons présenter une démonstration rapide de l'utilisation du MilvusVectorStore.</p>
<h2 id="Before-you-begin" class="common-anchor-header">Avant de commencer<button data-href="#Before-you-begin" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Install-dependencies" class="common-anchor-header">Installer les dépendances</h3><p>Les extraits de code de cette page nécessitent les dépendances pymilvus et llamaindex. Vous pouvez les installer à l'aide des commandes suivantes :</p>
<pre><code translate="no" class="language-python">$ pip install pymilvus&gt;=<span class="hljs-number">2.4</span><span class="hljs-number">.2</span>
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-python">$ pip install llama-index-vector-stores-milvus
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-python">$ pip install llama-index
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>Si vous utilisez Google Colab, pour activer les dépendances qui viennent d'être installées, vous devrez peut-être <strong>redémarrer le moteur d'exécution</strong>. (Cliquez sur le menu "Runtime" en haut de l'écran, et sélectionnez "Restart session" dans le menu déroulant).</p>
</div>
<h3 id="Setup-OpenAI" class="common-anchor-header">Configuration d'OpenAI</h3><p>Commençons par ajouter la clé api openai. Cela nous permettra d'accéder à chatgpt.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> openai

openai.api_key = <span class="hljs-string">&quot;sk-***********&quot;</span>
<button class="copy-code-btn"></button></code></pre>
<h3 id="Prepare-data" class="common-anchor-header">Préparer les données</h3><p>Vous pouvez télécharger des échantillons de données à l'aide des commandes suivantes :</p>
<pre><code translate="no" class="language-python">! mkdir -p <span class="hljs-string">&#x27;data/&#x27;</span>
! wget <span class="hljs-string">&#x27;https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt&#x27;</span> -O <span class="hljs-string">&#x27;data/paul_graham_essay.txt&#x27;</span>
! wget <span class="hljs-string">&#x27;https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf&#x27;</span> -O <span class="hljs-string">&#x27;data/uber_2021.pdf&#x27;</span>
<button class="copy-code-btn"></button></code></pre>
<h2 id="Getting-Started" class="common-anchor-header">Démarrage<button data-href="#Getting-Started" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Generate-our-data" class="common-anchor-header">Générer nos données</h3><p>Comme premier exemple, générons un document à partir du fichier <code translate="no">paul_graham_essay.txt</code>. Il s'agit d'un seul essai de Paul Graham intitulé <code translate="no">What I Worked On</code>. Pour générer les documents, nous utiliserons le SimpleDirectoryReader.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> SimpleDirectoryReader

<span class="hljs-comment"># load documents</span>
documents = SimpleDirectoryReader(
    input_files=[<span class="hljs-string">&quot;./data/paul_graham_essay.txt&quot;</span>]
).load_data()

<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Document ID:&quot;</span>, documents[<span class="hljs-number">0</span>].doc_id)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">Document ID: 95f25e4d-f270-4650-87ce-006d69d82033
</code></pre>
<h3 id="Create-an-index-across-the-data" class="common-anchor-header">Créer un index sur les données</h3><p>Maintenant que nous avons un document, nous pouvons créer un index et insérer le document. Pour l'index, nous utiliserons un MilvusVectorStore. MilvusVectorStore prend en compte quelques arguments :</p>
<h4 id="basic-args" class="common-anchor-header">arguments de base</h4><ul>
<li><code translate="no">uri (str, optional)</code>: L'URI à laquelle se connecter, sous la forme de "https://address:port" pour Milvus ou le service Zilliz Cloud, ou "path/to/local/milvus.db" pour Milvus local. La valeur par défaut est "./milvus_llamaindex.db".</li>
<li><code translate="no">token (str, optional)</code>: Le jeton de connexion. Vide si l'on n'utilise pas rbac, si l'on utilise rbac, il s'agira probablement de "username:password".</li>
<li><code translate="no">collection_name (str, optional)</code>: Le nom de la collection où les données seront stockées. La valeur par défaut est "llamalection".</li>
<li><code translate="no">overwrite (bool, optional)</code>: Si l'on veut écraser une collection existante portant le même nom. La valeur par défaut est False.</li>
</ul>
<h4 id="scalar-fields-including-doc-id--text" class="common-anchor-header">champs scalaires, y compris l'identifiant du document et le texte</h4><ul>
<li><code translate="no">doc_id_field (str, optional)</code>: Le nom du champ doc_id pour la collection. La valeur par défaut est DEFAULT_DOC_ID_KEY.</li>
<li><code translate="no">text_key (str, optional)</code>: La clé dans laquelle le texte est stocké dans la collection transmise. Utilisé lorsque vous apportez votre propre collection. La valeur par défaut est DEFAULT_TEXT_KEY.</li>
<li><code translate="no">scalar_field_names (list, optional)</code>: Les noms des champs scalaires supplémentaires à inclure dans le schéma de la collection.</li>
<li><code translate="no">scalar_field_types (list, optional)</code>: Les types des champs scalaires supplémentaires.</li>
</ul>
<h4 id="dense-field" class="common-anchor-header">champ dense</h4><ul>
<li><code translate="no">enable_dense (bool)</code>: Un indicateur booléen permettant d'activer ou de désactiver l'intégration dense. La valeur par défaut est True.</li>
<li><code translate="no">dim (int, optional)</code>: La dimension des vecteurs d'intégration pour la collection. Requis lors de la création d'une nouvelle collection si enable_sparse est False.</li>
<li><code translate="no">embedding_field (str, optional)</code>: Le nom du champ d'intégration dense pour la collection, par défaut DEFAULT_EMBEDDING_KEY.</li>
<li><code translate="no">index_config (dict, optional)</code>: La configuration utilisée pour construire l'index d'intégration dense. La valeur par défaut est None.</li>
<li><code translate="no">search_config (dict, optional)</code>: La configuration utilisée pour la recherche dans l'index dense Milvus. Notez qu'elle doit être compatible avec le type d'index spécifié par <code translate="no">index_config</code>. La valeur par défaut est None.</li>
<li><code translate="no">similarity_metric (str, optional)</code>: La métrique de similarité à utiliser pour l'intégration dense, actuellement IP, COSINE et L2.</li>
</ul>
<h4 id="sparse-field" class="common-anchor-header">champ sparse</h4><ul>
<li><code translate="no">enable_sparse (bool)</code>: Un indicateur booléen permettant d'activer ou de désactiver l'incorporation éparse. La valeur par défaut est False.</li>
<li><code translate="no">sparse_embedding_field (str)</code>: Le nom du champ d'intégration éparse, par défaut DEFAULT_SPARSE_EMBEDDING_KEY.</li>
<li><code translate="no">sparse_embedding_function (Union[BaseSparseEmbeddingFunction, BaseMilvusBuiltInFunction], optional)</code>: Si enable_sparse est True, cet objet doit être fourni pour convertir le texte en un encodage clairsemé. Si None, c'est la fonction d'incorporation éparse par défaut (BGEM3SparseEmbeddingFunction) qui sera utilisée.</li>
<li><code translate="no">sparse_index_config (dict, optional)</code>: La configuration utilisée pour construire l'index d'intégration éparse. La valeur par défaut est None.</li>
</ul>
<h4 id="hybrid-ranker" class="common-anchor-header">classeur hybride</h4><ul>
<li><p><code translate="no">hybrid_ranker (str)</code>: Spécifie le type de classificateur utilisé dans les requêtes de recherche hybrides. Actuellement, seul ["RRFRanker", "WeightedRanker"] est pris en charge. La valeur par défaut est "RRFRanker".</p></li>
<li><p><code translate="no">hybrid_ranker_params (dict, optional)</code>: Paramètres de configuration du classificateur hybride. La structure de ce dictionnaire dépend du classificateur spécifique utilisé :</p>
<ul>
<li>Pour "RRFRanker", il doit comprendre les éléments suivants<ul>
<li>"k" (int) : Paramètre utilisé dans la fusion réciproque des rangs (RRF). Cette valeur est utilisée pour calculer les scores de classement dans le cadre de l'algorithme RRF, qui combine plusieurs stratégies de classement en un seul score afin d'améliorer la pertinence de la recherche.</li>
</ul></li>
<li>Pour "WeightedRanker", il attend :<ul>
<li>"weights" (liste de flottants) : Une liste d'exactement deux poids :<ol>
<li>Le poids pour le composant d'intégration dense.</li>
<li>Ces poids sont utilisés pour ajuster l'importance des composantes denses et éparses des encastrements dans le processus de recherche hybride. Par défaut, le dictionnaire est vide, ce qui signifie que le classificateur fonctionnera avec ses paramètres prédéfinis par défaut.</li>
</ol></li>
</ul></li>
</ul></li>
</ul>
<h4 id="others" class="common-anchor-header">autres</h4><ul>
<li><code translate="no">collection_properties (dict, optional)</code>: Propriétés de la collection telles que TTL (Time-To-Live) et MMAP (memory mapping). La valeur par défaut est None. Il peut s'agir de<ul>
<li>"collection.ttl.seconds" (int) : Lorsque cette propriété est définie, les données de la collection actuelle expirent dans le délai spécifié. Les données périmées de la collection seront nettoyées et ne seront pas prises en compte dans les recherches ou les requêtes.</li>
<li>"mmap.enabled" (bool) : Permet d'activer ou non le stockage en mémoire au niveau de la collection.</li>
</ul></li>
<li><code translate="no">index_management (IndexManagement)</code>: Spécifie la stratégie de gestion d'index à utiliser. La valeur par défaut est "create_if_not_exists".</li>
<li><code translate="no">batch_size (int)</code>: Configure le nombre de documents traités dans un lot lors de l'insertion de données dans Milvus. La valeur par défaut est DEFAULT_BATCH_SIZE.</li>
<li><code translate="no">consistency_level (str, optional)</code>: Niveau de cohérence à utiliser pour une collection nouvellement créée. La valeur par défaut est "Session".</li>
</ul>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Create an index over the documents</span>
<span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> VectorStoreIndex, StorageContext
<span class="hljs-keyword">from</span> llama_index.vector_stores.milvus <span class="hljs-keyword">import</span> MilvusVectorStore


vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)
<button class="copy-code-btn"></button></code></pre>
<div class="alert note">
<p>Pour les paramètres de <code translate="no">MilvusVectorStore</code>:</p>
<ul>
<li>Définir <code translate="no">uri</code> comme un fichier local, par exemple<code translate="no">./milvus.db</code>, est la méthode la plus pratique, car elle utilise automatiquement <a href="https://milvus.io/docs/milvus_lite.md">Milvus Lite</a> pour stocker toutes les données dans ce fichier.</li>
<li>Si vous avez des données à grande échelle, vous pouvez configurer un serveur Milvus plus performant sur <a href="https://milvus.io/docs/quickstart.md">docker ou kubernetes</a>. Dans cette configuration, veuillez utiliser l'uri du serveur, par exemple<code translate="no">http://localhost:19530</code>, comme votre <code translate="no">uri</code>.</li>
<li>Si vous souhaitez utiliser <a href="https://zilliz.com/cloud">Zilliz Cloud</a>, le service cloud entièrement géré pour Milvus, adaptez les adresses <code translate="no">uri</code> et <code translate="no">token</code>, qui correspondent au <a href="https://docs.zilliz.com/docs/on-zilliz-cloud-console#free-cluster-details">point final public et à la clé Api</a> dans Zilliz Cloud.</li>
</ul>
</div>
<h3 id="Query-the-data" class="common-anchor-header">Interroger les données</h3><p>Maintenant que notre document est stocké dans l'index, nous pouvons poser des questions à l'index. L'index utilisera les données stockées en lui-même comme base de connaissances pour chatgpt.</p>
<pre><code translate="no" class="language-python">query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;What did the author learn?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The author learned that philosophy courses in college were boring to him, leading him to switch his focus to studying AI.
</code></pre>
<pre><code translate="no" class="language-python">res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges for the author as it affected his mother's health, leading to a stroke caused by colon cancer. This resulted in her losing her balance and needing to be placed in a nursing home. The author and his sister were determined to help their mother get out of the nursing home and back to her house.
</code></pre>
<p>Le test suivant montre que l'écrasement supprime les données précédentes.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core <span class="hljs-keyword">import</span> Document


vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    [Document(text=<span class="hljs-string">&quot;The number that is being searched for is ten.&quot;</span>)],
    storage_context,
)
query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;Who is the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The author is the individual who created the context information.
</code></pre>
<p>Le test suivant montre l'ajout de données supplémentaires à un index déjà existant.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">del</span> index, vector_store, storage_context, query_engine

vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, overwrite=<span class="hljs-literal">False</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)
query_engine = index.as_query_engine()
res = query_engine.query(<span class="hljs-string">&quot;What is the number?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The number is ten.
</code></pre>
<pre><code translate="no" class="language-python">res = query_engine.query(<span class="hljs-string">&quot;Who is the author?&quot;</span>)
<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">Paul Graham
</code></pre>
<h2 id="Metadata-filtering" class="common-anchor-header">Filtrage des métadonnées<button data-href="#Metadata-filtering" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>Nous pouvons générer des résultats en filtrant des sources spécifiques. L'exemple suivant illustre le chargement de tous les documents du répertoire et leur filtrage ultérieur sur la base des métadonnées.</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> llama_index.core.vector_stores <span class="hljs-keyword">import</span> ExactMatchFilter, MetadataFilters

<span class="hljs-comment"># Load all the two documents loaded before</span>
documents_all = SimpleDirectoryReader(<span class="hljs-string">&quot;./data/&quot;</span>).load_data()

vector_store = MilvusVectorStore(uri=<span class="hljs-string">&quot;./milvus_demo.db&quot;</span>, dim=<span class="hljs-number">1536</span>, overwrite=<span class="hljs-literal">True</span>)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(documents_all, storage_context)
<button class="copy-code-btn"></button></code></pre>
<p>Nous voulons récupérer uniquement les documents du fichier <code translate="no">uber_2021.pdf</code>.</p>
<pre><code translate="no" class="language-python">filters = MetadataFilters(
    filters=[ExactMatchFilter(key=<span class="hljs-string">&quot;file_name&quot;</span>, value=<span class="hljs-string">&quot;uber_2021.pdf&quot;</span>)]
)
query_engine = index.as_query_engine(filters=filters)
res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)

<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges related to the adverse impact on the business and operations, including reduced demand for Mobility offerings globally, affecting travel behavior and demand. Additionally, the pandemic led to driver supply constraints, impacted by concerns regarding COVID-19, with uncertainties about when supply levels would return to normal. The rise of the Omicron variant further affected travel, resulting in advisories and restrictions that could adversely impact both driver supply and consumer demand for Mobility offerings.
</code></pre>
<p>Nous obtenons un résultat différent lorsque nous extrayons les documents du fichier <code translate="no">paul_graham_essay.txt</code>.</p>
<pre><code translate="no" class="language-python">filters = MetadataFilters(
    filters=[ExactMatchFilter(key=<span class="hljs-string">&quot;file_name&quot;</span>, value=<span class="hljs-string">&quot;paul_graham_essay.txt&quot;</span>)]
)
query_engine = index.as_query_engine(filters=filters)
res = query_engine.query(<span class="hljs-string">&quot;What challenges did the disease pose for the author?&quot;</span>)

<span class="hljs-built_in">print</span>(res)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no">The disease posed challenges for the author as it affected his mother's health, leading to a stroke caused by colon cancer. This resulted in his mother losing her balance and needing to be placed in a nursing home. The author and his sister were determined to help their mother get out of the nursing home and back to her house.
</code></pre>
