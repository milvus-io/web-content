{"codeList":["# Replace YOUR_VLLM_ENDPOINT_URL with the actual URL (e.g., http://<service-ip>:<port>/v1/rerank)\n# Replace 'BAAI/bge-reranker-base' if you deployed a different model\n\ncurl -X 'POST' \\\n  'YOUR_VLLM_ENDPOINT_URL' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"model\": \"BAAI/bge-reranker-base\",\n  \"query\": \"What is the capital of France?\",\n  \"documents\": [\n    \"The capital of Brazil is Brasilia.\",\n    \"The capital of France is Paris.\",\n    \"Horses and cows are both animals\"\n  ]\n}'\n","from pymilvus import MilvusClient, Function, FunctionType\n\n# Connect to your Milvus server\nclient = MilvusClient(\n    uri=\"http://localhost:19530\"  # Replace with your Milvus server URI\n)\n\n# Create a vLLM Ranker function\nvllm_ranker = Function(\n    name=\"vllm_semantic_ranker\",    # Choose a descriptive name\n    input_field_names=[\"document\"],  # Field containing text to rerank\n    function_type=FunctionType.RERANK,  # Must be RERANK\n    params={\n        \"reranker\": \"model\",        # Specifies model-based reranking\n        \"provider\": \"vllm\",         # Specifies vLLM service\n        \"queries\": [\"renewable energy developments\"],  # Query text\n        \"endpoint\": \"http://localhost:8080\",  # vLLM service address\n        \"max_client_batch_size\": 32,              # Optional: batch size\n        \"truncate_prompt_tokens\": 256,  # Optional: Use last 256 tokens\n    }\n)\n","import io.milvus.v2.client.ConnectConfig;\nimport io.milvus.v2.client.MilvusClientV2;\nimport io.milvus.common.clientenum.FunctionType;\nimport io.milvus.v2.service.collection.request.CreateCollectionReq;\n\nMilvusClientV2 client = new MilvusClientV2(ConnectConfig.builder()\n        .uri(\"http://localhost:19530\")\n        .build());\n\nCreateCollectionReq.Function ranker = CreateCollectionReq.Function.builder()\n                       .functionType(FunctionType.RERANK)\n                       .name(\"vllm_semantic_ranker\")\n                       .inputFieldNames(Collections.singletonList(\"document\"))\n                       .param(\"reranker\", \"model\")\n                       .param(\"provider\", \"vllm\")\n                       .param(\"queries\", \"[\\\"renewable energy developments\\\"]\")\n                       .param(\"endpoint\", \"http://localhost:8080\")\n                       .param(\"max_client_batch_size\", \"32\")\n                       .param(\"truncate_prompt_tokens\", \"256\")\n                       .build();\n","// nodejs\n","// go\n","# restful\n","# Execute search with vLLM reranking\nresults = client.search(\n    collection_name=\"your_collection\",\n    data=[your_query_vector],  # Replace with your query vector\n    anns_field=\"dense_vector\",                   # Vector field to search\n    limit=5,                                     # Number of results to return\n    output_fields=[\"document\"],                  # Include text field for reranking\n    #  highlight-next-line\n    ranker=vllm_ranker,                         # Apply vLLM reranking\n    consistency_level=\"Bounded\"\n)\n","import io.milvus.v2.common.ConsistencyLevel;\nimport io.milvus.v2.service.vector.request.SearchReq;\nimport io.milvus.v2.service.vector.response.SearchResp;\nimport io.milvus.v2.service.vector.request.data.EmbeddedText;\n\nSearchReq searchReq = SearchReq.builder()\n        .collectionName(\"your_collection\")\n        .data(Arrays.asList(new EmbeddedText(\"AI Research Progress\"), new EmbeddedText(\"What is AI\")))\n        .annsField(\"vector_field\")\n        .limit(10)\n        .outputFields(Collections.singletonList(\"document\"))\n        .functionScore(FunctionScore.builder()\n                .addFunction(ranker)\n                .build())\n        .consistencyLevel(ConsistencyLevel.BOUNDED)\n        .build();\nSearchResp searchResp = client.search(searchReq);\n","// nodejs\n","// go\n","# restful\n","from pymilvus import AnnSearchRequest\n\n# Configure dense vector search\ndense_search = AnnSearchRequest(\n    data=[your_query_vector_1], # Replace with your query vector\n    anns_field=\"dense_vector\",\n    param={},\n    limit=5\n)\n\n# Configure sparse vector search  \nsparse_search = AnnSearchRequest(\n    data=[your_query_vector_2], # Replace with your query vector\n    anns_field=\"sparse_vector\", \n    param={},\n    limit=5\n)\n\n# Execute hybrid search with vLLM reranking\nhybrid_results = client.hybrid_search(\n    collection_name=\"your_collection\",\n    [dense_search, sparse_search],              # Multiple search requests\n    ranker=vllm_ranker,                        # Apply vLLM reranking to combined results\n    #  highlight-next-line\n    limit=5,                                   # Final number of results\n    output_fields=[\"document\"]\n)\n","import io.milvus.v2.service.vector.request.AnnSearchReq;\nimport io.milvus.v2.service.vector.request.HybridSearchReq;\nimport io.milvus.v2.service.vector.request.data.EmbeddedText;\nimport io.milvus.v2.service.vector.request.data.FloatVec;\n        \nList<AnnSearchReq> searchRequests = new ArrayList<>();\nsearchRequests.add(AnnSearchReq.builder()\n        .vectorFieldName(\"dense_vector\")\n        .vectors(Arrays.asList(new FloatVec(embedding1), new FloatVec(embedding2)))\n        .limit(5)\n        .build());\nsearchRequests.add(AnnSearchReq.builder()\n        .vectorFieldName(\"sparse_vector\")\n        .data(Arrays.asList(new EmbeddedText(\"AI Research Progress\"), new EmbeddedText(\"What is AI\")))\n        .limit(5)\n        .build());\n\nHybridSearchReq hybridSearchReq = HybridSearchReq.builder()\n                .collectionName(\"your_collection\")\n                .searchRequests(searchRequests)\n                .ranker(ranker)\n                .limit(5)\n                .outputFields(Collections.singletonList(\"document\"))\n                .build();\nSearchResp searchResp = client.hybridSearch(hybridSearchReq);\n","// nodejs\n","// go\n","# restful\n"],"headingContent":"vLLM Ranker","anchorList":[{"label":"Pemeringkat vLLMCompatible with Milvus 2.6.x","href":"vLLM-Ranker","type":1,"isActive":false},{"label":"Prasyarat","href":"Prerequisites","type":2,"isActive":false},{"label":"Membuat fungsi pemeringkat vLLM","href":"Create-a-vLLM-ranker-function","type":2,"isActive":false},{"label":"Parameter khusus pemeringkat vLLM","href":"vLLM-ranker-specific-parameters","type":3,"isActive":false},{"label":"Menerapkan ke pencarian vektor standar","href":"Apply-to-standard-vector-search","type":2,"isActive":false},{"label":"Menerapkan ke pencarian hibrida","href":"Apply-to-hybrid-search","type":2,"isActive":false}]}