{"codeList":["analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\":[{\n        \"type\": \"stop\", # Specifies the filter type as stop\n        \"stop_words\": [\"of\", \"to\", \"_english_\"], # Defines custom stop words and includes the English stop word list\n    }],\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Collections.singletonList(\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"of\", \"to\", \"_english_\"));\n                }}\n        )\n);\n","const analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\":[{\n        \"type\": \"stop\", # Specifies the filter type as stop\n        \"stop_words\": [\"of\", \"to\", \"_english_\"], # Defines custom stop words and includes the English stop word list\n    }],\n};\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n    \"filter\": []any{map[string]any{\n        \"type\":       \"stop\",\n        \"stop_words\": []string{\"of\", \"to\", \"_english_\"},\n    }}}\n","# restful\nanalyzerParams='{\n  \"tokenizer\": \"standard\",\n  \"filter\": [\n    {\n      \"type\": \"stop\",\n      \"stop_words\": [\n        \"of\",\n        \"to\",\n        \"_english_\"\n      ]\n    }\n  ]\n}'\n\n","analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\":[{\n        \"type\": \"stop\", # Specifies the filter type as stop\n        \"stop_words\": [\"of\", \"to\", \"_english_\"], # Defines custom stop words and includes the English stop word list\n    }],\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Collections.singletonList(\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"of\", \"to\", \"_english_\"));\n                }}\n        )\n);\n","// javascript\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n    \"filter\": []any{map[string]any{\n        \"type\":       \"stop\",\n        \"stop_words\": []string{\"of\", \"to\", \"_english_\"},\n    }}}\n","# restful\n","# Sample text to analyze\nsample_text = \"The stop filter allows control over common stop words for text processing.\"\n\n# Run the standard analyzer with the defined configuration\nresult = MilvusClient.run_analyzer(sample_text, analyzer_params)\nprint(result)\n","// java\n","// javascript\n","// go\n","# restful\n","['The', 'stop', 'filter', 'allows', 'control', 'over', 'common', 'stop', 'words', 'text', 'processing']\n"],"headingContent":"Stop","anchorList":[{"label":"Berhenti","href":"Stop","type":1,"isActive":false},{"label":"Konfigurasi","href":"Configuration","type":2,"isActive":false},{"label":"Contoh","href":"Examples","type":2,"isActive":false}]}