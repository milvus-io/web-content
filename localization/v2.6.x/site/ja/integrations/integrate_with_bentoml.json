{"codeList":["$ pip install -U pymilvus bentoml\n","import bentoml\n\nBENTO_EMBEDDING_MODEL_END_POINT = \"BENTO_EMBEDDING_MODEL_END_POINT\"\nBENTO_API_TOKEN = \"BENTO_API_TOKEN\"\n\nembedding_client = bentoml.SyncHTTPClient(\n    BENTO_EMBEDDING_MODEL_END_POINT, token=BENTO_API_TOKEN\n)\n","# naively chunk on newlines\ndef chunk_text(filename: str) -> list:\n    with open(filename, \"r\") as f:\n        text = f.read()\n    sentences = text.split(\"\\n\")\n    return sentences\n","import os\nimport requests\nimport urllib.request\n\n# set up the data source\nrepo = \"ytang07/bento_octo_milvus_RAG\"\ndirectory = \"data\"\nsave_dir = \"./city_data\"\napi_url = f\"https://api.github.com/repos/{repo}/contents/{directory}\"\n\n\nresponse = requests.get(api_url)\ndata = response.json()\n\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)\n\nfor item in data:\n    if item[\"type\"] == \"file\":\n        file_url = item[\"download_url\"]\n        file_path = os.path.join(save_dir, item[\"name\"])\n        urllib.request.urlretrieve(file_url, file_path)\n","# please upload your data directory under this file's folder\ncities = os.listdir(\"city_data\")\n# store chunked text for each of the cities in a list of dicts\ncity_chunks = []\nfor city in cities:\n    chunked = chunk_text(f\"city_data/{city}\")\n    cleaned = []\n    for chunk in chunked:\n        if len(chunk) > 7:\n            cleaned.append(chunk)\n    mapped = {\"city_name\": city.split(\".\")[0], \"chunks\": cleaned}\n    city_chunks.append(mapped)\n","def get_embeddings(texts: list) -> list:\n    if len(texts) > 25:\n        splits = [texts[x : x + 25] for x in range(0, len(texts), 25)]\n        embeddings = []\n        for split in splits:\n            embedding_split = embedding_client.encode(sentences=split)\n            embeddings += embedding_split\n        return embeddings\n    return embedding_client.encode(\n        sentences=texts,\n    )\n","entries = []\nfor city_dict in city_chunks:\n    # No need for the embeddings list if get_embeddings already returns a list of lists\n    embedding_list = get_embeddings(city_dict[\"chunks\"])  # returns a list of lists\n    # Now match texts with embeddings and city name\n    for i, embedding in enumerate(embedding_list):\n        entry = {\n            \"embedding\": embedding,\n            \"sentence\": city_dict[\"chunks\"][\n                i\n            ],  # Assume \"chunks\" has the corresponding texts for the embeddings\n            \"city\": city_dict[\"city_name\"],\n        }\n        entries.append(entry)\n    print(entries)\n","from pymilvus import MilvusClient\n\nCOLLECTION_NAME = \"Bento_Milvus_RAG\"  # random name for your collection\nDIMENSION = 384\n\n# Initialize a Milvus Lite client\nmilvus_client = MilvusClient(\"milvus_demo.db\")\n","from pymilvus import connections\n\nconnections.connect(uri=\"milvus_demo.db\")\n","from pymilvus import MilvusClient, DataType, Collection\n\n# Create schema\nschema = MilvusClient.create_schema(\n    auto_id=True,\n    enable_dynamic_field=True,\n)\n\n# 3.2. Add fields to schema\nschema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\nschema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n","# prepare index parameters\nindex_params = milvus_client.prepare_index_params()\n\n# add index\nindex_params.add_index(\n    field_name=\"embedding\",\n    index_type=\"AUTOINDEX\",  # use autoindex instead of other complex indexing method\n    metric_type=\"COSINE\",  # L2, COSINE, or IP\n)\n\n# create collection\nif milvus_client.has_collection(collection_name=COLLECTION_NAME):\n    milvus_client.drop_collection(collection_name=COLLECTION_NAME)\nmilvus_client.create_collection(\n    collection_name=COLLECTION_NAME, schema=schema, index_params=index_params\n)\n\n# Outside the loop, now you upsert all the entries at once\nmilvus_client.insert(collection_name=COLLECTION_NAME, data=entries)\n","BENTO_LLM_END_POINT = \"BENTO_LLM_END_POINT\"\n\nllm_client = bentoml.SyncHTTPClient(BENTO_LLM_END_POINT, token=BENTO_API_TOKEN)\n","def dorag(question: str, context: str):\n\n    prompt = (\n        f\"You are a helpful assistant. The user has a question. Answer the user question based only on the context: {context}. \\n\"\n        f\"The user question is {question}\"\n    )\n\n    results = llm_client.generate(\n        max_tokens=1024,\n        prompt=prompt,\n    )\n\n    res = \"\"\n    for result in results:\n        res += result\n\n    return res\n","question = \"What state is Cambridge in?\"\n\n\ndef ask_a_question(question):\n    embeddings = get_embeddings([question])\n    res = milvus_client.search(\n        collection_name=COLLECTION_NAME,\n        data=embeddings,  # search for the one (1) embedding returned as a list of lists\n        anns_field=\"embedding\",  # Search across embeddings\n        limit=5,  # get me the top 5 results\n        output_fields=[\"sentence\"],  # get the sentence/chunk and city\n    )\n\n    sentences = []\n    for hits in res:\n        for hit in hits:\n            print(hit)\n            sentences.append(hit[\"entity\"][\"sentence\"])\n    context = \". \".join(sentences)\n    return context\n\n\ncontext = ask_a_question(question=question)\nprint(context)\n","print(dorag(question=question, context=context))\n"],"headingContent":"Retrieval-Augmented Generation (RAG) with Milvus and BentoML","anchorList":[{"label":"Retrieval-Augmented Generation (RAG) with Milvus and BentoML","href":"Retrieval-Augmented-Generation-RAG-with-Milvus-and-BentoML","type":1,"isActive":false},{"label":"Introduction","href":"Introduction","type":2,"isActive":false},{"label":"Before you begin","href":"Before-you-begin","type":2,"isActive":false},{"label":"Serving Embeddings with BentoML/BentoCloud","href":"Serving-Embeddings-with-BentoMLBentoCloud","type":2,"isActive":false},{"label":"Inserting Data into a Vector Database for Retrieval","href":"Inserting-Data-into-a-Vector-Database-for-Retrieval","type":2,"isActive":false},{"label":"Creating Your Milvus Lite Collection","href":"Creating-Your-Milvus-Lite-Collection","type":2,"isActive":false},{"label":"Set up Your LLM for RAG","href":"Set-up-Your-LLM-for-RAG","type":2,"isActive":false},{"label":"LLM Instructions","href":"LLM-Instructions","type":2,"isActive":false},{"label":"A RAG Example","href":"A-RAG-Example","type":2,"isActive":false}]}