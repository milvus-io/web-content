{"codeList":["$ pip install --upgrade pymilvus milvus-lite openai requests tqdm\n","import os\n\nos.environ[\"FIREWORKS_API_KEY\"] = \"***********\"\n","$ wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n$ unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs\n","from glob import glob\n\ntext_lines = []\n\nfor file_path in glob(\"milvus_docs/en/faq/*.md\", recursive=True):\n    with open(file_path, \"r\") as file:\n        file_text = file.read()\n\n    text_lines += file_text.split(\"# \")\n","from openai import OpenAI\n\nfireworks_client = OpenAI(\n    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n    base_url=\"https://api.fireworks.ai/inference/v1\",\n)\n","def emb_text(text):\n    return (\n        fireworks_client.embeddings.create(\n            input=text, model=\"nomic-ai/nomic-embed-text-v1.5\"\n        )\n        .data[0]\n        .embedding\n    )\n","test_embedding = emb_text(\"This is a test\")\nembedding_dim = len(test_embedding)\nprint(embedding_dim)\nprint(test_embedding[:10])\n","from pymilvus import MilvusClient\n\nmilvus_client = MilvusClient(uri=\"./milvus_demo.db\")\n\ncollection_name = \"my_rag_collection\"\n","if milvus_client.has_collection(collection_name):\n    milvus_client.drop_collection(collection_name)\n","milvus_client.create_collection(\n    collection_name=collection_name,\n    dimension=embedding_dim,\n    metric_type=\"IP\",  # Inner product distance\n    consistency_level=\"Bounded\",  # Supported values are (`\"Strong\"`, `\"Session\"`, `\"Bounded\"`, `\"Eventually\"`). See https://milvus.io/docs/consistency.md#Consistency-Level for more details.\n)\n","from tqdm import tqdm\n\ndata = []\n\nfor i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n    data.append({\"id\": i, \"vector\": emb_text(line), \"text\": line})\n\nmilvus_client.insert(collection_name=collection_name, data=data)\n","question = \"How is data stored in milvus?\"\n","search_res = milvus_client.search(\n    collection_name=collection_name,\n    data=[\n        emb_text(question)\n    ],  # Use the `emb_text` function to convert the question to an embedding vector\n    limit=3,  # Return top 3 results\n    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n    output_fields=[\"text\"],  # Return the text field\n)\n","import json\n\nretrieved_lines_with_distances = [\n    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n]\nprint(json.dumps(retrieved_lines_with_distances, indent=4))\n","context = \"\\n\".join(\n    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n)\n","SYSTEM_PROMPT = \"\"\"\nHuman: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n\"\"\"\nUSER_PROMPT = f\"\"\"\nUse the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n<context>\n{context}\n</context>\n<question>\n{question}\n</question>\n\"\"\"\n","response = fireworks_client.chat.completions.create(\n    model=\"accounts/fireworks/models/llama-v3p1-405b-instruct\",\n    messages=[\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": USER_PROMPT},\n    ],\n)\nprint(response.choices[0].message.content)\n"],"headingContent":"Build RAG with Milvus and Fireworks AI","anchorList":[{"label":"Costruire RAG con Milvus e Fireworks AI","href":"Build-RAG-with-Milvus-and-Fireworks-AI","type":1,"isActive":false},{"label":"Preparazione","href":"Preparation","type":2,"isActive":false},{"label":"Dipendenze e ambiente","href":"Dependencies-and-Environment","type":3,"isActive":false},{"label":"Preparare i dati","href":"Prepare-the-data","type":3,"isActive":false},{"label":"Preparare l'LLM e il modello di incorporamento","href":"Prepare-the-LLM-and-Embedding-Model","type":3,"isActive":false},{"label":"Caricare i dati in Milvus","href":"Load-data-into-Milvus","type":2,"isActive":false},{"label":"Creare la raccolta","href":"Create-the-Collection","type":3,"isActive":false},{"label":"Inserire i dati","href":"Insert-data","type":3,"isActive":false},{"label":"Costruire la RAG","href":"Build-RAG","type":2,"isActive":false},{"label":"Recuperare i dati per una query","href":"Retrieve-data-for-a-query","type":3,"isActive":false},{"label":"Utilizzare LLM per ottenere una risposta RAG","href":"Use-LLM-to-get-a-RAG-response","type":3,"isActive":false}]}