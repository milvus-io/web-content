{"codeList":["$ pip install --upgrade pymilvus docling openai\n","import os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-***********\"\n","from openai import OpenAI\n\nopenai_client = OpenAI()\n","def emb_text(text):\n    return (\n        openai_client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n        .data[0]\n        .embedding\n    )\n","test_embedding = emb_text(\"This is a test\")\nembedding_dim = len(test_embedding)\nprint(embedding_dim)\nprint(test_embedding[:10])\n","from docling.document_converter import DocumentConverter\nfrom docling_core.transforms.chunker import HierarchicalChunker\n\nconverter = DocumentConverter()\nchunker = HierarchicalChunker()\n\n# Convert the input file to Docling Document\nsource = \"https://milvus.io/docs/overview.md\"\ndoc = converter.convert(source).document\n\n# Perform hierarchical chunking\ntexts = [chunk.text for chunk in chunker.chunk(doc)]\n\nfor i, text in enumerate(texts[:5]):\n    print(f\"Chunk {i+1}:\\n{text}\\n{'-'*50}\")\n","from pymilvus import MilvusClient\n\nmilvus_client = MilvusClient(uri=\"./milvus_demo.db\")\ncollection_name = \"my_rag_collection\"\n","if milvus_client.has_collection(collection_name):\n    milvus_client.drop_collection(collection_name)\n","milvus_client.create_collection(\n    collection_name=collection_name,\n    dimension=embedding_dim,\n    metric_type=\"IP\",  # Inner product distance\n    consistency_level=\"Bounded\",  # Supported values are (`\"Strong\"`, `\"Session\"`, `\"Bounded\"`, `\"Eventually\"`). See https://milvus.io/docs/consistency.md#Consistency-Level for more details.\n)\n","from tqdm import tqdm\n\ndata = []\n\nfor i, chunk in enumerate(tqdm(texts, desc=\"Processing chunks\")):\n    embedding = emb_text(chunk)\n    data.append({\"id\": i, \"vector\": embedding, \"text\": chunk})\n\nmilvus_client.insert(collection_name=collection_name, data=data)\n","question = (\n    \"What are the three deployment modes of Milvus, and what are their differences?\"\n)\n","search_res = milvus_client.search(\n    collection_name=collection_name,\n    data=[emb_text(question)],\n    limit=3,\n    search_params={\"metric_type\": \"IP\", \"params\": {}},\n    output_fields=[\"text\"],\n)\n","import json\n\nretrieved_lines_with_distances = [\n    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n]\nprint(json.dumps(retrieved_lines_with_distances, indent=4))\n","context = \"\\n\".join(\n    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n)\n","SYSTEM_PROMPT = \"\"\"\nHuman: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n\"\"\"\nUSER_PROMPT = f\"\"\"\nUse the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n<context>\n{context}\n</context>\n<question>\n{question}\n</question>\n\"\"\"\n","response = openai_client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": USER_PROMPT},\n    ],\n)\nprint(response.choices[0].message.content)\n"],"headingContent":"Build RAG with Milvus and Docling","anchorList":[{"label":"Construir RAG com Milvus e Docling","href":"Build-RAG-with-Milvus-and-Docling","type":1,"isActive":false},{"label":"Preparação","href":"Preparation","type":2,"isActive":false},{"label":"Processar dados utilizando o Docling","href":"Process-Data-Using-Docling","type":2,"isActive":false},{"label":"Carregar dados no Milvus","href":"Load-Data-into-Milvus","type":2,"isActive":false},{"label":"Criar RAG","href":"Build-RAG","type":2,"isActive":false}]}