{"codeList":["analyzer_params = {\n    \"type\": \"standard\", # Uses the standard built-in analyzer\n    \"stop_words\": [\"a\", \"an\", \"for\"] # Defines a list of common words (stop words) to exclude from tokenization\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"type\", \"standard\");\nanalyzerParams.put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n","const analyzer_params = {\n    \"type\": \"standard\", // Uses the standard built-in analyzer\n    \"stop_words\": [\"a\", \"an\", \"for\"] // Defines a list of common words (stop words) to exclude from tokenization\n};\n","analyzerParams := map[string]any{\"type\": \"standard\", \"stop_words\": []string{\"a\", \"an\", \"for\"}}\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"stop_words\": [\"a\", \"an\", \"for\"]\n    }'\n","# Sample text to analyze\ntext = \"An efficient system relies on a robust analyzer to correctly process text for various applications.\"\n\n# Run analyzer\nresult = client.run_analyzer(\n    text,\n    analyzer_params\n)\n","import io.milvus.v2.service.vector.request.RunAnalyzerReq;\nimport io.milvus.v2.service.vector.response.RunAnalyzerResp;\n\nList<String> texts = new ArrayList<>();\ntexts.add(\"An efficient system relies on a robust analyzer to correctly process text for various applications.\");\n\nRunAnalyzerResp resp = client.runAnalyzer(RunAnalyzerReq.builder()\n        .texts(texts)\n        .analyzerParams(analyzerParams)\n        .build());\nList<RunAnalyzerResp.AnalyzerResult> results = resp.getResults();\n","// javascrip# Sample text to analyze\nconst text = \"An efficient system relies on a robust analyzer to correctly process text for various applications.\"\n\n// Run analyzer\nconst result = await client.run_analyzer({\n    text,\n    analyzer_params\n});\n","import (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n\n    \"github.com/milvus-io/milvus/client/v2/milvusclient\"\n)\n\nbs, _ := json.Marshal(analyzerParams)\ntexts := []string{\"An efficient system relies on a robust analyzer to correctly process text for various applications.\"}\noption := milvusclient.NewRunAnalyzerOption(texts).\n    WithAnalyzerParams(string(bs))\n\nresult, err := client.RunAnalyzer(ctx, option)\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n","# restful\n","['efficient', 'system', 'relies', 'on', 'robust', 'analyzer', 'to', 'correctly', 'process', 'text', 'various', 'applications']\n","analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\": [\n        \"lowercase\",\n        {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n        }\n    ]\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Arrays.asList(\"lowercase\",\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n                }}));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\": [\n        \"lowercase\",\n        {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n        }\n    ]\n};\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n    \"filter\": []any{\"lowercase\", map[string]any{\n        \"type\":       \"stop\",\n        \"stop_words\": []string{\"a\", \"an\", \"for\"},\n    }}}\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"filter\":  [\n       \"lowercase\",\n       {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n       }\n   ]\n}'\n","[\"Vector\", \"Database\", \"Built\", \"for\", \"Scale\"]\n","analyzer_params = {\n    \"tokenizer\": \"whitespace\",\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"whitespace\");\n","const analyzer_params = {\n    \"tokenizer\": \"whitespace\",\n};\n","analyzerParams = map[string]any{\"tokenizer\": \"whitespace\"}\n","export analyzerParams='{\n       \"type\": \"whitespace\"\n    }'\n","[\"vector\", \"database\", \"built\", \"for\", \"scale\"]\n","analyzer_params = {\n    \"tokenizer\": \"standard\", # Mandatory: Specifies tokenizer\n    \"filter\": [\"lowercase\"], # Optional: Built-in filter that converts text to lowercase\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\", Collections.singletonList(\"lowercase\"));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\", // Mandatory: Specifies tokenizer\n    \"filter\": [\"lowercase\"], // Optional: Built-in filter that converts text to lowercase\n}\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n        \"filter\": []any{\"lowercase\"}}\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"filter\":  [\"lowercase\"]\n    }'\n","analyzer_params = {\n    \"tokenizer\": \"standard\", # Mandatory: Specifies tokenizer\n    \"filter\": [\n        {\n            \"type\": \"stop\", # Specifies 'stop' as the filter type\n            \"stop_words\": [\"of\", \"to\"], # Customizes stop words for this filter type\n        }\n    ]\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Collections.singletonList(new HashMap<String, Object>() {{\n            put(\"type\", \"stop\");\n            put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n        }}));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\", // Mandatory: Specifies tokenizer\n    \"filter\": [\n        {\n            \"type\": \"stop\", // Specifies 'stop' as the filter type\n            \"stop_words\": [\"of\", \"to\"], // Customizes stop words for this filter type\n        }\n    ]\n};\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n    \"filter\": []any{map[string]any{\n        \"type\":       \"stop\",\n        \"stop_words\": []string{\"of\", \"to\"},\n    }}}\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"filter\":  [\n       {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n       }\n    ]\n}'\n","from pymilvus import MilvusClient, DataType\n\n# Set up a Milvus client\nclient = MilvusClient(uri=\"http://localhost:19530\")\n\n# Create a new schema\nschema = client.create_schema(auto_id=True, enable_dynamic_field=False)\n","import io.milvus.v2.client.ConnectConfig;\nimport io.milvus.v2.client.MilvusClientV2;\nimport io.milvus.v2.common.DataType;\nimport io.milvus.v2.common.IndexParam;\nimport io.milvus.v2.service.collection.request.AddFieldReq;\nimport io.milvus.v2.service.collection.request.CreateCollectionReq;\n\n// Set up a Milvus client\nConnectConfig config = ConnectConfig.builder()\n        .uri(\"http://localhost:19530\")\n        .build();\nMilvusClientV2 client = new MilvusClientV2(config);\n\n// Create schema\nCreateCollectionReq.CollectionSchema schema = CreateCollectionReq.CollectionSchema.builder()\n        .enableDynamicField(false)\n        .build();\n","import { MilvusClient, DataType } from \"@zilliz/milvus2-sdk-node\";\n\n// Set up a Milvus client\nconst client = new MilvusClient(\"http://localhost:19530\");\n","import (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/milvus-io/milvus/client/v2/column\"\n    \"github.com/milvus-io/milvus/client/v2/entity\"\n    \"github.com/milvus-io/milvus/client/v2/index\"\n    \"github.com/milvus-io/milvus/client/v2/milvusclient\"\n)  \n\nctx, cancel := context.WithCancel(context.Background())\ndefer cancel()\n\ncli, err := milvusclient.New(ctx, &milvusclient.ClientConfig{\n    Address: \"localhost:19530\",\n})\nif err != nil {\n    fmt.Println(err.Error())\n    // handle err\n}\ndefer client.Close(ctx)\n\nschema := entity.NewSchema().WithAutoID(true).WithDynamicFieldEnabled(false)\n","# restful\n","# Built-in analyzer configuration for English text processing\nanalyzer_params_built_in = {\n    \"type\": \"english\"\n}\n\n# Verify built-in analyzer configuration\nsample_text = \"Milvus simplifies text analysis for search.\"\nresult = client.run_analyzer(sample_text, analyzer_params_built_in)\nprint(\"Built-in analyzer output:\", result)\n\n# Expected output:\n# Built-in analyzer output: ['milvus', 'simplifi', 'text', 'analysi', 'search']\n\n","Map<String, Object> analyzerParamsBuiltin = new HashMap<>();\nanalyzerParamsBuiltin.put(\"type\", \"english\");\n\nList<String> texts = new ArrayList<>();\ntexts.add(\"Milvus simplifies text ana\n\nlysis for search.\");\n\nRunAnalyzerResp resp = client.runAnalyzer(RunAnalyzerReq.builder()\n        .texts(texts)\n        .analyzerParams(analyzerParams)\n        .build());\nList<RunAnalyzerResp.AnalyzerResult> results = resp.getResults();\n\n","// Use a built-in analyzer for VARCHAR field `title_en`\nconst analyzerParamsBuiltIn = {\n  type: \"english\",\n};\n\nconst sample_text = \"Milvus simplifies text analysis for search.\";\nconst result = await client.run_analyzer({\n    text: sample_text, \n    analyzer_params: analyzer_params_built_in\n});\n\n","analyzerParams := map[string]any{\"type\": \"english\"}\n\nbs, _ := json.Marshal(analyzerParams)\ntexts := []string{\"Milvus simplifies text analysis for search.\"}\noption := milvusclient.NewRunAnalyzerOption(texts).\n    WithAnalyzerParams(string(bs))\n\nresult, err := client.RunAnalyzer(ctx, option)\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n\n","# restful\n","# Custom analyzer configuration with a standard tokenizer and custom filters\nanalyzer_params_custom = {\n    \"tokenizer\": \"standard\",\n    \"filter\": [\n        \"lowercase\",  # Built-in filter: convert tokens to lowercase\n        {\n            \"type\": \"length\",  # Custom filter: restrict token length\n            \"max\": 40\n        },\n        {\n            \"type\": \"stop\",  # Custom filter: remove specified stop words\n            \"stop_words\": [\"of\", \"for\"]\n        }\n    ]\n}\n\n# Verify custom analyzer configuration\nsample_text = \"Milvus provides flexible, customizable analyzers for robust text processing.\"\nresult = client.run_analyzer(sample_text, analyzer_params_custom)\nprint(\"Custom analyzer output:\", result)\n\n# Expected output:\n# Custom analyzer output: ['milvus', 'provides', 'flexible', 'customizable', 'analyzers', 'robust', 'text', 'processing']\n\n","// Configure a custom analyzer\nMap<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Arrays.asList(\"lowercase\",\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"length\");\n                    put(\"max\", 40);\n                }},\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"of\", \"for\"));\n                }}\n        )\n);\n\nList<String> texts = new ArrayList<>();\ntexts.add(\"Milvus provides flexible, customizable analyzers for robust text processing.\");\n\nRunAnalyzerResp resp = client.runAnalyzer(RunAnalyzerReq.builder()\n        .texts(texts)\n        .analyzerParams(analyzerParams)\n        .build());\nList<RunAnalyzerResp.AnalyzerResult> results = resp.getResults();\n","// Configure a custom analyzer for VARCHAR field `title`\nconst analyzerParamsCustom = {\n  tokenizer: \"standard\",\n  filter: [\n    \"lowercase\",\n    {\n      type: \"length\",\n      max: 40,\n    },\n    {\n      type: \"stop\",\n      stop_words: [\"of\", \"to\"],\n    },\n  ],\n};\nconst sample_text = \"Milvus provides flexible, customizable analyzers for robust text processing.\";\nconst result = await client.run_analyzer({\n    text: sample_text, \n    analyzer_params: analyzer_params_built_in\n});\n","analyzerParams = map[string]any{\"tokenizer\": \"standard\",\n    \"filter\": []any{\"lowercase\", \n    map[string]any{\n        \"type\": \"length\",\n        \"max\":  40,\n    map[string]any{\n        \"type\": \"stop\",\n        \"stop_words\": []string{\"of\", \"to\"},\n    }}}\n    \nbs, _ := json.Marshal(analyzerParams)\ntexts := []string{\"Milvus provides flexible, customizable analyzers for robust text processing.\"}\noption := milvusclient.NewRunAnalyzerOption(texts).\n    WithAnalyzerParams(string(bs))\n\nresult, err := client.RunAnalyzer(ctx, option)\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n","# curl\n","# Add VARCHAR field 'title_en' using the built-in analyzer configuration\nschema.add_field(\n    field_name='title_en',\n    datatype=DataType.VARCHAR,\n    max_length=1000,\n    enable_analyzer=True,\n    analyzer_params=analyzer_params_built_in,\n    enable_match=True,\n)\n\n# Add VARCHAR field 'title' using the custom analyzer configuration\nschema.add_field(\n    field_name='title',\n    datatype=DataType.VARCHAR,\n    max_length=1000,\n    enable_analyzer=True,\n    analyzer_params=analyzer_params_custom,\n    enable_match=True,\n)\n\n# Add a vector field for embeddings\nschema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, dim=3)\n\n# Add a primary key field\nschema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n","schema.addField(AddFieldReq.builder()\n        .fieldName(\"title\")\n        .dataType(DataType.VarChar)\n        .maxLength(1000)\n        .enableAnalyzer(true)\n        .analyzerParams(analyzerParams)\n        .enableMatch(true) // must enable this if you use TextMatch\n        .build());\n\n// Add vector field\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"embedding\")\n        .dataType(DataType.FloatVector)\n        .dimension(3)\n        .build());\n// Add primary field\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"id\")\n        .dataType(DataType.Int64)\n        .isPrimaryKey(true)\n        .autoID(true)\n        .build());\n","// Create schema\nconst schema = {\n  auto_id: true,\n  fields: [\n    {\n      name: \"id\",\n      type: DataType.INT64,\n      is_primary: true,\n    },\n    {\n      name: \"title_en\",\n      data_type: DataType.VARCHAR,\n      max_length: 1000,\n      enable_analyzer: true,\n      analyzer_params: analyzerParamsBuiltIn,\n      enable_match: true,\n    },\n    {\n      name: \"title\",\n      data_type: DataType.VARCHAR,\n      max_length: 1000,\n      enable_analyzer: true,\n      analyzer_params: analyzerParamsCustom,\n      enable_match: true,\n    },\n    {\n      name: \"embedding\",\n      data_type: DataType.FLOAT_VECTOR,\n      dim: 4,\n    },\n  ],\n};\n","schema.WithField(entity.NewField().\n    WithName(\"id\").\n    WithDataType(entity.FieldTypeInt64).\n    WithIsPrimaryKey(true).\n    WithIsAutoID(true),\n).WithField(entity.NewField().\n    WithName(\"embedding\").\n    WithDataType(entity.FieldTypeFloatVector).\n    WithDim(3),\n).WithField(entity.NewField().\n    WithName(\"title\").\n    WithDataType(entity.FieldTypeVarChar).\n    WithMaxLength(1000).\n    WithEnableAnalyzer(true).\n    WithAnalyzerParams(analyzerParams).\n    WithEnableMatch(true),\n)\n","# restful\n","# Set up index parameters for the vector field\nindex_params = client.prepare_index_params()\nindex_params.add_index(field_name=\"embedding\", metric_type=\"COSINE\", index_type=\"AUTOINDEX\")\n\n# Create the collection with the defined schema and index parameters\nclient.create_collection(\n    collection_name=\"my_collection\",\n    schema=schema,\n    index_params=index_params\n)\n","// Set up index params for vector field\nList<IndexParam> indexes = new ArrayList<>();\nindexes.add(IndexParam.builder()\n        .fieldName(\"embedding\")\n        .indexType(IndexParam.IndexType.AUTOINDEX)\n        .metricType(IndexParam.MetricType.COSINE)\n        .build());\n\n// Create collection with defined schema\nCreateCollectionReq requestCreate = CreateCollectionReq.builder()\n        .collectionName(\"my_collection\")\n        .collectionSchema(schema)\n        .indexParams(indexes)\n        .build();\nclient.createCollection(requestCreate);\n","// Set up index params for vector field\nconst indexParams = [\n  {\n    name: \"embedding\",\n    metric_type: \"COSINE\",\n    index_type: \"AUTOINDEX\",\n  },\n];\n\n// Create collection with defined schema\nawait client.createCollection({\n  collection_name: \"my_collection\",\n  schema: schema,\n  index_params: indexParams,\n});\n\nconsole.log(\"Collection created successfully!\");\n","idx := index.NewAutoIndex(index.MetricType(entity.COSINE))\nindexOption := milvusclient.NewCreateIndexOption(\"my_collection\", \"embedding\", idx)\n\nerr = client.CreateCollection(ctx,\n    milvusclient.NewCreateCollectionOption(\"my_collection\", schema).\n        WithIndexOptions(indexOption))\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n","# restful\n"],"headingContent":"Analyzer Overview","anchorList":[{"label":"Descrição geral do analisador","href":"Analyzer-Overview","type":1,"isActive":false},{"label":"Anatomia de um analisador","href":"Anatomy-of-an-analyzer","type":2,"isActive":false},{"label":"Tipos de analisadores","href":"Analyzer-types","type":2,"isActive":false},{"label":"Exemplo de utilização","href":"Example-use","type":2,"isActive":false}]}