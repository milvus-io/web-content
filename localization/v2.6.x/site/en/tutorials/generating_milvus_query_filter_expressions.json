{"codeList":["$ pip install --upgrade pymilvus openai requests docling beautifulsoup4\nprint(\"Environment setup complete!\")\n","import os\nimport openai\n\nos.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\napi_key = os.getenv(\"OPENAI_API_KEY\")\n\nif not api_key:\n    raise ValueError(\"Please set the OPENAI_API_KEY environment variable!\")\n\nopenai.api_key = api_key\nprint(\"API key loaded.\")\n","from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\nimport os\nfrom openai import OpenAI\nimport uuid\n\nclient = MilvusClient(uri=\"http://localhost:19530\")\nopenai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\nembedding_model = \"text-embedding-3-small\"\nembedding_dim = 1536\n\nfields = [\n    FieldSchema(\n        name=\"pk\",\n        dtype=DataType.VARCHAR,\n        is_primary=True,\n        auto_id=False,\n        max_length=100,\n    ),\n    FieldSchema(name=\"name\", dtype=DataType.VARCHAR, max_length=128),\n    FieldSchema(name=\"age\", dtype=DataType.INT64),\n    FieldSchema(name=\"city\", dtype=DataType.VARCHAR, max_length=128),\n    FieldSchema(name=\"hobby\", dtype=DataType.VARCHAR, max_length=128),\n    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),\n]\nschema = CollectionSchema(fields=fields, description=\"User data embedding example\")\ncollection_name = \"user_data_collection\"\n\nif client.has_collection(collection_name):\n    client.drop_collection(collection_name)\n# Strong consistency waits for all loads to complete, adding latency with large datasets\n# client.create_collection(\n#     collection_name=collection_name, schema=schema, consistency_level=\"Strong\"\n# )\nclient.create_collection(collection_name=collection_name, schema=schema)\n\nindex_params = client.prepare_index_params()\nindex_params.add_index(\n    field_name=\"embedding\",\n    index_type=\"IVF_FLAT\",\n    metric_type=\"COSINE\",\n    params={\"nlist\": 128},\n)\nclient.create_index(collection_name=collection_name, index_params=index_params)\n\ndata_to_insert = [\n    {\"name\": \"John\", \"age\": 23, \"city\": \"Shanghai\", \"hobby\": \"Drinking coffee\"},\n    {\"name\": \"Alice\", \"age\": 29, \"city\": \"New York\", \"hobby\": \"Reading books\"},\n    {\"name\": \"Bob\", \"age\": 31, \"city\": \"London\", \"hobby\": \"Playing chess\"},\n    {\"name\": \"Eve\", \"age\": 27, \"city\": \"Paris\", \"hobby\": \"Painting\"},\n    {\"name\": \"Charlie\", \"age\": 35, \"city\": \"Tokyo\", \"hobby\": \"Cycling\"},\n    {\"name\": \"Grace\", \"age\": 22, \"city\": \"Berlin\", \"hobby\": \"Photography\"},\n    {\"name\": \"David\", \"age\": 40, \"city\": \"Toronto\", \"hobby\": \"Watching movies\"},\n    {\"name\": \"Helen\", \"age\": 30, \"city\": \"Sydney\", \"hobby\": \"Cooking\"},\n    {\"name\": \"Frank\", \"age\": 28, \"city\": \"Beijing\", \"hobby\": \"Hiking\"},\n    {\"name\": \"Ivy\", \"age\": 26, \"city\": \"Seoul\", \"hobby\": \"Dancing\"},\n    {\"name\": \"Tom\", \"age\": 33, \"city\": \"Madrid\", \"hobby\": \"Writing\"},\n]\n\n\ndef get_embeddings(texts):\n    return [\n        rec.embedding\n        for rec in openai_client.embeddings.create(\n            input=texts, model=embedding_model, dimensions=embedding_dim\n        ).data\n    ]\n\n\ntexts = [\n    f\"{item['name']} from {item['city']} is {item['age']} years old and likes {item['hobby']}.\"\n    for item in data_to_insert\n]\nembeddings = get_embeddings(texts)\n\ninsert_data = []\nfor item, embedding in zip(data_to_insert, embeddings):\n    item_with_embedding = {\n        \"pk\": str(uuid.uuid4()),\n        \"name\": item[\"name\"],\n        \"age\": item[\"age\"],\n        \"city\": item[\"city\"],\n        \"hobby\": item[\"hobby\"],\n        \"embedding\": embedding,\n    }\n    insert_data.append(item_with_embedding)\n\nclient.insert(collection_name=collection_name, data=insert_data)\n\nprint(f\"Collection '{collection_name}' has been created and data has been inserted.\")\n","from pymilvus import MilvusClient\nimport os\nfrom openai import OpenAI\n\nclient = MilvusClient(uri=\"http://localhost:19530\")\ncollection_name = \"user_data_collection\"\n\nclient.load_collection(collection_name=collection_name)\n\nresult = client.query(\n    collection_name=collection_name,\n    filter=\"\",\n    output_fields=[\"name\", \"age\", \"city\", \"hobby\"],\n    limit=3,\n)\n\nfor record in result:\n    print(record)\n","import docling\nfrom docling.document_converter import DocumentConverter\n\nconverter = DocumentConverter()\ndocs = [\n    converter.convert(url)\n    for url in [\n        \"https://milvus.io/docs/boolean.md\",\n        \"https://milvus.io/docs/basic-operators.md\",\n        \"https://milvus.io/docs/filtering-templating.md\",\n    ]\n]\n\nfor doc in docs[:3]:\n    print(doc.document.export_to_markdown())\n","from openai import OpenAI\nimport json\nfrom IPython.display import display, Markdown\n\ncontext = \"\\n\".join([doc.document.export_to_markdown() for doc in docs])\n\nprompt = f\"\"\"\nYou are an expert Milvus vector database engineer. Your task is to convert a user's natural language query into a valid Milvus filter expression, using the provided Milvus documentation as your knowledge base.\n\nFollow these rules strictly:\n1. Only use the provided documents as your source of knowledge.\n2. Ensure the generated filter expression is syntactically correct.\n3. If there isn't enough information in the documents to create an expression, state that directly.\n4. Only return the final filter expression. Do not include any explanations or extra text.\n\n---\n**Milvus Documentation Context:**\n{context}\n\n---\n**User Query:**\n{user_query}\n\n---\n**Filter Expression:**\n\"\"\"\n\nclient = OpenAI()\n\n\ndef generate_filter_expr(user_query):\n    \"\"\"\n    Generates a Milvus filter expression from a user query using GPT-4o-mini.\n    \"\"\"\n    completion = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": prompt},\n            {\"role\": \"user\", \"content\": user_query},\n        ],\n        temperature=0.0,\n    )\n    return completion.choices[0].message.content\n\n\nuser_query = \"Find people older than 30 who live in London, Tokyo, or Toronto\"\n\nfilter_expr = generate_filter_expr(user_query)\n\nprint(f\"Generated filter expression: {filter_expr}\")\n","from pymilvus import MilvusClient\nfrom openai import OpenAI\nimport os\n\nclient = MilvusClient(uri=\"http://localhost:19530\")\nopenai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n\nclean_filter = (\n    filter_expr.replace(\"```\", \"\").replace('filter=\"', \"\").replace('\"', \"\").strip()\n)\nprint(f\"Using filter: {clean_filter}\")\n\nquery_embedding = (\n    openai_client.embeddings.create(\n        input=[user_query], model=\"text-embedding-3-small\", dimensions=1536\n    )\n    .data[0]\n    .embedding\n)\n\nsearch_results = client.search(\n    collection_name=\"user_data_collection\",\n    data=[query_embedding],\n    limit=10,\n    filter=clean_filter,\n    output_fields=[\"pk\", \"name\", \"age\", \"city\", \"hobby\"],\n    search_params={\n        \"metric_type\": \"COSINE\",\n        \"params\": {\"nprobe\": 10},\n    },\n)\n\nprint(\"Search results:\")\nfor i, hits in enumerate(search_results):\n    print(f\"Query {i}:\")\n    for hit in hits:\n        print(f\"  - {hit}\")\n    print()\n"],"headingContent":"Generating Milvus Query Filter Expressions with Large Language Models","anchorList":[{"label":"Generating Milvus Query Filter Expressions with Large Language Models","href":"Generating-Milvus-Query-Filter-Expressions-with-Large-Language-Models","type":1,"isActive":false},{"label":"Dependencies and Environment","href":"Dependencies-and-Environment","type":2,"isActive":false},{"label":"Set up environment variables","href":"Set-up-environment-variables","type":2,"isActive":false},{"label":"Create a Sample Collection","href":"Create-a-Sample-Collection","type":2,"isActive":false},{"label":"Print 3 sample data","href":"Print-3-sample-data","type":2,"isActive":false},{"label":"Collecting Milvus Filter Expression Documentation","href":"Collecting-Milvus-Filter-Expression-Documentation","type":2,"isActive":false},{"label":"LLM-Powered Filter Generation","href":"LLM-Powered-Filter-Generation","type":2,"isActive":false},{"label":"Test the Generated Filter","href":"Test-the-Generated-Filter","type":2,"isActive":false},{"label":"Results Analysis","href":"Results-Analysis","type":2,"isActive":false}]}