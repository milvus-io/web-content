{"codeList":["pip install --upgrade pymilvus\npip install \"pymilvus[model]\"\n","from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n\nbge_m3_ef = BGEM3EmbeddingFunction(\n    model_name='BAAI/bge-m3', # Specify the model name\n    device='cpu', # Specify the device to use, e.g., 'cpu' or 'cuda:0'\n    use_fp16=False # Specify whether to use fp16. Set to `False` if `device` is `cpu`.\n)\n","docs = [\n    \"Artificial intelligence was founded as an academic discipline in 1956.\",\n    \"Alan Turing was the first person to conduct substantial research in AI.\",\n    \"Born in Maida Vale, London, Turing was raised in southern England.\",\n]\n\ndocs_embeddings = bge_m3_ef.encode_documents(docs)\n\n# Print embeddings\nprint(\"Embeddings:\", docs_embeddings)\n# Print dimension of dense embeddings\nprint(\"Dense document dim:\", bge_m3_ef.dim[\"dense\"], docs_embeddings[\"dense\"][0].shape)\n# Since the sparse embeddings are in a 2D csr_array format, we convert them to a list for easier manipulation.\nprint(\"Sparse document dim:\", bge_m3_ef.dim[\"sparse\"], list(docs_embeddings[\"sparse\"])[0].shape)\n","Embeddings: {'dense': [array([-0.02505937, -0.00142193,  0.04015467, ..., -0.02094924,\n        0.02623661,  0.00324098], dtype=float32), array([ 0.00118463,  0.00649292, -0.00735763, ..., -0.01446293,\n        0.04243685, -0.01794822], dtype=float32), array([ 0.00415287, -0.0101492 ,  0.0009811 , ..., -0.02559666,\n        0.08084674,  0.00141647], dtype=float32)], 'sparse': <3x250002 sparse array of type '<class 'numpy.float32'>'\n        with 43 stored elements in Compressed Sparse Row format>}\nDense document dim: 1024 (1024,)\nSparse document dim: 250002 (1, 250002)\n","queries = [\"When was artificial intelligence founded\", \n           \"Where was Alan Turing born?\"]\n\nquery_embeddings = bge_m3_ef.encode_queries(queries)\n\n# Print embeddings\nprint(\"Embeddings:\", query_embeddings)\n# Print dimension of dense embeddings\nprint(\"Dense query dim:\", bge_m3_ef.dim[\"dense\"], query_embeddings[\"dense\"][0].shape)\n# Since the sparse embeddings are in a 2D csr_array format, we convert them to a list for easier manipulation.\nprint(\"Sparse query dim:\", bge_m3_ef.dim[\"sparse\"], list(query_embeddings[\"sparse\"])[0].shape)\n","Embeddings: {'dense': [array([-0.02024024, -0.01514386,  0.02380808, ...,  0.00234648,\n       -0.00264978, -0.04317448], dtype=float32), array([ 0.00648045, -0.0081542 , -0.02717067, ..., -0.00380103,\n        0.04200587, -0.01274772], dtype=float32)], 'sparse': <2x250002 sparse array of type '<class 'numpy.float32'>'\n        with 14 stored elements in Compressed Sparse Row format>}\nDense query dim: 1024 (1024,)\nSparse query dim: 250002 (1, 250002)\n"],"headingContent":"BGE M3","anchorList":[{"label":"BGE M3","href":"BGE-M3","type":1,"isActive":false}]}