{"codeList":["multi_analyzer_params = {\n  # Define language-specific analyzers\n  # Each analyzer follows this format: <analyzer_name>: <analyzer_params>\n  \"analyzers\": {\n    \"english\": {\"type\": \"english\"},          # English-optimized analyzer\n    \"chinese\": {\"type\": \"chinese\"},          # Chinese-optimized analyzer\n    \"default\": {\"tokenizer\": \"icu\"}          # Required fallback analyzer\n  },\n  \"by_field\": \"language\",                    # Field determining analyzer selection\n  \"alias\": {\n    \"cn\": \"chinese\",                         # Use \"cn\" as shorthand for Chinese\n    \"en\": \"english\"                          # Use \"en\" as shorthand for English\n  }\n}\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"analyzers\", new HashMap<String, Object>() {{\n    put(\"english\", new HashMap<String, Object>() {{\n        put(\"type\", \"english\");\n    }});\n    put(\"chinese\", new HashMap<String, Object>() {{\n        put(\"type\", \"chinese\");\n    }});\n    put(\"default\", new HashMap<String, Object>() {{\n        put(\"tokenizer\", \"icu\");\n    }});\n}});\nanalyzerParams.put(\"by_field\", \"language\");\nanalyzerParams.put(\"alias\", new HashMap<String, Object>() {{\n    put(\"cn\", \"chinese\");\n    put(\"en\", \"english\");\n}});\n","const multi_analyzer_params = {\n  // Define language-specific analyzers\n  // Each analyzer follows this format: <analyzer_name>: <analyzer_params>\n  \"analyzers\": {\n    \"english\": {\"type\": \"english\"},          # English-optimized analyzer\n    \"chinese\": {\"type\": \"chinese\"},          # Chinese-optimized analyzer\n    \"default\": {\"tokenizer\": \"icu\"}          # Required fallback analyzer\n  },\n  \"by_field\": \"language\",                    # Field determining analyzer selection\n  \"alias\": {\n    \"cn\": \"chinese\",                         # Use \"cn\" as shorthand for Chinese\n    \"en\": \"english\"                          # Use \"en\" as shorthand for English\n  }\n}\n","multiAnalyzerParams := map[string]any{\n    \"analyzers\": map[string]any{\n        \"english\": map[string]string{\"type\": \"english\"},\n        \"chinese\": map[string]string{\"type\": \"chinese\"},\n        \"default\": map[string]string{\"tokenizer\": \"icu\"},\n    },\n    \"by_field\": \"language\",\n    \"alias\": map[string]string{\n        \"cn\": \"chinese\",\n        \"en\": \"english\",\n    },\n}\n","# restful\nexport multi_analyzer_params='{\n  \"analyzers\": {\n    \"english\": {\n      \"type\": \"english\"\n    },\n    \"chinese\": {\n      \"type\": \"chinese\"\n    },\n    \"default\": {\n      \"tokenizer\": \"icu\"\n    }\n  },\n  \"by_field\": \"language\",\n  \"alias\": {\n    \"cn\": \"chinese\",\n    \"en\": \"english\"\n  }\n}'\n\n","# Import required modules\nfrom pymilvus import MilvusClient, DataType, Function, FunctionType\n\n# Initialize client\nclient = MilvusClient(\n    uri=\"http://localhost:19530\",\n)\n\n# Initialize a new schema\nschema = client.create_schema()\n\n# Step 2.1: Add a primary key field for unique document identification\nschema.add_field(\n    field_name=\"id\",                  # Field name\n    datatype=DataType.INT64,          # Integer data type\n    is_primary=True,                  # Designate as primary key\n    auto_id=True                      # Auto-generate IDs (recommended)\n)\n\n# Step 2.2: Add language identifier field\n# This MUST match the \"by_field\" value in language_analyzer_config\nschema.add_field(\n    field_name=\"language\",       # Field name\n    datatype=DataType.VARCHAR,   # String data type\n    max_length=255               # Maximum length (adjust as needed)\n)\n\n# Step 2.3: Add text content field with multi-language analysis capability\nschema.add_field(\n    field_name=\"text\",                           # Field name\n    datatype=DataType.VARCHAR,                   # String data type\n    max_length=8192,                             # Maximum length (adjust based on expected text size)\n    enable_analyzer=True,                        # Enable text analysis\n    multi_analyzer_params=multi_analyzer_params  # Connect with our language analyzers\n)\n\n# Step 2.4: Add sparse vector field to store the BM25 output\nschema.add_field(\n    field_name=\"sparse\",                   # Field name\n    datatype=DataType.SPARSE_FLOAT_VECTOR  # Sparse vector data type\n)\n","import com.google.gson.JsonObject;\nimport io.milvus.common.clientenum.FunctionType;\nimport io.milvus.v2.client.ConnectConfig;\nimport io.milvus.v2.client.MilvusClientV2;\nimport io.milvus.v2.common.DataType;\nimport io.milvus.v2.common.IndexParam;\nimport io.milvus.v2.service.collection.request.AddFieldReq;\nimport io.milvus.v2.service.collection.request.CreateCollectionReq;\nimport io.milvus.v2.service.collection.request.DropCollectionReq;\nimport io.milvus.v2.service.utility.request.FlushReq;\nimport io.milvus.v2.service.vector.request.InsertReq;\nimport io.milvus.v2.service.vector.request.SearchReq;\nimport io.milvus.v2.service.vector.request.data.EmbeddedText;\nimport io.milvus.v2.service.vector.response.SearchResp;\n\nMilvusClientV2 client = new MilvusClientV2(ConnectConfig.builder()\n        .uri(\"http://localhost:19530\")\n        .build());\n        \nCreateCollectionReq.CollectionSchema collectionSchema = CreateCollectionReq.CollectionSchema.builder()\n        .build();\n        \ncollectionSchema.addField(AddFieldReq.builder()\n        .fieldName(\"id\")\n        .dataType(DataType.Int64)\n        .isPrimaryKey(true)\n        .autoID(true)\n        .build());\n        \ncollectionSchema.addField(AddFieldReq.builder()\n        .fieldName(\"language\")\n        .dataType(DataType.VarChar)\n        .maxLength(255)\n        .build());\n\ncollectionSchema.addField(AddFieldReq.builder()\n        .fieldName(\"text\")\n        .dataType(DataType.VarChar)\n        .maxLength(8192)\n        .enableAnalyzer(true)\n        .multiAnalyzerParams(analyzerParams)\n        .build());\n        \ncollectionSchema.addField(AddFieldReq.builder()\n        .fieldName(\"sparse\")\n        .dataType(DataType.SparseFloatVector)\n        .build());\n","import { MilvusClient, DataType, FunctionType } from \"@zilliz/milvus2-sdk-node\";\n\n// Initialize client\nconst client = new MilvusClient({\n  address: \"http://localhost:19530\",\n});\n\n// Initialize schema array\nconst schema = [\n  {\n    name: \"id\",\n    data_type: DataType.Int64,\n    is_primary_key: true,\n    auto_id: true,\n  },\n  {\n    name: \"language\",\n    data_type: DataType.VarChar,\n    max_length: 255,\n  },\n  {\n    name: \"text\",\n    data_type: DataType.VarChar,\n    max_length: 8192,\n    enable_analyzer: true,\n    analyzer_params: multi_analyzer_params,\n  },\n  {\n    name: \"sparse\",\n    data_type: DataType.SparseFloatVector,\n  },\n];\n\n","import (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/milvus-io/milvus/client/v2/column\"\n    \"github.com/milvus-io/milvus/client/v2/entity\"\n    \"github.com/milvus-io/milvus/client/v2/index\"\n    \"github.com/milvus-io/milvus/client/v2/milvusclient\"\n)\n\nclient, err := milvusclient.New(ctx, &milvusclient.ClientConfig{\n    Address: \"localhost:19530\",\n    APIKey:  \"root:Milvus\",\n})\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n\nschema := entity.NewSchema()\n\nschema.WithField(entity.NewField().\n    WithName(\"id\").\n    WithDataType(entity.FieldTypeInt64).\n    WithIsPrimaryKey(true).\n    WithIsAutoID(true),\n).WithField(entity.NewField().\n    WithName(\"language\").\n    WithDataType(entity.FieldTypeVarChar).\n    WithMaxLength(255),\n).WithField(entity.NewField().\n    WithName(\"text\").\n    WithDataType(entity.FieldTypeVarChar).\n    WithMaxLength(8192).\n    WithEnableAnalyzer(true).\n    WithMultiAnalyzerParams(multiAnalyzerParams),\n).WithField(entity.NewField().\n    WithName(\"sparse\").\n    WithDataType(entity.FieldTypeSparseVector),\n)\n","# restful\nexport TOKEN=\"root:Milvus\"\nexport CLUSTER_ENDPOINT=\"http://localhost:19530\"\n\nexport idField='{\n  \"fieldName\": \"id\",\n  \"dataType\": \"Int64\",\n  \"isPrimary\": true,\n  \"autoID\": true\n}'\n\nexport languageField='{\n  \"fieldName\": \"language\",\n  \"dataType\": \"VarChar\",\n  \"elementTypeParams\": {\n    \"max_length\": 255\n  }\n}'\n\nexport textField='{\n  \"fieldName\": \"text\",\n  \"dataType\": \"VarChar\",\n  \"elementTypeParams\": {\n    \"max_length\": 8192,\n    \"enable_analyzer\": true\n  },\n  \"multiAnalyzerParam\": '\"$multi_analyzer_params\"'\n}'\n\nexport sparseField='{\n  \"fieldName\": \"sparse\",\n  \"dataType\": \"SparseFloatVector\"\n}'\n","# Create the BM25 function\nbm25_function = Function(\n    name=\"text_to_vector\",            # Descriptive function name\n    function_type=FunctionType.BM25,  # Use BM25 algorithm\n    input_field_names=[\"text\"],       # Process text from this field\n    output_field_names=[\"sparse\"]     # Store vectors in this field\n)\n\n# Add the function to our schema\nschema.add_function(bm25_function)\n","CreateCollectionReq.Function function = CreateCollectionReq.Function.builder()\n        .functionType(FunctionType.BM25)\n        .name(\"text_to_vector\")\n        .inputFieldNames(Collections.singletonList(\"text\"))\n        .outputFieldNames(Collections.singletonList(\"sparse\"))\n        .build();\ncollectionSchema.addFunction(function);\n","const functions = [\n  {\n    name: \"text_bm25_emb\",\n    description: \"bm25 function\",\n    type: FunctionType.BM25,\n    input_field_names: [\"text\"],\n    output_field_names: [\"sparse\"],\n    params: {},\n  },\n];\n","function := entity.NewFunction()\nschema.WithFunction(function.WithName(\"text_to_vector\").\n    WithType(entity.FunctionTypeBM25).\n    WithInputFields(\"text\").\n    WithOutputFields(\"sparse\"))\n","# restful\nexport function='{\n  \"name\": \"text_to_vector\",\n  \"type\": \"BM25\",\n  \"inputFieldNames\": [\"text\"],\n  \"outputFieldNames\": [\"sparse\"]\n}'\n\nexport schema=\"{\n  \\\"autoID\\\": true,\n  \\\"fields\\\": [\n    $idField,\n    $languageField,\n    $textField,\n    $sparseField\n  ],\n  \\\"functions\\\": [\n    $function\n  ]\n}\"\n","# Configure index parameters\nindex_params = client.prepare_index_params()\n\n# Add index for sparse vector field\nindex_params.add_index(\n    field_name=\"sparse\",        # Field to index (our vector field)\n    index_type=\"AUTOINDEX\",     # Let Milvus choose optimal index type\n    metric_type=\"BM25\"          # Must be BM25 for this feature\n)\n","List<IndexParam> indexes = new ArrayList<>();\nindexes.add(IndexParam.builder()\n        .fieldName(\"sparse\")\n        .indexType(IndexParam.IndexType.AUTOINDEX)\n        .metricType(IndexParam.MetricType.BM25)\n        .build());\n","const index_params = [{\n    field_name: \"sparse\",\n    index_type: \"AUTOINDEX\",\n    metric_type: \"BM25\"\n}];\n","idx := index.NewAutoIndex(index.MetricType(entity.BM25))\nindexOption := milvusclient.NewCreateIndexOption(\"multilingual_documents\", \"sparse\", idx)\n","# restful\nexport IndexParams='[\n  {\n    \"fieldName\": \"sparse\",\n    \"indexType\": \"AUTOINDEX\",\n    \"metricType\": \"BM25\",\n    \"params\": {}\n  }\n]'\n","# Create collection\nCOLLECTION_NAME = \"multilingual_documents\"\n\n# Check if collection already exists\nif client.has_collection(COLLECTION_NAME):\n    client.drop_collection(COLLECTION_NAME)  # Remove it for this example\n    print(f\"Dropped existing collection: {COLLECTION_NAME}\")\n\n# Create the collection\nclient.create_collection(\n    collection_name=COLLECTION_NAME,       # Collection name\n    schema=schema,                         # Our multilingual schema\n    index_params=index_params              # Our search index configuration\n)\n","client.dropCollection(DropCollectionReq.builder()\n        .collectionName(\"multilingual_documents\")\n        .build());\n        \nCreateCollectionReq requestCreate = CreateCollectionReq.builder()\n        .collectionName(\"multilingual_documents\")\n        .collectionSchema(collectionSchema)\n        .indexParams(indexes)\n        .build();\nclient.createCollection(requestCreate);\n","const COLLECTION_NAME = \"multilingual_documents\";\n\n// Create the collection\nawait client.createCollection({\n  collection_name: COLLECTION_NAME,\n  schema: schema,\n  index_params: index_params,\n  functions: functions\n});\n\n","err = client.CreateCollection(ctx,\n    milvusclient.NewCreateCollectionOption(\"multilingual_documents\", schema).\n        WithIndexOptions(indexOption))\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n","# restful\ncurl --request POST \\\n--url \"${CLUSTER_ENDPOINT}/v2/vectordb/collections/create\" \\\n--header \"Authorization: Bearer ${TOKEN}\" \\\n--header \"Content-Type: application/json\" \\\n--data \"{\n  \\\"collectionName\\\": \\\"multilingual_documents\\\",\n  \\\"schema\\\": $schema,\n  \\\"indexParams\\\": $IndexParams\n}\"\n\n","# Prepare multilingual documents\ndocuments = [\n    # English documents\n    {\n        \"text\": \"Artificial intelligence is transforming technology\",\n        \"language\": \"english\",  # Using full language name\n    },\n    {\n        \"text\": \"Machine learning models require large datasets\",\n        \"language\": \"en\",  # Using our defined alias\n    },\n    # Chinese documents\n    {\n        \"text\": \"人工智能正在改变技术领域\",\n        \"language\": \"chinese\",  # Using full language name\n    },\n    {\n        \"text\": \"机器学习模型需要大型数据集\",\n        \"language\": \"cn\",  # Using our defined alias\n    },\n]\n\n# Insert the documents\nresult = client.insert(COLLECTION_NAME, documents)\n\n# Print results\ninserted = result[\"insert_count\"]            \nprint(f\"Successfully inserted {inserted} documents\")\nprint(\"Documents by language: 2 English, 2 Chinese\")\n\n# Expected output:\n# Successfully inserted 4 documents\n# Documents by language: 2 English, 2 Chinese\n","List<String> texts = Arrays.asList(\n        \"Artificial intelligence is transforming technology\",\n        \"Machine learning models require large datasets\",\n        \"人工智能正在改变技术领域\",\n        \"机器学习模型需要大型数据集\"\n);\nList<String> languages = Arrays.asList(\n        \"english\", \"en\", \"chinese\", \"cn\"\n);\n\nList<JsonObject> rows = new ArrayList<>();\nfor (int i = 0; i < texts.size(); i++) {\n    JsonObject row = new JsonObject();\n    row.addProperty(\"text\", texts.get(i));\n    row.addProperty(\"language\", languages.get(i));\n    rows.add(row);\n}\nclient.insert(InsertReq.builder()\n        .collectionName(\"multilingual_documents\")\n        .data(rows)\n        .build());\n","// Prepare multilingual documents\nconst documents = [\n  // English documents\n  {\n    text: \"Artificial intelligence is transforming technology\",\n    language: \"english\",\n  },\n  {\n    text: \"Machine learning models require large datasets\",\n    language: \"en\",\n  },\n  // Chinese documents\n  {\n    text: \"人工智能正在改变技术领域\",\n    language: \"chinese\",\n  },\n  {\n    text: \"机器学习模型需要大型数据集\",\n    language: \"cn\",\n  },\n];\n\n// Insert the documents\nconst result = await client.insert({\n  collection_name: COLLECTION_NAME,\n  data: documents,\n});\n\n// Print results\nconst inserted = result.insert_count;\nconsole.log(`Successfully inserted ${inserted} documents`);\nconsole.log(\"Documents by language: 2 English, 2 Chinese\");\n\n// Expected output:\n// Successfully inserted 4 documents\n// Documents by language: 2 English, 2 Chinese\n\n","column1 := column.NewColumnVarChar(\"text\",\n    []string{\n        \"Artificial intelligence is transforming technology\",\n        \"Machine learning models require large datasets\",\n        \"人工智能正在改变技术领域\",\n        \"机器学习模型需要大型数据集\",\n    })\ncolumn2 := column.NewColumnVarChar(\"language\",\n    []string{\"english\", \"en\", \"chinese\", \"cn\"})\n\n_, err = client.Insert(ctx, milvusclient.NewColumnBasedInsertOption(\"multilingual_documents\").\n    WithColumns(column1, column2),\n)\nif err != nil {\n    fmt.Println(err.Error())\n    // handle err\n}\n","# restful\ncurl --request POST \\\n--url \"${CLUSTER_ENDPOINT}/v2/vectordb/entities/insert\" \\\n--header \"Authorization: Bearer ${TOKEN}\" \\\n--header \"Content-Type: application/json\" \\\n--data '{\n  \"collectionName\": \"multilingual_documents\",\n  \"data\": [\n    {\n      \"text\": \"Artificial intelligence is transforming technology\",\n      \"language\": \"english\"\n    },\n    {\n      \"text\": \"Machine learning models require large datasets\",\n      \"language\": \"en\"\n    },\n    {\n      \"text\": \"人工智能正在改变技术领域\",\n      \"language\": \"chinese\"\n    },\n    {\n      \"text\": \"机器学习模型需要大型数据集\",\n      \"language\": \"cn\"\n    }\n  ]\n}'\n","search_params = {\n    \"metric_type\": \"BM25\",            # Must match index configuration\n    \"analyzer_name\": \"english\",  # Analyzer that matches the query language\n    \"drop_ratio_search\": \"0\",     # Keep all terms in search (tweak as needed)\n}\n\n# Execute the search\nenglish_results = client.search(\n    collection_name=COLLECTION_NAME,  # Collection to search\n    data=[\"artificial intelligence\"],                # Query text\n    anns_field=\"sparse\",              # Field to search against\n    search_params=search_params,      # Search configuration\n    limit=3,                      # Max results to return\n    output_fields=[\"text\", \"language\"],  # Fields to include in the output\n    consistency_level=\"Strong\",       # Data‑consistency guarantee\n)\n\n# Display English search results\nprint(\"\\n=== English Search Results ===\")\nfor i, hit in enumerate(english_results[0]):\n    print(f\"{i+1}. [{hit.score:.4f}] {hit.entity.get('text')} \"\n          f\"(Language: {hit.entity.get('language')})\")\n\n# Expected output:\n# === English Search Results ===\n# 1. [2.7881] Artificial intelligence is transforming technology (Language: english)\n","Map<String,Object> searchParams = new HashMap<>();\nsearchParams.put(\"metric_type\", \"BM25\");\nsearchParams.put(\"analyzer_name\", \"english\");\nsearchParams.put(\"drop_ratio_search\", 0);\nSearchResp searchResp = client.search(SearchReq.builder()\n        .collectionName(\"multilingual_documents\")\n        .data(Collections.singletonList(new EmbeddedText(\"artificial intelligence\")))\n        .annsField(\"sparse\")\n        .topK(3)\n        .searchParams(searchParams)\n        .outputFields(Arrays.asList(\"text\", \"language\"))\n        .build());\n\nSystem.out.println(\"\\n=== English Search Results ===\");\nList<List<SearchResp.SearchResult>> searchResults = searchResp.getSearchResults();\nfor (List<SearchResp.SearchResult> results : searchResults) {\n    for (SearchResp.SearchResult result : results) {\n        System.out.printf(\"Score: %f, %s\\n\", result.getScore(), result.getEntity().toString());\n    }\n}\n","// Execute the search\nconst english_results = await client.search({\n  collection_name: COLLECTION_NAME,\n  data: [\"artificial intelligence\"],\n  anns_field: \"sparse\",\n  params: {\n    metric_type: \"BM25\",\n    analyzer_name: \"english\",\n    drop_ratio_search: \"0\",\n  },\n  limit: 3,\n  output_fields: [\"text\", \"language\"],\n  consistency_level: \"Strong\",\n});\n\n// Display English search results\nconsole.log(\"\\n=== English Search Results ===\");\nenglish_results.results.forEach((hit, i) => {\n  console.log(\n    `${i + 1}. [${hit.score.toFixed(4)}] ${hit.entity.text} ` +\n      `(Language: ${hit.entity.language})`\n  );\n});\n\n","annSearchParams := index.NewCustomAnnParam()\nannSearchParams.WithExtraParam(\"metric_type\", \"BM25\")\nannSearchParams.WithExtraParam(\"analyzer_name\", \"english\")\nannSearchParams.WithExtraParam(\"drop_ratio_search\", 0)\n\nresultSets, err := client.Search(ctx, milvusclient.NewSearchOption(\n    \"multilingual_documents\", // collectionName\n    3,                        // limit\n    []entity.Vector{entity.Text(\"artificial intelligence\")},\n).WithANNSField(\"sparse\").\n    WithAnnParam(annSearchParams).\n    WithOutputFields(\"text\", \"language\"))\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n\nfor _, resultSet := range resultSets {\n    for i := 0; i < len(resultSet.Scores); i++ {\n        text, _ := resultSet.GetColumn(\"text\").GetAsString(i)\n        lang, _ := resultSet.GetColumn(\"language\").GetAsString(i)\n        fmt.Println(\"Score: \", resultSet.Scores[i], \"Text: \", text, \"Language:\", lang)\n    }\n}\n","# restful\ncurl --request POST \\\n--url \"${CLUSTER_ENDPOINT}/v2/vectordb/entities/search\" \\\n--header \"Authorization: Bearer ${TOKEN}\" \\\n--header \"Content-Type: application/json\" \\\n--data '{\n  \"collectionName\": \"multilingual_documents\",\n  \"data\": [\"artificial intelligence\"],\n  \"annsField\": \"sparse\",\n  \"limit\": 3,\n  \"searchParams\": {\n    \"metric_type\": \"BM25\",\n    \"analyzer_name\": \"english\",\n    \"drop_ratio_search\": \"0\"  \n  },\n  \"outputFields\": [\"text\", \"language\"],\n  \"consistencyLevel\": \"Strong\"\n}'\n","search_params[\"analyzer_name\"] = \"cn\"\n\nchinese_results = client.search(\n    collection_name=COLLECTION_NAME,  # Collection to search\n    data=[\"人工智能\"],                # Query text\n    anns_field=\"sparse\",              # Field to search against\n    search_params=search_params,      # Search configuration\n    limit=3,                      # Max results to return\n    output_fields=[\"text\", \"language\"],  # Fields to include in the output\n    consistency_level=\"Strong\",       # Data‑consistency guarantee\n)\n\n# Display Chinese search results\nprint(\"\\n=== Chinese Search Results ===\")\nfor i, hit in enumerate(chinese_results[0]):\n    print(f\"{i+1}. [{hit.score:.4f}] {hit.entity.get('text')} \"\n          f\"(Language: {hit.entity.get('language')})\")\n\n# Expected output:\n# === Chinese Search Results ===\n# 1. [3.3814] 人工智能正在改变技术领域 (Language: chinese)\n","searchParams.put(\"analyzer_name\", \"cn\");\nsearchResp = client.search(SearchReq.builder()\n        .collectionName(\"multilingual_documents\")\n        .data(Collections.singletonList(new EmbeddedText(\"人工智能\")))\n        .annsField(\"sparse\")\n        .topK(3)\n        .searchParams(searchParams)\n        .outputFields(Arrays.asList(\"text\", \"language\"))\n        .build());\n\nSystem.out.println(\"\\n=== Chinese Search Results ===\");\nsearchResults = searchResp.getSearchResults();\nfor (List<SearchResp.SearchResult> results : searchResults) {\n    for (SearchResp.SearchResult result : results) {\n        System.out.printf(\"Score: %f, %s\\n\", result.getScore(), result.getEntity().toString());\n    }\n}\n","// Execute the search\nconst cn_results = await client.search({\n  collection_name: COLLECTION_NAME,\n  data: [\"人工智能\"],\n  anns_field: \"sparse\",\n  params: {\n    metric_type: \"BM25\",\n    analyzer_name: \"cn\",\n    drop_ratio_search: \"0\",\n  },\n  limit: 3,\n  output_fields: [\"text\", \"language\"],\n  consistency_level: \"Strong\",\n});\n\n// Display Chinese search results\nconsole.log(\"\\n=== Chinese Search Results ===\");\ncn_results.results.forEach((hit, i) => {\n  console.log(\n    `${i + 1}. [${hit.score.toFixed(4)}] ${hit.entity.text} ` +\n      `(Language: ${hit.entity.language})`\n  );\n});\n\n","annSearchParams.WithExtraParam(\"analyzer_name\", \"cn\")\n\nresultSets, err = client.Search(ctx, milvusclient.NewSearchOption(\n    \"multilingual_documents\", // collectionName\n    3,                        // limit\n    []entity.Vector{entity.Text(\"人工智能\")},\n).WithANNSField(\"sparse\").\n    WithAnnParam(annSearchParams).\n    WithOutputFields(\"text\", \"language\"))\nif err != nil {\n    fmt.Println(err.Error())\n    // handle error\n}\n\nfor _, resultSet := range resultSets {\n    for i := 0; i < len(resultSet.Scores); i++ {\n        text, _ := resultSet.GetColumn(\"text\").GetAsString(i)\n        lang, _ := resultSet.GetColumn(\"language\").GetAsString(i)\n        fmt.Println(\"Score: \", resultSet.Scores[i], \"Text: \", text, \"Language:\", lang)\n    }\n}\n\n","# restful\ncurl --request POST \\\n--url \"${CLUSTER_ENDPOINT}/v2/vectordb/entities/search\" \\\n--header \"Authorization: Bearer ${TOKEN}\" \\\n--header \"Content-Type: application/json\" \\\n--data '{\n  \"collectionName\": \"multilingual_documents\",\n  \"data\": [\"人工智能\"],\n  \"annsField\": \"sparse\",\n  \"limit\": 3,\n  \"searchParams\": {\n    \"analyzer_name\": \"cn\"\n  },\n  \"outputFields\": [\"text\", \"language\"],\n  \"consistencyLevel\": \"Strong\"\n}'\n"],"headingContent":"Multi-language Analyzers","anchorList":[{"label":"Mehrsprachige Analyzer","href":"Multi-language-Analyzers","type":1,"isActive":false},{"label":"Begrenzt","href":"Limits","type":2,"isActive":false},{"label":"Übersicht","href":"Overview","type":2,"isActive":false},{"label":"Schritt 1: Konfigurieren Sie multi_analyzer_params","href":"Step-1-Configure-multianalyzerparams","type":2,"isActive":false},{"label":"Schritt 2: Sammlung erstellen","href":"Step-2-Create-collection","type":2,"isActive":false},{"label":"Schritt 3: Einfügen von Beispieldaten","href":"Step-3-Insert-example-data","type":2,"isActive":false},{"label":"Schritt 4: Suchoperationen durchführen","href":"Step-4-Perform-search-operations","type":2,"isActive":false}]}