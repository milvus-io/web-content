{"codeList":["$ pip install --upgrade pymilvus pillow\n$ pip install git+https://github.com/openai/CLIP.git\n","$ wget https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip\n$ unzip -q reverse_image_search.zip -d images_folder\n","from pymilvus import MilvusClient\n\nmilvus_client = MilvusClient(uri=\"milvus.db\")\n","import clip\nfrom PIL import Image\n\n\n# Load CLIP model\nmodel_name = \"ViT-B/32\"\nmodel, preprocess = clip.load(model_name)\nmodel.eval()\n\n\n# Define a function to encode images\ndef encode_image(image_path):\n    image = preprocess(Image.open(image_path)).unsqueeze(0)\n    image_features = model.encode_image(image)\n    image_features /= image_features.norm(\n        dim=-1, keepdim=True\n    )  # Normalize the image features\n    return image_features.squeeze().tolist()\n\n\n# Define a function to encode text\ndef encode_text(text):\n    text_tokens = clip.tokenize(text)\n    text_features = model.encode_text(text_tokens)\n    text_features /= text_features.norm(\n        dim=-1, keepdim=True\n    )  # Normalize the text features\n    return text_features.squeeze().tolist()\n","collection_name = \"image_collection\"\n\n# Drop the collection if it already exists\nif milvus_client.has_collection(collection_name):\n    milvus_client.drop_collection(collection_name)\n\n# Create a new collection in quickstart mode\nmilvus_client.create_collection(\n    collection_name=collection_name,\n    dimension=512,  # this should match the dimension of the image embedding\n    auto_id=True,  # auto generate id and store in the id field\n    enable_dynamic_field=True,  # enable dynamic field for scalar fields\n)\n","import os\nfrom glob import glob\n\n\nimage_dir = \"./images_folder/train\"\nraw_data = []\n\nfor image_path in glob(os.path.join(image_dir, \"**/*.JPEG\")):\n    image_embedding = encode_image(image_path)\n    image_dict = {\"vector\": image_embedding, \"filepath\": image_path}\n    raw_data.append(image_dict)\ninsert_result = milvus_client.insert(collection_name=collection_name, data=raw_data)\n\nprint(\"Inserted\", insert_result[\"insert_count\"], \"images into Milvus.\")\n","query_text = \"a white dog\"\nquery_embedding = encode_text(query_text)\n\nsearch_results = milvus_client.search(\n    collection_name=collection_name,\n    data=[query_embedding],\n    limit=10,  # return top 10 results\n    output_fields=[\"filepath\"],  # return the filepath field\n)\n","from IPython.display import display\n\n\nwidth = 150 * 5\nheight = 150 * 2\nconcatenated_image = Image.new(\"RGB\", (width, height))\n\nresult_images = []\nfor result in search_results:\n    for hit in result:\n        filename = hit[\"entity\"][\"filepath\"]\n        img = Image.open(filename)\n        img = img.resize((150, 150))\n        result_images.append(img)\n\nfor idx, img in enumerate(result_images):\n    x = idx % 5\n    y = idx // 5\n    concatenated_image.paste(img, (x * 150, y * 150))\nprint(f\"Query text: {query_text}\")\nprint(\"\\nSearch results:\")\ndisplay(concatenated_image)\n"],"headingContent":"Text-to-Image Search with Milvus","anchorList":[{"label":"البحث من نص إلى صورة مع ميلفوس","href":"Text-to-Image-Search-with-Milvus","type":1,"isActive":false},{"label":"المتطلبات الأساسية","href":"Prerequisites","type":2,"isActive":false},{"label":"الشروع في العمل","href":"Getting-Started","type":2,"isActive":false}]}