{"codeList":["$ pip install --upgrade pymilvus transformers datasets torch\n","from datasets import load_dataset\n\n\nDATASET = \"squad\"  # Name of dataset from HuggingFace Datasets\nINSERT_RATIO = 0.001  # Ratio of example dataset to be inserted\n\ndata = load_dataset(DATASET, split=\"validation\")\n# Generates a fixed subset. To generate a random subset, remove the seed.\ndata = data.train_test_split(test_size=INSERT_RATIO, seed=42)[\"test\"]\n# Clean up the data structure in the dataset.\ndata = data.map(\n    lambda val: {\"answer\": val[\"answers\"][\"text\"][0]},\n    remove_columns=[\"id\", \"answers\", \"context\"],\n)\n\n# View summary of example data\nprint(data)\n","from transformers import AutoTokenizer, AutoModel\nimport torch\n\nMODEL = (\n    \"sentence-transformers/all-MiniLM-L6-v2\"  # Name of model from HuggingFace Models\n)\nINFERENCE_BATCH_SIZE = 64  # Batch size of model inference\n\n# Load tokenizer & model from HuggingFace Hub\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModel.from_pretrained(MODEL)\n\n\ndef encode_text(batch):\n    # Tokenize sentences\n    encoded_input = tokenizer(\n        batch[\"question\"], padding=True, truncation=True, return_tensors=\"pt\"\n    )\n\n    # Compute token embeddings\n    with torch.no_grad():\n        model_output = model(**encoded_input)\n\n    # Perform pooling\n    token_embeddings = model_output[0]\n    attention_mask = encoded_input[\"attention_mask\"]\n    input_mask_expanded = (\n        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    )\n    sentence_embeddings = torch.sum(\n        token_embeddings * input_mask_expanded, 1\n    ) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n    # Normalize embeddings\n    batch[\"question_embedding\"] = torch.nn.functional.normalize(\n        sentence_embeddings, p=2, dim=1\n    )\n    return batch\n\n\ndata = data.map(encode_text, batched=True, batch_size=INFERENCE_BATCH_SIZE)\ndata_list = data.to_list()\n","from pymilvus import MilvusClient\n\n\nMILVUS_URI = \"./huggingface_milvus_test.db\"  # Connection URI\nCOLLECTION_NAME = \"huggingface_test\"  # Collection name\nDIMENSION = 384  # Embedding dimension depending on model\n\nmilvus_client = MilvusClient(MILVUS_URI)\nif milvus_client.has_collection(collection_name=COLLECTION_NAME):\n    milvus_client.drop_collection(collection_name=COLLECTION_NAME)\nmilvus_client.create_collection(\n    collection_name=COLLECTION_NAME,\n    dimension=DIMENSION,\n    auto_id=True,  # Enable auto id\n    enable_dynamic_field=True,  # Enable dynamic fields\n    vector_field_name=\"question_embedding\",  # Map vector field name and embedding column in dataset\n    consistency_level=\"Strong\",  # To enable search with latest data\n)\n","milvus_client.insert(collection_name=COLLECTION_NAME, data=data_list)\n","questions = {\n    \"question\": [\n        \"What is LGM?\",\n        \"When did Massachusetts first mandate that children be educated in schools?\",\n    ]\n}\n\n# Generate question embeddings\nquestion_embeddings = [v.tolist() for v in encode_text(questions)[\"question_embedding\"]]\n\n# Search across Milvus\nsearch_results = milvus_client.search(\n    collection_name=COLLECTION_NAME,\n    data=question_embeddings,\n    limit=3,  # How many search results to output\n    output_fields=[\"answer\", \"question\"],  # Include these fields in search results\n)\n\n# Print out results\nfor q, res in zip(questions[\"question\"], search_results):\n    print(\"Question:\", q)\n    for r in res:\n        print(\n            {\n                \"answer\": r[\"entity\"][\"answer\"],\n                \"score\": r[\"distance\"],\n                \"original question\": r[\"entity\"][\"question\"],\n            }\n        )\n    print(\"\\n\")\n"],"headingContent":"Question Answering Using Milvus and Hugging Face","anchorList":[{"label":"Question Answering Using Milvus and Hugging Face","href":"Question-Answering-Using-Milvus-and-Hugging-Face","type":1,"isActive":false},{"label":"Before you begin","href":"Before-you-begin","type":2,"isActive":false},{"label":"Prepare data","href":"Prepare-data","type":2,"isActive":false},{"label":"Insert data","href":"Insert-data","type":2,"isActive":false},{"label":"Ask questions","href":"Ask-questions","type":2,"isActive":false}]}