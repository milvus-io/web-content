{"codeList":["analyzer_params = {​\n    \"type\": \"standard\", # Uses the standard built-in analyzer​\n    \"stop_words\": [\"a\", \"an\", \"for\"] # Defines a list of common words (stop words) to exclude from tokenization​\n}​\n\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"type\", \"standard\");\nanalyzerParams.put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n","const analyzer_params = {\n    \"type\": \"standard\", // Uses the standard built-in analyzer\n    \"stop_words\": [\"a\", \"an\", \"for\"] // Defines a list of common words (stop words) to exclude from tokenization\n};\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"stop_words\": [\"a\", \"an\", \"for\"]\n    }'\n","analyzer_params = {​\n    \"tokenizer\": \"standard\",​\n    \"filter\": [​\n        \"lowercase\",​\n        {​\n            \"type\": \"stop\",​\n            \"stop_words\": [\"a\", \"an\", \"for\"]​\n        }​\n    ]​\n}​\n\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Arrays.asList(\"lowercase\",\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n                }}));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\",\n    \"filter\": [\n        \"lowercase\",\n        {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n        }\n    ]\n};\n","export analyzerParams='{\n       \"type\": \"standard\",\n       \"filter\":  [\n       \"lowercase\",\n       {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n       }\n   ]\n}'\n","[\"Vector\", \"Database\", \"Built\", \"for\", \"Scale\"]​\n","analyzer_params = {​\n    \"tokenizer\": \"whitespace\",​\n}​\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"whitespace\");\n","const analyzer_params = {\n    \"tokenizer\": \"whitespace\",\n};\n","export analyzerParams='{\n       \"type\": \"whitespace\"\n    }'\n","[\"vector\", \"database\", \"built\", \"for\", \"scale\"]​\n","analyzer_params = {​\n    \"tokenizer\": \"standard\", # Mandatory: Specifies tokenizer​\n    \"filter\": [\"lowercase\"], # Optional: Built-in filter that converts text to lowercase​\n}​\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\", Collections.singletonList(\"lowercase\"));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\", // Mandatory: Specifies tokenizer\n    \"filter\": [\"lowercase\"], // Optional: Built-in filter that converts text to lowercase\n}\n","export analyzerParams='{\n   \"type\": \"standard\",\n   \"filter\":  [\"lowercase\"]\n}'\n","analyzer_params = {​\n    \"tokenizer\": \"standard\", # Mandatory: Specifies tokenizer​\n    \"filter\": [​\n        {​\n            \"type\": \"stop\", # Specifies 'stop' as the filter type​\n            \"stop_words\": [\"of\", \"to\"], # Customizes stop words for this filter type​\n        }​\n    ]​\n}​\n\n","Map<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n    Collections.singletonList(new HashMap<String, Object>() {{\n        put(\"type\", \"stop\");\n        put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n    }}));\n","const analyzer_params = {\n    \"tokenizer\": \"standard\", // Mandatory: Specifies tokenizer\n    \"filter\": [\n        {\n            \"type\": \"stop\", // Specifies 'stop' as the filter type\n            \"stop_words\": [\"of\", \"to\"], // Customizes stop words for this filter type\n        }\n    ]\n};\n","export analyzerParams='{\n    \"type\": \"standard\",\n    \"filter\":  [\n    {\n            \"type\": \"stop\",\n            \"stop_words\": [\"a\", \"an\", \"for\"]\n    }\n    ]\n}'\n","from pymilvus import MilvusClient, DataType​\n​\n# Set up a Milvus client​\nclient = MilvusClient(​\n    uri=\"http://localhost:19530\"​\n)​\n​\n# Create schema​\nschema = client.create_schema(auto_id=True, enable_dynamic_field=False)​\n​\n# Add fields to schema​\n​\n# Use a built-in analyzer​\nanalyzer_params_built_in = {​\n    \"type\": \"english\"​\n}​\n​\n# Add VARCHAR field `title_en`​\nschema.add_field(​\n    field_name='title_en', ​\n    datatype=DataType.VARCHAR, ​\n    max_length=1000, ​\n    enable_analyzer=True，​\n    analyzer_params=analyzer_params_built_in,​\n    enable_match=True, ​\n)​\n​\n# Configure a custom analyzer​\nanalyzer_params_custom = {​\n    \"tokenizer\": \"standard\",​\n    \"filter\": [​\n        \"lowercase\", # Built-in filter​\n        {​\n            \"type\": \"length\", # Custom filter​\n            \"max\": 40​\n        },​\n        {​\n            \"type\": \"stop\", # Custom filter​\n            \"stop_words\": [\"of\", \"to\"]​\n        }​\n    ]​\n}​\n​\n# Add VARCHAR field `title`​\nschema.add_field(​\n    field_name='title', ​\n    datatype=DataType.VARCHAR, ​\n    max_length=1000, ​\n    enable_analyzer=True，​\n    analyzer_params=analyzer_params_custom,​\n    enable_match=True, ​\n)​\n​\n# Add vector field​\nschema.add_field(field_name=\"embedding\", datatype=DataType.FLOAT_VECTOR, dim=3)​\n# Add primary field​\nschema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)​\n​\n# Set up index params for vector field​\nindex_params = client.prepare_index_params()​\nindex_params.add_index(field_name=\"embedding\", metric_type=\"COSINE\", index_type=\"AUTOINDEX\")​\n​\n# Create collection with defined schema​\nclient.create_collection(​\n    collection_name=\"YOUR_COLLECTION_NAME\",​\n    schema=schema,​\n    index_params=index_params​\n)​\n","import io.milvus.v2.client.ConnectConfig;\nimport io.milvus.v2.client.MilvusClientV2;\nimport io.milvus.v2.common.DataType;\nimport io.milvus.v2.common.IndexParam;\nimport io.milvus.v2.service.collection.request.AddFieldReq;\nimport io.milvus.v2.service.collection.request.CreateCollectionReq;\n\n// Set up a Milvus client\nConnectConfig config = ConnectConfig.builder()\n        .uri(\"http://localhost:19530\")\n        .build();\nMilvusClientV2 client = new MilvusClientV2(config);\n\n// Create schema\nCreateCollectionReq.CollectionSchema schema = CreateCollectionReq.CollectionSchema.builder()\n        .enableDynamicField(false)\n        .build();\n\n// Add fields to schema\n// Use a built-in analyzer\nMap<String, Object> analyzerParamsBuiltin = new HashMap<>();\nanalyzerParamsBuiltin.put(\"type\", \"english\");\n// Add VARCHAR field `title_en`\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"title_en\")\n        .dataType(DataType.VarChar)\n        .maxLength(1000)\n        .enableAnalyzer(true)\n        .analyzerParams(analyzerParamsBuiltin)\n        .enableMatch(true)\n        .build());\n\n// Configure a custom analyzer\nMap<String, Object> analyzerParams = new HashMap<>();\nanalyzerParams.put(\"tokenizer\", \"standard\");\nanalyzerParams.put(\"filter\",\n        Arrays.asList(\"lowercase\",\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"length\");\n                    put(\"max\", 40);\n                }},\n                new HashMap<String, Object>() {{\n                    put(\"type\", \"stop\");\n                    put(\"stop_words\", Arrays.asList(\"a\", \"an\", \"for\"));\n                }}\n        )\n);\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"title\")\n        .dataType(DataType.VarChar)\n        .maxLength(1000)\n        .enableAnalyzer(true)\n        .analyzerParams(analyzerParams)\n        .enableMatch(true) // must enable this if you use TextMatch\n        .build());\n\n// Add vector field\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"embedding\")\n        .dataType(DataType.FloatVector)\n        .dimension(3)\n        .build());\n// Add primary field\nschema.addField(AddFieldReq.builder()\n        .fieldName(\"id\")\n        .dataType(DataType.Int64)\n        .isPrimaryKey(true)\n        .autoID(true)\n        .build());\n\n// Set up index params for vector field\nList<IndexParam> indexes = new ArrayList<>();\nindexes.add(IndexParam.builder()\n        .fieldName(\"embedding\")\n        .indexType(IndexParam.IndexType.AUTOINDEX)\n        .metricType(IndexParam.MetricType.COSINE)\n        .build());\n\n// Create collection with defined schema\nCreateCollectionReq requestCreate = CreateCollectionReq.builder()\n        .collectionName(\"YOUR_COLLECTION_NAME\")\n        .collectionSchema(schema)\n        .indexParams(indexes)\n        .build();\nclient.createCollection(requestCreate);\n","import { MilvusClient, DataType } from \"@zilliz/milvus2-sdk-node\";\n\n// Set up a Milvus client\nconst client = new MilvusClient(\"http://localhost:19530\");\n// Use a built-in analyzer for VARCHAR field `title_en`\nconst analyzerParamsBuiltIn = {\n  type: \"english\",\n};\n\n// Configure a custom analyzer for VARCHAR field `title`\nconst analyzerParamsCustom = {\n  tokenizer: \"standard\",\n  filter: [\n    \"lowercase\",\n    {\n      type: \"length\",\n      max: 40,\n    },\n    {\n      type: \"stop\",\n      stop_words: [\"of\", \"to\"],\n    },\n  ],\n};\n\n// Create schema\nconst schema = {\n  auto_id: true,\n  fields: [\n    {\n      name: \"id\",\n      type: DataType.INT64,\n      is_primary: true,\n    },\n    {\n      name: \"title_en\",\n      data_type: DataType.VARCHAR,\n      max_length: 1000,\n      enable_analyzer: true,\n      analyzer_params: analyzerParamsBuiltIn,\n      enable_match: true,\n    },\n    {\n      name: \"title\",\n      data_type: DataType.VARCHAR,\n      max_length: 1000,\n      enable_analyzer: true,\n      analyzer_params: analyzerParamsCustom,\n      enable_match: true,\n    },\n    {\n      name: \"embedding\",\n      data_type: DataType.FLOAT_VECTOR,\n      dim: 4,\n    },\n  ],\n};\n\n// Set up index params for vector field\nconst indexParams = [\n  {\n    name: \"embedding\",\n    metric_type: \"COSINE\",\n    index_type: \"AUTOINDEX\",\n  },\n];\n\n// Create collection with defined schema\nawait client.createCollection({\n  collection_name: \"YOUR_COLLECTION_NAME\",\n  schema: schema,\n  index_params: indexParams,\n});\n\nconsole.log(\"Collection created successfully!\");\n\n","export schema='{\n        \"autoId\": true,\n        \"enabledDynamicField\": false,\n        \"fields\": [\n            {\n                \"fieldName\": \"id\",\n                \"dataType\": \"Int64\",\n                \"isPrimary\": true\n            },\n            {\n                \"fieldName\": \"title_en\",\n                \"dataType\": \"VarChar\",\n                \"elementTypeParams\": {\n                    \"max_length\": 1000,\n                    \"enable_analyzer\": true,\n                    \"enable_match\": true,\n                    \"analyzer_params\": {\"type\": \"english\"}\n                }\n            },\n            {\n                \"fieldName\": \"title\",\n                \"dataType\": \"VarChar\",\n                \"elementTypeParams\": {\n                    \"max_length\": 1000,\n                    \"enable_analyzer\": true,\n                    \"enable_match\": true,\n                    \"analyzer_params\": {\n                        \"tokenizer\": \"standard\",\n                        \"filter\":[\n                            \"lowercase\",\n                            {\n                                \"type\":\"length\",\n                                \"max\":40\n                            },\n                            {\n                                \"type\":\"stop\",\n                                \"stop_words\":[\"of\",\"to\"]\n                            }\n                        ]\n                    }\n                }\n            },\n            {\n                \"fieldName\": \"embedding\",\n                \"dataType\": \"FloatVector\",\n                \"elementTypeParams\": {\n                    \"dim\":3\n                }\n            }\n        ]\n    }'\n    \nexport indexParams='[\n        {\n            \"fieldName\": \"embedding\",\n            \"metricType\": \"COSINE\",\n            \"indexType\": \"AUTOINDEX\"\n        }\n    ]'\n\nexport CLUSTER_ENDPOINT=\"http://localhost:19530\"\nexport TOKEN=\"root:Milvus\"\n\ncurl --request POST \\\n--url \"${CLUSTER_ENDPOINT}/v2/vectordb/collections/create\" \\\n--header \"Authorization: Bearer ${TOKEN}\" \\\n--header \"Content-Type: application/json\" \\\n-d \"{\n    \\\"collectionName\\\": \\\"YOUR_COLLECTION_NAME\\\",\n    \\\"schema\\\": $schema,\n    \\\"indexParams\\\": $indexParams\n}\"\n"],"headingContent":"Analyzer Overview​","anchorList":[{"label":"Analyzer Overview​","href":"Analyzer-Overview​","type":1,"isActive":false},{"label":"Anatomy of an analyzer​","href":"Anatomy-of-an-analyzer​","type":2,"isActive":false},{"label":"Analyzer types​","href":"Analyzer-types​","type":2,"isActive":false},{"label":"Example use​","href":"Example-use​","type":2,"isActive":false}]}