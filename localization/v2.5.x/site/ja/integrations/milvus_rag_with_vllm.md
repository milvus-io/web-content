---
id: milvus_rag_with_vllm.md
summary: >-
  ã“ã®ãƒ–ãƒ­ã‚°ã§ã¯ã€Milvusã€vLLMã€Llama
  3.1ã‚’ä½¿ã£ã¦RAGã‚’æ§‹ç¯‰ã—ã€å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€Milvusã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿ã¨ã—ã¦åŸ‹ã‚è¾¼ã¿ã€ä¿å­˜ã—ã€ã“ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’åŠ¹ç‡çš„ã«æ¤œç´¢ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
title: Milvusã€vLLMã€Llama 3.1ã«ã‚ˆã‚‹RAGã®æ§‹ç¯‰
---
<h1 id="Building-RAG-with-Milvus-vLLM-and-Llama-31" class="common-anchor-header">Milvusã€vLLMã€Llama 3.1ã«ã‚ˆã‚‹RAGã®æ§‹ç¯‰<button data-href="#Building-RAG-with-Milvus-vLLM-and-Llama-31" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h1><p>ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢å¤§å­¦ãƒãƒ¼ã‚¯ãƒ¬ãƒ¼æ ¡ã¯ã€2024å¹´7æœˆã€LLMæ¨è«–ã¨ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã®ãŸã‚ã®é«˜é€Ÿã§ä½¿ã„ã‚„ã™ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚‹<a href="https://docs.vllm.ai/en/latest/index.html">vLLMã‚’</a>ã€ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ®µéšã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦<a href="https://lfaidata.foundation/">LF AI &amp; Data Foundationã«</a>å¯„è´ˆã—ã¾ã—ãŸã€‚ç§ãŸã¡ã¯vLLMãŒLF AI &amp; Dataãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«åŠ ã‚ã‚‹ã“ã¨ã‚’æ­“è¿ã—ã¾ã™ï¼ğŸ‰</p>
<p>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«<a href="https://zilliz.com/glossary/large-language-models-(llms)">ï¼ˆLLM</a>ï¼‰ã¨<a href="https://zilliz.com/learn/what-is-vector-database">ãƒ™ã‚¯ãƒˆãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯</a>é€šå¸¸ã€<a href="https://zilliz.com/glossary/ai-hallucination">AIå¹»è¦šã«</a>å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹<a href="https://zilliz.com/learn/Retrieval-Augmented-Generation">RAGï¼ˆ</a>Retrieval Augmented Generationï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«çµ„ã¿åˆã‚ã•ã‚Œã¾ã™ã€‚ã“ã®ãƒ–ãƒ­ã‚°ã§ã¯ã€Milvusã€vLLMã€Llama 3.1ã‚’ä½¿ã£ã¦RAGã‚’æ§‹ç¯‰ã—ã€å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€Milvusã«ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’<a href="https://zilliz.com/glossary/vector-embeddings">ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã¨ã—ã¦</a>åŸ‹ã‚è¾¼ã¿ã€ä¿å­˜ã—ã€ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’åŠ¹ç‡çš„ã«æ¤œç´¢ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚æœ€å¾Œã«ã€vLLMã‚’æ´»ç”¨ã—ã¦Metaã®Llama 3.1-8Bãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã€æ¤œç´¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã£ã¦æ‹¡å¼µã•ã‚ŒãŸå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã•ã‚ã€é£›ã³è¾¼ã‚‚ã†ï¼</p>
<h2 id="Introduction-to-Milvus-vLLM-and-Metaâ€™s-Llama-31" class="common-anchor-header">Milvusã€vLLMã€Metaã®Llama 3.1ã®ç´¹ä»‹<button data-href="#Introduction-to-Milvus-vLLM-and-Metaâ€™s-Llama-31" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Milvus-vector-database" class="common-anchor-header">Milvusãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</h3><p><a href="https://zilliz.com/what-is-milvus"><strong>Milvusã¯</strong></a>ã€<a href="https://zilliz.com/learn/generative-ai">Generative AI</a>(GenAI)ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ã‘ã€æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®<a href="https://zilliz.com/blog/what-is-a-real-vector-database">ç›®çš„åˆ¥</a>åˆ†æ•£ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚‹ã€‚<a href="https://zilliz.com/blog/a-review-of-hybrid-search-in-milvus">ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã€</a> <a href="https://zilliz.com/blog/what-is-new-with-metadata-filtering-in-milvus">ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°</a>ã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã€ä½•å…†ã‚‚ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹èƒ½åŠ›ã«ã‚ˆã‚Šã€Milvusã¯AIãŠã‚ˆã³æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«æœ€é©ãªé¸æŠè‚¢ã¨ãªã£ã¦ã„ã¾ã™ã€‚<a href="https://github.com/milvus-io/">Milvusã¯</a>ã€ãƒ­ãƒ¼ã‚«ãƒ«ã€ã‚¯ãƒ©ã‚¹ã‚¿ã€ã¾ãŸã¯ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰<a href="https://zilliz.com/cloud">Zillizã‚¯ãƒ©ã‚¦ãƒ‰ã§</a>ç¨¼åƒã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<h3 id="vLLM" class="common-anchor-header">vLLM</h3><p><a href="https://vllm.readthedocs.io/en/latest/index.html"><strong>vLLMã¯</strong></a>UC Berkeley SkyLabã§é–‹å§‹ã•ã‚ŒãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€LLMã‚µãƒ¼ãƒ“ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚PagedAttentionã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†ã€ç¶™ç¶šçš„ãªãƒãƒƒãƒå‡¦ç†ã€æœ€é©åŒ–ã•ã‚ŒãŸCUDAã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦ã€vLLMã¯GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åŠåˆ†ã«å‰Šæ¸›ã—ãªãŒã‚‰ã€é…ä¿¡æ€§èƒ½ã‚’æœ€å¤§24å€å‘ä¸Šã•ã›ãŸã€‚</p>
<p>è«–æ–‡ã€Œ<a href="https://arxiv.org/abs/2309.06180">Efficient Memory Management for Large Language Model Serving with PagedAttention</a>ã€ã«ã‚ˆã‚‹ã¨ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯GPUãƒ¡ãƒ¢ãƒªã®ç´„30%ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€æ½œåœ¨çš„ãªãƒ¡ãƒ¢ãƒªå•é¡Œã«ã¤ãªãŒã£ã¦ã„ã‚‹ã€‚KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯é€£ç¶šã—ãŸãƒ¡ãƒ¢ãƒªã«æ ¼ç´ã•ã‚Œã¾ã™ãŒã€ã‚µã‚¤ã‚ºãŒå¤‰ã‚ã‚‹ã¨ãƒ¡ãƒ¢ãƒªã®æ–­ç‰‡åŒ–ãŒèµ·ã“ã‚Šã€è¨ˆç®—åŠ¹ç‡ãŒæ‚ªããªã‚Šã¾ã™ã€‚</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="/docs/v2.5.x/assets/vllm_1.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ç”»åƒ1.æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼ˆ2023 Paged Attention<a href="https://arxiv.org/pdf/2309.06180">è«–æ–‡ï¼‰</a></em></p>
<p>KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä»®æƒ³ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€vLLMã¯å¿…è¦ã«å¿œã˜ã¦ç‰©ç†GPUãƒ¡ãƒ¢ãƒªã®ã¿ã‚’å‰²ã‚Šå½“ã¦ã€ãƒ¡ãƒ¢ãƒªã®æ–­ç‰‡åŒ–ã‚’æ’é™¤ã—ã€äº‹å‰å‰²ã‚Šå½“ã¦ã‚’å›é¿ã—ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆã§ã¯ã€vLLMã¯<a href="https://huggingface.co/docs/transformers/main_classes/text_generation">HuggingFace Transformers</a>ï¼ˆHFï¼‰ãŠã‚ˆã³<a href="https://github.com/huggingface/text-generation-inference">Text Generation Inference</a>ï¼ˆTGIï¼‰ã‚’ä¸Šå›ã‚Šã€NVIDIA A10GãŠã‚ˆã³A100 GPUä¸Šã§HFã‚ˆã‚Šæœ€å¤§24å€ã€TGIã‚ˆã‚Šæœ€å¤§3.5å€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’é”æˆã—ã¾ã—ãŸã€‚</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="/docs/v2.5.x/assets/vllm_2.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>ç”»åƒ2.vLLMã¯ã€HFã‚ˆã‚Š8.5å€ï½15å€ã€TGIã‚ˆã‚Š3.3å€ï½3.5å€é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’é”æˆã—ã¦ã„ã‚‹ï¼ˆ2023<a href="https://blog.vllm.ai/2023/06/20/vllm.html">vLLMãƒ–ãƒ­ã‚°</a>ï¼‰ã€‚</em></p>
<h3 id="Metaâ€™s-Llama-31" class="common-anchor-header">ãƒ¡ã‚¿ã®ãƒ©ãƒ3.1</h3><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models"><strong>Meta's Llama 3.1ãŒ</strong></a>2024å¹´7æœˆ23æ—¥ã«ç™ºè¡¨ã•ã‚ŒãŸã€‚405Bãƒ¢ãƒ‡ãƒ«ã¯ã„ãã¤ã‹ã®å…¬é–‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€128,000ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æŒã¡ã€æ§˜ã€…ãªå•†ç”¨åˆ©ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã€‚4,050å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ä¸¦è¡Œã—ã¦ã€Metaç¤¾ã¯Llama3 70Bï¼ˆ700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã¨8Bï¼ˆ80å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã®æ›´æ–°ç‰ˆã‚’ãƒªãƒªãƒ¼ã‚¹ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã¯<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWbMJv2vnLfjW3Rh6L96gqS5YW7MhRLh5j9tjNN8BHR5W3qgyTW6N1vHY6lZ3l8N8htfRfqP8DzW72mhHB6vwYd2W77hFt886l4_PV22X226RPmZbW67mSH08gVp9MW2jcZvf24w97BW207Jmf8gPH0yW20YPQv261xxjW8nc6VW3jj-nNW6XdRhg5HhZk_W1QS0yL9dJZb0W818zFK1w62kdW8y-_4m1gfjfNW2jswrd3xbv-yW5mrvdk3n-KqyW45sLMF21qDrwW5TR3vr2MYxZ9W2hWhq23q-nQdW4blHqh3JlZWfW937hlZ58-KJCW82Pgv9384MbYW7yp56M6pvzd6f77wnH004">Metaã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰</a>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã€‚</p>
<p>é‡è¦ãªæ´å¯Ÿã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ãŒã€è³ªã®ä½ã„ä¾‹ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä½ä¸‹ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã ã£ãŸã€‚Llamaãƒãƒ¼ãƒ ã¯ã€ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã€è£œåŠ©ãƒ¢ãƒ‡ãƒ«ã€ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ã“ã‚Œã‚‰ã®æ‚ªã„ä¾‹ã‚’ç‰¹å®šã—ã€é™¤å»ã™ã‚‹ãŸã‚ã«åºƒç¯„å›²ã«åƒãã¾ã—ãŸã€‚</p>
<h2 id="Build-and-Perform-the-RAG-Retrieval-with-Milvus" class="common-anchor-header">Milvusã‚’ä½¿ã£ãŸRAGæ¤œç´¢ã®æ§‹ç¯‰ã¨å®Ÿè¡Œ<button data-href="#Build-and-Perform-the-RAG-Retrieval-with-Milvus" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Prepare-your-dataset" class="common-anchor-header">ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ã€‚</h3><p>ç§ã¯ã“ã®ãƒ‡ãƒ¢ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦<a href="https://milvus.io/docs/">Milvusã®</a>å…¬å¼<a href="https://milvus.io/docs/">ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’</a>ä½¿ç”¨ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> DirectoryLoader
<span class="hljs-comment"># Load HTML files already saved in a local directory</span>
path = <span class="hljs-string">&quot;../../RAG/rtdocs_new/&quot;</span>
global_pattern = <span class="hljs-string">&#x27;*.html&#x27;</span>
loader = DirectoryLoader(path=path, glob=global_pattern)
docs = loader.load()


<span class="hljs-comment"># Print num documents and a preview.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;loaded <span class="hljs-subst">{<span class="hljs-built_in">len</span>(docs)}</span> documents&quot;</span>)
<span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)
pprint.pprint(docs[<span class="hljs-number">0</span>].metadata)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">loaded <span class="hljs-number">22</span> documents
<span class="hljs-title class_">Why</span> <span class="hljs-title class_">Milvus</span> <span class="hljs-title class_">Docs</span> <span class="hljs-title class_">Tutorials</span> <span class="hljs-title class_">Tools</span> <span class="hljs-title class_">Blog</span> <span class="hljs-title class_">Community</span> <span class="hljs-title class_">Stars0</span> <span class="hljs-title class_">Try</span> <span class="hljs-title class_">Managed</span> <span class="hljs-title class_">Milvus</span> <span class="hljs-variable constant_">FREE</span> <span class="hljs-title class_">Search</span> <span class="hljs-title class_">Home</span> v2<span class="hljs-number">.4</span>.<span class="hljs-property">x</span> <span class="hljs-title class_">About</span> ...
{<span class="hljs-string">&#x27;source&#x27;</span>: <span class="hljs-string">&#x27;https://milvus.io/docs/quickstart.md&#x27;</span>}
<button class="copy-code-btn"></button></code></pre>
<h3 id="Download-an-embedding-model" class="common-anchor-header">åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚</h3><p>æ¬¡ã«ã€HuggingFaceã‹ã‚‰ç„¡æ–™ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®<a href="https://zilliz.com/ai-models">åŸ‹ã‚è¾¼ã¿</a>ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer


<span class="hljs-comment"># Initialize torch settings for device-agnostic code.</span>
N_GPU = torch.cuda.device_count()
DEVICE = torch.device(<span class="hljs-string">&#x27;cuda:N_GPU&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)


<span class="hljs-comment"># Download the model from huggingface model hub.</span>
model_name = <span class="hljs-string">&quot;BAAI/bge-large-en-v1.5&quot;</span>
encoder = SentenceTransformer(model_name, device=DEVICE)


<span class="hljs-comment"># Get the model parameters and save for later.</span>
EMBEDDING_DIM = encoder.get_sentence_embedding_dimension()
MAX_SEQ_LENGTH_IN_TOKENS = encoder.get_max_seq_length()


<span class="hljs-comment"># Inspect model parameters.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;model_name: <span class="hljs-subst">{model_name}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;EMBEDDING_DIM: <span class="hljs-subst">{EMBEDDING_DIM}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;MAX_SEQ_LENGTH: <span class="hljs-subst">{MAX_SEQ_LENGTH}</span>&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">model_name: BAAI/bge-large-en-v1.5
EMBEDDING_DIM: 1024
MAX_SEQ_LENGTH: 512
<button class="copy-code-btn"></button></code></pre>
<h3 id="Chunk-and-encode-your-custom-data-as-vectors" class="common-anchor-header">ã‚«ã‚¹ã‚¿ãƒ ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã—ã¦ã€ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚</h3><p>ã“ã“ã§ã¯ã€512æ–‡å­—ã®å›ºå®šé•·ã§ã€10ï¼…ã®é‡ãªã‚Šã‚’ä½¿ç”¨ã™ã‚‹ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter


CHUNK_SIZE = <span class="hljs-number">512</span>
chunk_overlap = np.<span class="hljs-built_in">round</span>(CHUNK_SIZE * <span class="hljs-number">0.10</span>, <span class="hljs-number">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;chunk_size: <span class="hljs-subst">{CHUNK_SIZE}</span>, chunk_overlap: <span class="hljs-subst">{chunk_overlap}</span>&quot;</span>)


<span class="hljs-comment"># Define the splitter.</span>
child_splitter = RecursiveCharacterTextSplitter(
   chunk_size=CHUNK_SIZE,
   chunk_overlap=chunk_overlap)


<span class="hljs-comment"># Chunk the docs.</span>
chunks = child_splitter.split_documents(docs)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{<span class="hljs-built_in">len</span>(docs)}</span> docs split into <span class="hljs-subst">{<span class="hljs-built_in">len</span>(chunks)}</span> child documents.&quot;</span>)


<span class="hljs-comment"># Encoder input is doc.page_content as strings.</span>
list_of_strings = [doc.page_content <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> chunks <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(doc, <span class="hljs-string">&#x27;page_content&#x27;</span>)]


<span class="hljs-comment"># Embedding inference using HuggingFace encoder.</span>
embeddings = torch.tensor(encoder.encode(list_of_strings))


<span class="hljs-comment"># Normalize the embeddings.</span>
embeddings = np.array(embeddings / np.linalg.norm(embeddings))


<span class="hljs-comment"># Milvus expects a list of `numpy.ndarray` of `numpy.float32` numbers.</span>
converted_values = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(np.float32, embeddings))


<span class="hljs-comment"># Create dict_list for Milvus insertion.</span>
dict_list = []
<span class="hljs-keyword">for</span> chunk, vector <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(chunks, converted_values):
   <span class="hljs-comment"># Assemble embedding vector, original text chunk, metadata.</span>
   chunk_dict = {
       <span class="hljs-string">&#x27;chunk&#x27;</span>: chunk.page_content,
       <span class="hljs-string">&#x27;source&#x27;</span>: chunk.metadata.get(<span class="hljs-string">&#x27;source&#x27;</span>, <span class="hljs-string">&quot;&quot;</span>),
       <span class="hljs-string">&#x27;vector&#x27;</span>: vector,
   }
   dict_list.append(chunk_dict)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">chunk_size: 512, chunk_overlap: 51.0
22 docs <span class="hljs-built_in">split</span> into 355 child documents.
<button class="copy-code-btn"></button></code></pre>
<h3 id="Save-the-vectors-in-Milvus" class="common-anchor-header">Milvusã§ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’ä¿å­˜ã™ã‚‹ã€‚</h3><p>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’Milvusãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å–ã‚Šè¾¼ã‚€ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Connect a client to the Milvus Lite server.</span>
<span class="hljs-keyword">from</span> pymilvus <span class="hljs-keyword">import</span> MilvusClient
mc = MilvusClient(<span class="hljs-string">&quot;milvus_demo.db&quot;</span>)


<span class="hljs-comment"># Create a collection with flexible schema and AUTOINDEX.</span>
COLLECTION_NAME = <span class="hljs-string">&quot;MilvusDocs&quot;</span>
mc.create_collection(COLLECTION_NAME,
       EMBEDDING_DIM,
       consistency_level=<span class="hljs-string">&quot;Eventually&quot;</span>,
       auto_id=<span class="hljs-literal">True</span>, 
       overwrite=<span class="hljs-literal">True</span>)


<span class="hljs-comment"># Insert data into the Milvus collection.</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start inserting entities&quot;</span>)
start_time = time.time()
mc.insert(
   COLLECTION_NAME,
   data=dict_list,
   progress_bar=<span class="hljs-literal">True</span>)


end_time = time.time()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Milvus insert time for <span class="hljs-subst">{<span class="hljs-built_in">len</span>(dict_list)}</span> vectors: &quot;</span>, end=<span class="hljs-string">&quot;&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{<span class="hljs-built_in">round</span>(end_time - start_time, <span class="hljs-number">2</span>)}</span> seconds&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text">Start inserting entities
Milvus insert time for 355 vectors: 0.2 seconds
<button class="copy-code-btn"></button></code></pre>
<h3 id="Perform-a-vector-search" class="common-anchor-header">ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’è¡Œã†ã€‚</h3><p>è³ªå•ã‚’ã—ã€Milvusã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€è¿‘å‚ã®ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢ã—ã¾ã™ã€‚</p>
<pre><code translate="no" class="language-python">SAMPLE_QUESTION = <span class="hljs-string">&quot;What do the parameters for HNSW mean?&quot;</span>


<span class="hljs-comment"># Embed the question using the same encoder.</span>
query_embeddings = torch.tensor(encoder.encode(SAMPLE_QUESTION))
<span class="hljs-comment"># Normalize embeddings to unit length.</span>
query_embeddings = F.normalize(query_embeddings, p=<span class="hljs-number">2</span>, dim=<span class="hljs-number">1</span>)
<span class="hljs-comment"># Convert the embeddings to list of list of np.float32.</span>
query_embeddings = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(np.float32, query_embeddings))


<span class="hljs-comment"># Define metadata fields you can filter on.</span>
OUTPUT_FIELDS = <span class="hljs-built_in">list</span>(dict_list[<span class="hljs-number">0</span>].keys())
OUTPUT_FIELDS.remove(<span class="hljs-string">&#x27;vector&#x27;</span>)


<span class="hljs-comment"># Define how many top-k results you want to retrieve.</span>
TOP_K = <span class="hljs-number">2</span>


<span class="hljs-comment"># Run semantic vector search using your query and the vector database.</span>
results = mc.search(
    COLLECTION_NAME,
    data=query_embeddings,
    output_fields=OUTPUT_FIELDS,
    limit=TOP_K,
    consistency_level=<span class="hljs-string">&quot;Eventually&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<p>æ¤œç´¢çµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚</p>
<pre><code translate="no" class="language-text">Retrieved result <span class="hljs-comment">#1</span>
distance = 0.7001987099647522
(<span class="hljs-string">&#x27;Chunk text: layer, finds the node closest to the target in this layer, and&#x27;</span>
...
<span class="hljs-string">&#x27;outgoing&#x27;</span>)
<span class="hljs-built_in">source</span>: https://milvus.io/docs/index.md

Retrieved result <span class="hljs-comment">#2</span>
distance = 0.6953287124633789
(<span class="hljs-string">&#x27;Chunk text: this value can improve recall rate at the cost of increased&#x27;</span>
...
<span class="hljs-string">&#x27;to the target&#x27;</span>)
<span class="hljs-built_in">source</span>: https://milvus.io/docs/index.md
<button class="copy-code-btn"></button></code></pre>
<h2 id="Build-and-Perform-the-RAG-Generation-with-vLLM-and-Llama-31-8B" class="common-anchor-header">vLLMã¨Llama 3.1-8Bã«ã‚ˆã‚‹RAGç”Ÿæˆã®ãƒ“ãƒ«ãƒ‰ã¨å®Ÿè¡Œ<button data-href="#Build-and-Perform-the-RAG-Generation-with-vLLM-and-Llama-31-8B" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><h3 id="Install-vLLM-and-models-from-HuggingFace" class="common-anchor-header">vLLMã¨HuggingFaceã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚</h3><p>vLLMã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§HuggingFaceã‹ã‚‰å¤§ããªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ä¸€èˆ¬çš„ã«ã€HuggingFaceã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ãŸã„å ´åˆã¯ã€ã„ã¤ã§ã‚‚pip install --upgradeã¾ãŸã¯-Uã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€vLLMã§Metaã®Llama 3.1ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯GPUãŒå¿…è¦ã§ã™ã€‚</p>
<p>vLLMãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹å…¨ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã¯ã€ã“ã¡ã‚‰ã®<a href="https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models">ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã‚’</a>ã”è¦§ãã ã•ã„ã€‚</p>
<pre><code translate="no" class="language-shell"><span class="hljs-comment"># (Recommended) Create a new conda environment.</span>
conda create -n myenv python=<span class="hljs-number">3.11</span> -y
conda activate myenv


<span class="hljs-comment"># Install vLLM with CUDA 12.1.</span>
pip install -U vllm transformers torch


<span class="hljs-keyword">import</span> vllm, torch
<span class="hljs-keyword">from</span> vllm <span class="hljs-keyword">import</span> LLM, SamplingParams


<span class="hljs-comment"># Clear the GPU memory cache.</span>
torch.cuda.empty_cache()


<span class="hljs-comment"># Check the GPU.</span>
!nvidia-smi
<button class="copy-code-btn"></button></code></pre>
<p>vLLMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€<a href="https://docs.vllm.ai/en/latest/getting_started/installation.html">ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«</a>ãƒšãƒ¼ã‚¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
<h3 id="Get-a-HuggingFace-token" class="common-anchor-header">HuggingFaceãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹ã€‚</h3><p>Meta Llama 3.1ã®ã‚ˆã†ãªHuggingFaceä¸Šã®ã„ãã¤ã‹ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¦ã‚§ã‚¤ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹å‰ã«ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’å—ã‘å…¥ã‚Œã‚‹ã“ã¨ã‚’è¦æ±‚ã—ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€HuggingFaceã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’æ‰¿èªã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
<p>HuggingFaceã®ã“ã®<a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-70B">Llama3.1ã®ãƒšãƒ¼ã‚¸ã«</a>ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€æ¡ä»¶ã«åŒæ„ã™ã‚‹ã‚ˆã†æ±‚ã‚ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚<strong>Accept License</strong>"ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å‰ã«ãƒ¡ã‚¿æ¡ä»¶ã‚’æ‰¿èªã—ã¦ãã ã•ã„ã€‚æ‰¿èªã«ã¯é€šå¸¸1æ—¥ã‚‚ã‹ã‹ã‚Šã¾ã›ã‚“ã€‚</p>
<p><strong>æ‰¿èªã‚’å—ã‘ãŸã‚‰ã€æ–°ã—ã„HuggingFaceãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚å¤ã„ãƒˆãƒ¼ã‚¯ãƒ³ã¯æ–°ã—ã„æ¨©é™ã§ã¯ä½¿ãˆã¾ã›ã‚“ã€‚</strong></p>
<p>vLLMã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å‰ã«ã€æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã§HuggingFaceã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã§ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«Colab secretsã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚</p>
<pre><code translate="no" class="language-shell"><span class="hljs-comment"># Login to HuggingFace using your new token.</span>
<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> login
<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> userdata
hf_token = userdata.get(<span class="hljs-string">&#x27;HF_TOKEN&#x27;</span>)
login(token = hf_token, add_to_git_credential=<span class="hljs-literal">True</span>)
<button class="copy-code-btn"></button></code></pre>
<h3 id="Run-the-RAG-Generation" class="common-anchor-header">RAGã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ</h3><p>ãƒ‡ãƒ¢ã§ã¯ã€<code translate="no">Llama-3.1-8B</code> ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã€‚ã“ã‚Œã¯ã€ã‚¹ãƒ”ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«GPUã¨ã‹ãªã‚Šã®ãƒ¡ãƒ¢ãƒªã‚’å¿…è¦ã¨ã™ã‚‹ã€‚ä»¥ä¸‹ã®ä¾‹ã¯ã€A100 GPUã‚’æ­è¼‰ã—ãŸGoogle Colab Proï¼ˆæœˆé¡10ãƒ‰ãƒ«ï¼‰ã§å®Ÿè¡Œã—ãŸã€‚vLLMã®å®Ÿè¡Œæ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html">ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’</a>ã”è¦§ãã ã•ã„ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># 1. Choose a model</span>
MODELTORUN = <span class="hljs-string">&quot;meta-llama/Meta-Llama-3.1-8B-Instruct&quot;</span>


<span class="hljs-comment"># 2. Clear the GPU memory cache, you&#x27;re going to need it all!</span>
torch.cuda.empty_cache()


<span class="hljs-comment"># 3. Instantiate a vLLM model instance.</span>
llm = LLM(model=MODELTORUN,
         enforce_eager=<span class="hljs-literal">True</span>,
         dtype=torch.bfloat16,
         gpu_memory_utilization=<span class="hljs-number">0.5</span>,
         max_model_len=<span class="hljs-number">1000</span>,
         seed=<span class="hljs-number">415</span>,
         max_num_batched_tokens=<span class="hljs-number">3000</span>)
<button class="copy-code-btn"></button></code></pre>
<p>Milvusã‹ã‚‰å–å¾—ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨˜è¿°ã—ã¾ã™ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Separate all the context together by space.</span>
contexts_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(contexts)
<span class="hljs-comment"># Lance Martin, LangChain, says put the best contexts at the end.</span>
contexts_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">reversed</span>(contexts))


<span class="hljs-comment"># Separate all the unique sources together by comma.</span>
source_combined = <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">reversed</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">dict</span>.fromkeys(sources))))


SYSTEM_PROMPT = <span class="hljs-string">f&quot;&quot;&quot;First, check if the provided Context is relevant to
the user&#x27;s question.  Second, only if the provided Context is strongly relevant, answer the question using the Context.  Otherwise, if the Context is not strongly relevant, answer the question without using the Context. 
Be clear, concise, relevant.  Answer clearly, in fewer than 2 sentences.
Grounding sources: <span class="hljs-subst">{source_combined}</span>
Context: <span class="hljs-subst">{contexts_combined}</span>
User&#x27;s question: <span class="hljs-subst">{SAMPLE_QUESTION}</span>
&quot;&quot;&quot;</span>


prompts = [SYSTEM_PROMPT]
<button class="copy-code-btn"></button></code></pre>
<p>æ¬¡ã«ã€å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è©°ã‚è¾¼ã¾ã‚ŒãŸå…ƒã®è³ªå•ã‚’ä½¿ã£ã¦ç­”ãˆã‚’ç”Ÿæˆã™ã‚‹ã€‚</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Sampling parameters</span>
sampling_params = SamplingParams(temperature=<span class="hljs-number">0.2</span>, top_p=<span class="hljs-number">0.95</span>)


<span class="hljs-comment"># Invoke the vLLM model.</span>
outputs = llm.generate(prompts, sampling_params)


<span class="hljs-comment"># Print the outputs.</span>
<span class="hljs-keyword">for</span> output <span class="hljs-keyword">in</span> outputs:
   prompt = output.prompt
   generated_text = output.outputs[<span class="hljs-number">0</span>].text
   <span class="hljs-comment"># !r calls repr(), which prints a string inside quotes.</span>
   <span class="hljs-built_in">print</span>()
   <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{SAMPLE_QUESTION!r}</span>&quot;</span>)
   pprint.pprint(<span class="hljs-string">f&quot;Generated text: <span class="hljs-subst">{generated_text!r}</span>&quot;</span>)
<button class="copy-code-btn"></button></code></pre>
<pre><code translate="no" class="language-text"><span class="hljs-title class_">Question</span>: <span class="hljs-string">&#x27;What do the parameters for HNSW MEAN!?&#x27;</span>
<span class="hljs-title class_">Generated</span> <span class="hljs-attr">text</span>: <span class="hljs-string">&#x27;Answer: The parameters for HNSW (Hiera(rchical Navigable Small World Graph) are: &#x27;</span>
<span class="hljs-string">&#x27;* M: The maximum degree of nodes on each layer oof the graph, which can improve &#x27;</span>
<span class="hljs-string">&#x27;recall rate at the cost of increased search time. * efConstruction and ef: &#x27;</span> 
<span class="hljs-string">&#x27;These parameters specify a search range when building or searching an index.&#x27;</span>
<button class="copy-code-btn"></button></code></pre>
<p>ä¸Šã®ç­”ãˆã¯ç§ã«ã¯å®Œç’§ã«è¦‹ãˆã¾ã™ï¼</p>
<p>ã“ã®ãƒ‡ãƒ¢ã«èˆˆå‘³ã‚’æŒãŸã‚ŒãŸæ–¹ã¯ã€ã”è‡ªç”±ã«ãŠè©¦ã—ã„ãŸã ãã€æ„Ÿæƒ³ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚ã¾ãŸã€<a href="https://discord.com/invite/8uyFbECzPX">Discordã®Milvusã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«</a>å‚åŠ ã—ã¦ã€GenAIé–‹ç™ºè€…å…¨å“¡ã¨ç›´æ¥ä¼šè©±ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚</p>
<h2 id="References" class="common-anchor-header">å‚è€ƒæ–‡çŒ®<button data-href="#References" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p>vLLM<a href="https://docs.vllm.ai/en/latest/getting_started/installation.html">å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨</a> <a href="https://docs.vllm.ai/en/latest/models/supported_models.html#supported-models">ãƒ¢ãƒ‡ãƒ«ãƒšãƒ¼ã‚¸</a></p></li>
<li><p><a href="https://arxiv.org/pdf/2309.06180">ãƒšãƒ¼ã‚¸ãƒ³ã‚°ã•ã‚ŒãŸæ³¨æ„ã«é–¢ã™ã‚‹2023 vLLMè«–æ–‡</a></p></li>
<li><p>Ray Summitã§ã®<a href="https://www.youtube.com/watch?v=80bIUggRJf4">2023 vLLMãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³</a></p></li>
<li><p>vLLM blog:<a href="https://blog.vllm.ai/2023/06/20/vllm.html">vLLM: PagedAttentionã‚’ä½¿ã£ãŸç°¡å˜ã€é«˜é€Ÿã€å®‰ä¾¡ãªLLM Serving</a></p></li>
<li><p>vLLMã‚µãƒ¼ãƒã®é‹ç”¨ã«å½¹ç«‹ã¤ãƒ–ãƒ­ã‚°<a href="https://ploomber.io/blog/vllm-deploy/">vLLMã®ãƒ‡ãƒ—ãƒ­ã‚¤ï¼šã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ã‚¬ã‚¤ãƒ‰</a></p></li>
<li><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">ãƒ©ãƒ3ä¸–ãƒ¢ãƒ‡ãƒ«ã®ç¾¤ã‚Œï½œç ”ç©¶ - AI at Meta</a></p></li>
</ul>
