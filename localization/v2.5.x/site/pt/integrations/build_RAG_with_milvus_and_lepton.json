{"codeList":["$ pip install --upgrade pymilvus[model] openai requests tqdm\n","import os\n\nos.environ[\"LEPTONAI_TOKEN\"] = \"***********\"\n","$ wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n$ unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs\n","from glob import glob\n\ntext_lines = []\n\nfor file_path in glob(\"milvus_docs/en/faq/*.md\", recursive=True):\n    with open(file_path, \"r\") as file:\n        file_text = file.read()\n\n    text_lines += file_text.split(\"# \")\n","from openai import OpenAI\n\nlepton_client = OpenAI(\n    api_key=os.environ[\"LEPTONAI_TOKEN\"],\n    base_url=\"https://mistral-7b.lepton.run/api/v1/\",\n)\n","from pymilvus import model as milvus_model\n\nembedding_model = milvus_model.DefaultEmbeddingFunction()\n","test_embedding = embedding_model.encode_queries([\"This is a test\"])[0]\nembedding_dim = len(test_embedding)\nprint(embedding_dim)\nprint(test_embedding[:10])\n","from pymilvus import MilvusClient\n\nmilvus_client = MilvusClient(uri=\"./milvus_demo.db\")\n\ncollection_name = \"my_rag_collection\"\n","if milvus_client.has_collection(collection_name):\n    milvus_client.drop_collection(collection_name)\n","milvus_client.create_collection(\n    collection_name=collection_name,\n    dimension=embedding_dim,\n    metric_type=\"IP\",  # Inner product distance\n    consistency_level=\"Strong\",  # Strong consistency level\n)\n","from tqdm import tqdm\n\ndata = []\n\ndoc_embeddings = embedding_model.encode_documents(text_lines)\n\nfor i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n    data.append({\"id\": i, \"vector\": doc_embeddings[i], \"text\": line})\n\nmilvus_client.insert(collection_name=collection_name, data=data)\n","question = \"How is data stored in milvus?\"\n","search_res = milvus_client.search(\n    collection_name=collection_name,\n    data=embedding_model.encode_queries(\n        [question]\n    ),  # Convert the question to an embedding vector\n    limit=3,  # Return top 3 results\n    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n    output_fields=[\"text\"],  # Return the text field\n)\n","import json\n\nretrieved_lines_with_distances = [\n    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n]\nprint(json.dumps(retrieved_lines_with_distances, indent=4))\n","context = \"\\n\".join(\n    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n)\n","SYSTEM_PROMPT = \"\"\"\nHuman: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n\"\"\"\nUSER_PROMPT = f\"\"\"\nUse the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n<context>\n{context}\n</context>\n<question>\n{question}\n</question>\n\"\"\"\n","response = lepton_client.chat.completions.create(\n    model=\"mistral-7b\",\n    messages=[\n        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n        {\"role\": \"user\", \"content\": USER_PROMPT},\n    ],\n)\nprint(response.choices[0].message.content)\n"],"headingContent":"Build RAG with Milvus and Lepton AI","anchorList":[{"label":"Build RAG with Milvus and Lepton AI","href":"Build-RAG-with-Milvus-and-Lepton-AI","type":1,"isActive":false},{"label":"Preparation","href":"Preparation","type":2,"isActive":false},{"label":"Load data into Milvus","href":"Load-data-into-Milvus","type":2,"isActive":false},{"label":"Build RAG","href":"Build-RAG","type":2,"isActive":false}]}